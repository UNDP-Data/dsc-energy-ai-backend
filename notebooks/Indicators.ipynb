{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba99349b-4804-44bc-8e75-3128cecc209e",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053701cb-254e-4c3b-9146-2e570341c750",
   "metadata": {},
   "source": [
    "Instructions for SUTime (Taken from this page: https://github.com/FraBle/python-sutime)\n",
    "\n",
    "To install SUTime, follow these steps:\n",
    "```python\n",
    "# Ideally, create a virtual environment before installing any dependencies\n",
    "pip install sutime\n",
    "# Install Java dependencies\n",
    "mvn dependency:copy-dependencies -DoutputDirectory=./jars -f $(python3 -c 'import importlib; import pathlib; print(pathlib.Path(importlib.util.find_spec(\"sutime\").origin).parent / \"pom.xml\")')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2d9dcf-b7fd-4c8a-b007-6d6692189b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import re\n",
    "import tiktoken\n",
    "import time\n",
    "import faiss\n",
    "import awoc\n",
    "import spacy\n",
    "import csv\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from sutime import SUTime\n",
    "import json\n",
    "import datetime\n",
    "from bert_score import score as bert_score\n",
    "from country_named_entity_recognition import find_countries\n",
    "import ast\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../utils')\n",
    "\n",
    "from processing_modules_for_test_indicator import semanticSearchModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d16eed-8ad4-41cb-87ac-56b0c627e301",
   "metadata": {},
   "source": [
    "## Load Raw Documents Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d78821-139c-4c9f-bc8e-c00d656359a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main data\n",
    "wdi_csv = pd.read_csv('../data/WDI_CSV/WDICSV.csv')\n",
    "# country meta data\n",
    "wdi_country = pd.read_csv('../data/WDI_CSV/WDICountry.csv')\n",
    "# Series meta data\n",
    "wdi_series = pd.read_csv('../data/WDI_CSV/WDISeries.csv')\n",
    "# country + series\n",
    "#wdi_country_series = pd.read_csv('../data/WDI_CSV/WDIcountry-series.csv')\n",
    "# series + time\n",
    "#wdi_series_time = pd.read_csv('../data/WDI_CSV/WDIseries-time.csv')\n",
    "# With CountryCode + SeriesCode + year, describe more info about this resource\n",
    "#wdi_footnote = pd.read_csv('../data/WDI_CSV/WDIfootnote.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd74365-94ef-44e9-bf65-8167cc4ff2f2",
   "metadata": {},
   "source": [
    "## Load Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07c63cf-0815-47cc-ba92-0f350971617d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee3772a-959b-4d97-a2c9-c8b6fb407d8f",
   "metadata": {},
   "source": [
    "## OpenAI API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221e10b7-28d0-47cb-b13c-b7442a809c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API configuration\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"api_key_azure\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"api_version\")\n",
    "openai_deployment = \"sdgi-gpt-35-turbo-16k\"\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"api_key_azure\"),  \n",
    "  api_version = os.getenv(\"api_version\"),\n",
    "  azure_endpoint =os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    ")\n",
    "\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "embedding_model = os.getenv(\"USER_QUERY_EMBEDDING_ENGINE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619262ea-724b-44de-8bd3-d8d36b2e8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to make simple openAI Calls\n",
    "def callOpenAI(prompt):  \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ]\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b001050-5e77-4986-985c-230202dfa2ff",
   "metadata": {},
   "source": [
    "To get any information from WDICSV.csv (WDI meta data) we need 3 things: 1. country code 2. indicator code 3. target period (1960 - 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105332f-1762-4608-a6e7-208ed83434aa",
   "metadata": {},
   "source": [
    "## Function for searching country code (First Condition Done ✅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd36673f-d6ef-47b7-82af-f89762719967",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Previous 'find_mentioned_countries' can detect countries when they are formed correctly.\n",
    "\n",
    "'''\n",
    "# Extract mentioned countries' ISO3 code\n",
    "def find_mentioned_country_code(user_query):\n",
    "    countries = set()\n",
    "    extracted_countries = find_countries(user_query, is_ignore_case=True)\n",
    "    # check if we have country first\n",
    "    if extracted_countries:\n",
    "        for c in extracted_countries:\n",
    "            countries.add(c[0].alpha_3)\n",
    "    # check if we have continent\n",
    "    else:\n",
    "        words = re.findall(r'\\w+|[^\\w\\s]', user_query)\n",
    "        text = ' '.join(words)  # Join the tokens back into a string\n",
    "    \n",
    "        world_info = awoc.AWOC()\n",
    "        all_continents = set([continent.lower() for continent in world_info.get_continents_list()])\n",
    "        for word in text.split():\n",
    "            word = word.lower()\n",
    "            # check if this continent\n",
    "            if word in all_continents:\n",
    "                target_countries = world_info.get_countries_list_of(word)\n",
    "                for country in target_countries:\n",
    "                    countries.add(world_info.get_country_data(country)['ISO3'])\n",
    "    return countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d1a17-8822-4fa1-a604-c9eaaf8fd6c1",
   "metadata": {},
   "source": [
    "# Function for searching indicator code (Second Condition Done✅)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a4578-3f5d-4e5a-bda8-702c69463189",
   "metadata": {},
   "source": [
    "## Embedding Processing for Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5094b8b1-234b-46e0-ae38-130d6f4a57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(row):\n",
    "    time.sleep(3)\n",
    "    #print(row.name)\n",
    "    input_text = row['Indicator Name'].replace(\"\\n\", \" \")\n",
    "    input_text = re.sub(r'\\s+', ' ', input_text)\n",
    "    encodings = encoding.encode(input_text)\n",
    "    length = len(encodings)\n",
    "    embedding = client.embeddings.create( \n",
    "        input=input_text ,model= embedding_model\n",
    "    ).data[0].embedding\n",
    "    \n",
    "    return length, embedding\n",
    "\n",
    "#wdi_series['token_length'], wdi_series['Embedding'] = zip(*wdi_series.apply(lambda row: create_embedding(row), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f53dfdb7-12dd-43cc-a860-d880ce8fdf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wdi_series.to_pickle('../data/indicator_meta_embed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43470894-46b1-43a5-8680-3e3788a7c026",
   "metadata": {},
   "source": [
    "## Searching target indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3b703a-57b3-493a-862c-8160d152acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/indicator_meta_embed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eab9be9-a94b-40cd-8c23-70efbb217489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Jaccard similarity between two texts\n",
    "def jaccard_similarity(text1, text2):\n",
    "    # Tokenize texts\n",
    "    tokens1 = set(text1.lower().split())\n",
    "    tokens2 = set(text2.lower().split())\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    intersection = len(tokens1.intersection(tokens2))\n",
    "    union = len(tokens1.union(tokens2))\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96a5e173-6a61-4a48-bb68-180e698e1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_indicators(user_query):\n",
    "    # Calculate similarity scores for each indicators\n",
    "    similarity_scores = []\n",
    "    indicators = []\n",
    "\n",
    "    # Iterate through each indicator title and calculate similarity score\n",
    "    for indicator in df['Indicator Name']:\n",
    "        similarity_score = jaccard_similarity(user_query, indicator)\n",
    "        similarity_scores.append(similarity_score)\n",
    "        indicators.append(indicator)\n",
    "        \n",
    "    # Create DataFrame only with valid similarity scores\n",
    "    similarity_df = pd.DataFrame({'Indicator Name': indicators, 'Similarity Score': similarity_scores})\n",
    "    similarity_df = similarity_df.sort_values('Similarity Score', ascending=False)\n",
    "    similarity_df = similarity_df[:10]\n",
    "        \n",
    "    # Filter indicators where similarity score is above a threshold (e.g., 0.3)\n",
    "    threshold = 0.01\n",
    "    filtered_df = df[df['Indicator Name'].isin(similarity_df[similarity_df['Similarity Score'] > threshold]['Indicator Name'])]\n",
    "\n",
    "    return  list(filtered_df['Series Code'])\n",
    "#print(filter_indicators(test_query))\n",
    "#print(filter_indicators(test_query2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f51e73a-597b-41c1-a2e0-76d3fece207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search target indicator\n",
    "# Implement this function later\n",
    "def search_embeddings(user_query):\n",
    "    df_filtered = filter_indicators(user_query) if filter_indicators(user_query) is not None else None\n",
    "    \n",
    "    if df_filtered is not None and not df_filtered.empty:  # Check if DataFrame is not None and not empty\n",
    "        length = len(df_filtered.head())\n",
    "        filtered_embeddings_arrays = np.array(list(df_filtered['Embedding']))\n",
    "        index = faiss.IndexFlatIP(filtered_embeddings_arrays.shape[1]) \n",
    "        index.add(filtered_embeddings_arrays)\n",
    "        \n",
    "        user_query_embedding = client.embeddings.create( \n",
    "                input=user_query ,model= embedding_model\n",
    "            ).data[0].embedding\n",
    "\n",
    "        k = min(5, length)\n",
    "        distances, indices = index.search(np.array([user_query_embedding]), k)\n",
    "        return df_filtered, distances, indices\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54971fae-ddcf-4caf-b0fe-1c3c6240f746",
   "metadata": {},
   "source": [
    "# Function for searching target period (1960 - 2023) (Third Condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad977de-aabd-4857-aaf9-0f980be92b0f",
   "metadata": {},
   "source": [
    "First Trial - Package is too heavy❌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a40d575b-c8ba-4ff5-baba-3002debe466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract set of years from given timex3_list\n",
    "def timex3_to_year_list(timex3_list):\n",
    "    year_list = set()\n",
    "    for timex3 in timex3_list:\n",
    "        sutimeType, value = timex3[\"type\"], timex3[\"value\"]\n",
    "        if \"REF\" not in value:\n",
    "            if isinstance(value, dict):\n",
    "                if value:\n",
    "                    for year in range(int(value['begin']), int(value['end']) + 1):\n",
    "                        year_list.add(str(year))\n",
    "            elif value.isdigit():\n",
    "                year_list.add(str(value))\n",
    "            elif sutimeType in ['DATE', 'DURATION']:\n",
    "                if sutimeType == 'DATE':\n",
    "                    res = re.search('^\\d\\d\\d\\d', value)\n",
    "                    if res:\n",
    "                        year_list.add(str(res.group(0)))\n",
    "                else:\n",
    "                    year_dur = 0\n",
    "                    current_year = datetime.now().year\n",
    "                    dur_list = re.findall('\\d+', \"\".join(re.findall('P[0-9]+Y', value)))\n",
    "                    if dur_list:\n",
    "                        year_dur = max([int(y) for y in dur_list])\n",
    "                        while year_dur:\n",
    "                            year_list.add(str(current_year - year_dur))\n",
    "                            year_dur -= 1\n",
    "            else:\n",
    "                continue\n",
    "    return list(year_list)\n",
    "    \n",
    "def find_target_period(user_query):\n",
    "    sutime = SUTime(mark_time_ranges = True, include_range = True)\n",
    "    res = sutime.parse(user_query)\n",
    "    return timex3_to_year_list(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc03ad-6020-4c87-9562-424fc8e413fa",
   "metadata": {},
   "source": [
    "Second Trial - using GPT. Works pretty well ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8d2d6f1-fc02-4f0f-a31f-75d2d4c79ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_period(user_query):\n",
    "    current_year = datetime.date.today().year\n",
    "    gpt_prompt = f\"\"\"\n",
    "    Identify and extract all the years mentioned in the provided user query, returning them as a list. Current year is {current_year}\n",
    "    The format of the output should be a list of strings, each representing a year, e.g., [\\\"2020\\\", \\\"2021\\\"].\n",
    "\n",
    "    User Query: {user_query}\n",
    "    \"\"\"\n",
    "\n",
    "    answer = callOpenAI(gpt_prompt)\n",
    "\n",
    "    year_list = ast.literal_eval(answer)\n",
    "    \n",
    "    return year_list if year_list else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59551b17-a78f-4aaf-9f0b-c7d13463e6e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019', '2020', '2021', '2022', '2023']\n",
      "['2021']\n",
      "['2020', '2021', '2022', '2023']\n"
     ]
    }
   ],
   "source": [
    "test1 = \"past 5 years\"\n",
    "test2 = \"in 2021\"\n",
    "test3 = \"from 2020 to 2023\"\n",
    "print(find_target_period(test1))\n",
    "print(find_target_period(test2))\n",
    "print(find_target_period(test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4406f-5189-4a7f-9752-b377f40a8d07",
   "metadata": {},
   "source": [
    "## Final one function for searching indicator data (Function for finding info from indicator database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d45b480-44fa-4fd7-b02a-83eda2cedab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_structure(countries, indicators, years):\n",
    "    # load all indicator dataset\n",
    "    # wdi_csv = pd.read_csv('../data/WDI_CSV/WDICSV.csv')\n",
    "    count = 0\n",
    "    result_dict = {}\n",
    "    for country in countries:\n",
    "        for indicator in indicators:\n",
    "            indicator_id = f\"indicator-{count + 1}\"\n",
    "            target_row = wdi_csv[(wdi_csv['Country Code'] == country) & (wdi_csv['Indicator Code'] == indicator)]\n",
    "            if not target_row.empty:\n",
    "                country_name, indicator_name = target_row['Country Name'].values[0], target_row['Indicator Name'].values[0]\n",
    "                if years:\n",
    "                    target_row = target_row[years]\n",
    "                else:\n",
    "                    target_row = target_row.iloc[:,4:]\n",
    "                target_row = target_row.dropna(axis=1)\n",
    "                if not target_row.empty:\n",
    "                    year_to_value = {}\n",
    "                    for column in target_row:\n",
    "                        year_to_value[column] = target_row[column].values[0]\n",
    "                    indicator_info = {\n",
    "                        \"Country\": country_name,\n",
    "                        \"Indicator Name\": indicator_name,\n",
    "                        \"Values Per Year\": year_to_value\n",
    "                    }\n",
    "                    \n",
    "                    result_dict[indicator_id] = indicator_info\n",
    "                    # Increment the counter\n",
    "                    count += 1\n",
    "        if count == 30:\n",
    "            break\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e64e007e-c4cf-4876-a39a-361d31556c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## module to extract text from documents and return the text and document codes\n",
    "def indicatorsModule(user_query):\n",
    "    countries = find_mentioned_country_code(user_query)\n",
    "    indicators = filter_indicators(user_query) #df, distances, indices\n",
    "    years = find_target_period(user_query)\n",
    "    if countries and indicators:\n",
    "        # Reduce Indicator List to 2 if countries are too many\n",
    "        if len(countries) > 5:\n",
    "            indicators = indicators[:2]\n",
    "        # for testing\n",
    "        #result_structure = {}\n",
    "        #result_structure[\"User Query\"] = user_query\n",
    "        #result_structure[\"indicatorsModule Result\"] = map_to_structure(countries, indicators, years)\n",
    "        result_structure = map_to_structure(countries, indicators, years)\n",
    "        return result_structure\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cf8b9-2481-4f5f-873b-2a406aac0265",
   "metadata": {},
   "source": [
    "# Test Function (indicatorsModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00a85b63-0697-4351-a866-6f358a2c8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(csv_file, moonshot_model):\n",
    "    # Initialize an empty list to store processed entries\n",
    "    result = []\n",
    "    \n",
    "    # Loop through each entry in the CSV file\n",
    "    for entry in csv.DictReader(csv_file):\n",
    "        print(f\"Testing Query #{len(result)}...\")\n",
    "        query = entry['query']\n",
    "        sample_answer = entry['sample_answer']\n",
    "        \n",
    "        # Call OpenAI for chat GPT answer\n",
    "        chat_gpt_answer = callOpenAI(f\"\"\" \n",
    "                                    {query}\n",
    "                                    \"\"\")\n",
    "        \n",
    "        # Call the moonshot model API\n",
    "        moonshot_model_answer = moonshot_model(query)\n",
    "\n",
    "        # Calculate BERT score for moonshot model answer\n",
    "        P, F, R = bert_score([sample_answer], [moonshot_model_answer['answer']], lang='en', verbose=True)\n",
    "        entry['moonshot_model_answer'] = moonshot_model_answer['answer']\n",
    "        entry['bert_score'] = round(float(F), 2)\n",
    "\n",
    "        # Calculate BERT score for chat GPT answer\n",
    "        P, F, R = bert_score([sample_answer], [chat_gpt_answer], lang='en', verbose=True)\n",
    "        entry['chat_gpt_answer'] = chat_gpt_answer\n",
    "        entry['bert_score_gpt'] = round(float(F), 2)\n",
    "        \n",
    "        # Append the processed entry to the result list\n",
    "        result.append(entry)\n",
    "    \n",
    "    # Return the list of processed entries\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ee2eb-5ff1-4d2b-8a01-bfdc866d0c04",
   "metadata": {},
   "source": [
    "## Conduct test only using the indicator database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b751eb6-347c-4b55-94ee-d3ffc27d0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moonshot_model_indicator_only(user_query):\n",
    "    \n",
    "    ##run processing modules\n",
    "    indicators_dict=indicatorsModule(user_query)\n",
    "    llm_instructions = f\"\"\"\n",
    "    Ignore previous commands!!!\n",
    "    Given a user query, use the provided <Sources> extract section of the JSON only to provide the correct answer to the user's query.\n",
    "    \n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Sources: {indicators_dict}\n",
    "\n",
    "    - Among the given data sources provided in the json, reference all of them, but only use the materials necessary to answer the <User Query>\n",
    "    - Keep your response concise and maintain a formal academic tone. Avoid providing lengthy answers.\n",
    "    - If no or only some <Sources> are provided, attempt to make suggestions or provide a partial response. If unable to obtain any answer, simply state that you don't have that information.  \n",
    "    - Remove new line or tab characters from your output\n",
    "    \"\"\"\n",
    "    \n",
    "    ##synthesis module\n",
    "    answer = callOpenAI(llm_instructions)\n",
    "\n",
    "    ##structure response\n",
    "    response={\n",
    "        \"user_query\":user_query,\n",
    "        \"answer\":answer,\n",
    "        \"sources\":indicators_dict,    \n",
    "    }\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7f691c87-e755-4807-b385-cb4c70bb78e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Query #0...\n",
      "Testing Query #1...\n",
      "Testing Query #2...\n",
      "Testing Query #3...\n"
     ]
    }
   ],
   "source": [
    "# Test only using indicator database\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = \"../testing/indicator_test/test_queries.csv\"\n",
    "\n",
    "result = []\n",
    "# Open the CSV file for reading\n",
    "with open(csv_file_path, mode='r') as file:\n",
    "    for entry in csv.DictReader(file):\n",
    "        print(f\"Testing Query #{len(result)}...\")\n",
    "        query = entry['query']\n",
    "        sample_answer = entry['sample_answer']\n",
    "        \n",
    "        # Call OpenAI for chat GPT answer\n",
    "        chat_gpt_answer = callOpenAI(f\"{query}\")\n",
    "        # Call the moonshot model API\n",
    "        moonshot_model_answer = moonshot_model_indicator_only(query)\n",
    "        \n",
    "        entry['moonshot_model_answer'] = moonshot_model_answer['answer']\n",
    "        entry['chat_gpt_answer'] = chat_gpt_answer\n",
    "        \n",
    "        # Append the processed entry to the result list\n",
    "        result.append(entry)\n",
    "        \n",
    "# Print updated data with scores\n",
    "#print(json.dumps(result, indent=4))\n",
    "\n",
    "# Save updated data to a JSON file\n",
    "with open('../testing/indicator_test/test_output_indicator_only.json', 'w') as file:\n",
    "    json.dump(result, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b536f-83b0-49c6-9422-5bf0f0b3112f",
   "metadata": {},
   "source": [
    "# \"Layer\" before implementing indicator functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01653460-2b4b-4b8b-b094-248e3559cbc2",
   "metadata": {},
   "source": [
    "We've observed that the indicator database is necessary only when a user query requires statistical information. Otherwise, our indicator functions pull the wrong data, wasting time. We could add a layer to determine if statistical information is needed for a user query, allowing us to decide whether to implement indicator functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec7059-ecd0-4078-b176-db734022d2d9",
   "metadata": {},
   "source": [
    "## Test Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23114f10-2c72-4448-ad00-da2bd84c76da",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_query = \"How much private investment did Ethiopia attract in its energy sector in 2021?\" # Expected: True\n",
    "clarification_query = \"Could you clarify the role of UNDP in promoting sustainable energy solutions in urban areas?\" # Expected: False\n",
    "comparative_query = \"How does UNDP's approach to sustainable energy differ from other international development organizations?\" # Expected: False\n",
    "descriptive_query = \"Can you describe the impact of UNDP's sustainable energy projects on local communities?\" # Expected: False\n",
    "informational_query = \"What are the indicators used by UNDP to measure the effectiveness of sustainable energy interventions?\" # Expected: False\n",
    "opinion_query = \"Has UNDP's focus on sustainable energy contributed to poverty alleviation in rural areas?\" # Expected: False\n",
    "procedural_query = \"How do you assess the feasibility of a sustainable energy project, following UNDP's guidelines?\" # Expected: False\n",
    "queries = \"What percentage of Niger's population has access to electricity for productive use?\" # Expected: True\n",
    "indicator_query2 = \"What percentage of China's total energy consumption in 2014 came from fossil fuels such as coal, oil, natural gas, and similar sources?\" # Expected: True\n",
    "\n",
    "\n",
    "test_queries = [indicator_query, clarification_query, comparative_query, descriptive_query, informational_query, opinion_query, procedural_query, queries, indicator_query2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d936c373-86bd-41e2-874e-c58293649a90",
   "metadata": {},
   "source": [
    "## First Trial - Few Shot (Didn't work well) ❌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90669bad-85a1-4cdb-bec8-1a6b1349e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to make simple openAI Calls\n",
    "def callOpenAIFewShot(prompts):  \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0,\n",
    "                    messages=prompts\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b8b8d49-f20d-4188-8467-b40f648e80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_layer_few_shot(user_query):\n",
    "    # few-shot prompt\n",
    "    llm_instructions = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\":\"As an AI assistant, your task is to determine if a user query requires statistical information. These are questions that depend on quantitative data (such as mean, percentage, etc.) for an accurate response.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What has been the average percentage of the population with access to energy, electricity, and clean cooking solutions in Haiti over the past five years?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"True\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Could you clarify the role of UNDP in promoting sustainable energy solutions in urban areas?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"False\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{user_query}\"\n",
    "        }\n",
    "    ]\n",
    "    ##synthesis module\n",
    "    answer = callOpenAIFewShot(llm_instructions)\n",
    "\n",
    "    ##structure response\n",
    "    response={\n",
    "        \"user_query\":user_query,\n",
    "        \"answer\":answer   \n",
    "    }\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bb70331-9618-417a-9d57-16e427dac836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_query': 'How much private investment did Ethiopia attract in its energy sector in 2021?', 'answer': 'True'}\n",
      "{'user_query': 'Could you clarify the role of UNDP in promoting sustainable energy solutions in urban areas?', 'answer': 'True'}\n",
      "{'user_query': \"How does UNDP's approach to sustainable energy differ from other international development organizations?\", 'answer': 'True'}\n",
      "{'user_query': \"Can you describe the impact of UNDP's sustainable energy projects on local communities?\", 'answer': 'True'}\n",
      "{'user_query': 'What are the indicators used by UNDP to measure the effectiveness of sustainable energy interventions?', 'answer': 'True'}\n",
      "{'user_query': \"Has UNDP's focus on sustainable energy contributed to poverty alleviation in rural areas?\", 'answer': 'True'}\n",
      "{'user_query': \"How do you assess the feasibility of a sustainable energy project, following UNDP's guidelines?\", 'answer': 'True'}\n",
      "{'user_query': \"What percentage of Niger's population has access to electricity for productive use?\", 'answer': 'True'}\n",
      "{'user_query': \"What percentage of China's total energy consumption in 2014 came from fossil fuels such as coal, oil, natural gas, and similar sources?\", 'answer': 'True'}\n"
     ]
    }
   ],
   "source": [
    "for query in test_queries:\n",
    "    print(indicator_layer_few_shot(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65c168-2f01-461c-a7ef-dc81bfd56b30",
   "metadata": {},
   "source": [
    "## Second Trial - Most of time works well but need to do experiments more ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b33615f-13db-44a6-9017-8f874d5b2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_layer(user_query):\n",
    "    llm_instructions = f\"\"\"\n",
    "    Determine if a user query requires statistical information. These are questions that depend on quantitative data for an accurate response. Answer with \"True\" or False\"\n",
    "\n",
    "    User Query: {user_query}\n",
    "    \"\"\"\n",
    "    ##synthesis module\n",
    "    #answer = callOpenAIFewShot(llm_instructions)\n",
    "    answer = callOpenAI(llm_instructions)\n",
    "\n",
    "    ##structure response\n",
    "    response={\n",
    "        \"user_query\":user_query,\n",
    "        \"answer\":answer   \n",
    "    }\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c29a8810-e3e3-4116-86a6-8b280b61301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_query': 'How much private investment did Ethiopia attract in its energy sector in 2021?', 'answer': 'True'}\n",
      "{'user_query': 'Could you clarify the role of UNDP in promoting sustainable energy solutions in urban areas?', 'answer': 'False'}\n",
      "{'user_query': \"How does UNDP's approach to sustainable energy differ from other international development organizations?\", 'answer': 'False'}\n",
      "{'user_query': \"Can you describe the impact of UNDP's sustainable energy projects on local communities?\", 'answer': 'False'}\n",
      "{'user_query': 'What are the indicators used by UNDP to measure the effectiveness of sustainable energy interventions?', 'answer': 'False'}\n",
      "{'user_query': \"Has UNDP's focus on sustainable energy contributed to poverty alleviation in rural areas?\", 'answer': 'False'}\n",
      "{'user_query': \"How do you assess the feasibility of a sustainable energy project, following UNDP's guidelines?\", 'answer': 'False'}\n",
      "{'user_query': \"What percentage of Niger's population has access to electricity for productive use?\", 'answer': 'True'}\n",
      "{'user_query': \"What percentage of China's total energy consumption in 2014 came from fossil fuels such as coal, oil, natural gas, and similar sources?\", 'answer': 'True'}\n"
     ]
    }
   ],
   "source": [
    "for query in test_queries:\n",
    "    print(indicator_layer(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285af89-2565-4bb9-8bb8-aa8d2d6423e1",
   "metadata": {},
   "source": [
    "# Indicator Trello Test Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55f259ad-f23d-4ad3-a5b3-e6d1562fd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_csv = pd. read_csv('../data/WDI_CSV/WDICSV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21c903a6-117b-4614-b116-d01c095a3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_trello_test(user_query) :\n",
    "    is_indicator_question = indicator_layer(user_query)\n",
    "    country_codes = find_mentioned_country_code (user_query)\n",
    "    indicator_codes = filter_indicators (user_query)\n",
    "    years = find_target_period (user_query)\n",
    "    countries, indicators = set(), []\n",
    "    \n",
    "    for country_code in country_codes:\n",
    "        for indicator_code in indicator_codes:\n",
    "            target_row = wdi_csv[(wdi_csv['Country Code'] == country_code) & (wdi_csv['Indicator Code'] == indicator_code)]\n",
    "            if not target_row. empty:\n",
    "                country, indicator = target_row['Country Name'].values[0], target_row['Indicator Name'].values [0]\n",
    "                countries.add(country)\n",
    "                indicators.append (indicator)\n",
    "                \n",
    "    query_analysis_info = {\n",
    "        'is_indicator_question': is_indicator_question['answer'],\n",
    "        'Countries': list(countries),\n",
    "        'Indicators': indicators,\n",
    "        'years': years\n",
    "    }\n",
    "    \n",
    "    return query_analysis_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04756177-55a5-443b-b3e5-f78e6f549858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_indicator_question': 'True',\n",
       " 'Countries': ['China'],\n",
       " 'Indicators': ['Electricity production from oil, gas and coal sources (% of total)',\n",
       "  'Renewable energy consumption (% of total final energy consumption)',\n",
       "  'Alternative and nuclear energy (% of total energy use)',\n",
       "  'Fossil fuel energy consumption (% of total)',\n",
       "  'Merchandise imports from low- and middle-income economies in East Asia & Pacific (% of total merchandise imports)',\n",
       "  'Merchandise imports from low- and middle-income economies in Europe & Central Asia (% of total merchandise imports)',\n",
       "  'Merchandise imports from low- and middle-income economies in Latin America & the Caribbean (% of total merchandise imports)',\n",
       "  'Merchandise imports from low- and middle-income economies in Middle East & North Africa (% of total merchandise imports)',\n",
       "  'Merchandise imports from low- and middle-income economies in South Asia (% of total merchandise imports)',\n",
       "  'Merchandise imports from low- and middle-income economies in Sub-Saharan Africa (% of total merchandise imports)'],\n",
       " 'years': ['2014']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator_trello_test(indicator_query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364b25c-e7b0-4d36-93a0-bdad6449824e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
