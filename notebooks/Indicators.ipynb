{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba99349b-4804-44bc-8e75-3128cecc209e",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c2d9dcf-b7fd-4c8a-b007-6d6692189b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import re\n",
    "import tiktoken\n",
    "import time\n",
    "import faiss\n",
    "import awoc\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sutime import SUTime\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d16eed-8ad4-41cb-87ac-56b0c627e301",
   "metadata": {},
   "source": [
    "## Load Documents Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d78821-139c-4c9f-bc8e-c00d656359a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main data\n",
    "wdi_csv = pd.read_csv('../data/WDI_CSV/WDICSV.csv')\n",
    "# country meta data\n",
    "wdi_country = pd.read_csv('../data/WDI_CSV/WDICountry.csv')\n",
    "# Series meta data\n",
    "wdi_series = pd.read_csv('../data/WDI_CSV/WDISeries.csv')\n",
    "# country + series\n",
    "#wdi_country_series = pd.read_csv('../data/WDI_CSV/WDIcountry-series.csv')\n",
    "# series + time\n",
    "#wdi_series_time = pd.read_csv('../data/WDI_CSV/WDIseries-time.csv')\n",
    "# With CountryCode + SeriesCode + year, describe more info about this resource\n",
    "#wdi_footnote = pd.read_csv('../data/WDI_CSV/WDIfootnote.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd74365-94ef-44e9-bf65-8167cc4ff2f2",
   "metadata": {},
   "source": [
    "## Load Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07c63cf-0815-47cc-ba92-0f350971617d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee3772a-959b-4d97-a2c9-c8b6fb407d8f",
   "metadata": {},
   "source": [
    "## OpenAI API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221e10b7-28d0-47cb-b13c-b7442a809c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API configuration\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"api_key_azure\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"api_version\")\n",
    "openai_deployment = \"sdgi-gpt-35-turbo-16k\"\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"api_key_azure\"),  \n",
    "  api_version = os.getenv(\"api_version\"),\n",
    "  azure_endpoint =os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    ")\n",
    "\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "embedding_model = os.getenv(\"USER_QUERY_EMBEDDING_ENGINE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619262ea-724b-44de-8bd3-d8d36b2e8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to make simple openAI Calls\n",
    "def callOpenAI(prompt):  \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ]\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2064d46-3400-489b-8da5-8b1f31e89dfc",
   "metadata": {},
   "source": [
    "## Test Query Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddad0d7c-3a88-4f56-b73e-ad5bedad19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"How many people in africa lack access to energy/electricity/clean cooking solutions?\"\n",
    "test_query2 = 'What is the Human Development Index (HDI) value for albania as mentioned in the document?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b001050-5e77-4986-985c-230202dfa2ff",
   "metadata": {},
   "source": [
    "To get any information from WDICSV.csv (WDI meta data) we need 3 things: 1. country code 2. indicator code 3. target period (1960 - 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105332f-1762-4608-a6e7-208ed83434aa",
   "metadata": {},
   "source": [
    "## Function for searching country code (First Condition Done ✅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd36673f-d6ef-47b7-82af-f89762719967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'REU', 'ESH', 'ZWE', 'MAR', 'TCD', 'GHA', 'BWA', 'SDN', 'NER', 'COM', 'STP', 'GNQ', 'LBY', 'RWA', 'NAM', 'TZA', 'ZMB', 'TUN', 'UGA', 'GMB', 'GIN', 'CMR', 'CPV', 'MOZ', 'DJI', 'BFA', 'SYC', 'MUS', 'SEN', 'ZAF', 'COD', 'BDI', 'KEN', 'LSO', 'ETH', 'COG', 'SOM', 'ERI', 'GNB', 'GAB', 'MYT', 'NGA', 'AGO', 'CIV', 'SSD', 'SWZ', 'MLI', 'MRT', 'TGO', 'LBR', 'MWI', 'MDG', 'CAF', 'BEN', 'DZA', 'SHN', 'EGY', 'SLE'}\n",
      "{'ALB'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Previous 'find_mentioned_countries' cannot catch continent -> Modify a bit\n",
    "'''\n",
    "# Extract mentioned countries' ISO3 code\n",
    "def find_mentioned_country_code(user_query):\n",
    "    countries = set()\n",
    "    \n",
    "    # Tokenize the text using regular expressions to preserve punctuation marks\n",
    "    words = re.findall(r'\\w+|[^\\w\\s]', user_query)\n",
    "    text = ' '.join(words)  # Join the tokens back into a string\n",
    "    \n",
    "    world_info = awoc.AWOC()\n",
    "\n",
    "    all_continents = set([continent.lower() for continent in world_info.get_continents_list()])\n",
    "    all_countries = set([country.lower() for country in world_info.get_countries_list()])\n",
    "    \n",
    "    for word in text.split():\n",
    "        # check if this continent\n",
    "        if word in all_countries:\n",
    "            countries.add(world_info.get_country_data(word)['ISO3'])\n",
    "        elif word.lower() in all_continents:\n",
    "            target_countries = world_info.get_countries_list_of(word)\n",
    "            for country in target_countries:\n",
    "                countries.add(world_info.get_country_data(country)['ISO3'])\n",
    "    return countries\n",
    "print(find_mentioned_country_code(test_query))\n",
    "print(find_mentioned_country_code(test_query2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d1a17-8822-4fa1-a604-c9eaaf8fd6c1",
   "metadata": {},
   "source": [
    "# Function for searching indicator code (Second Condition Done✅)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a4578-3f5d-4e5a-bda8-702c69463189",
   "metadata": {},
   "source": [
    "## Embedding Processing for Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094b8b1-234b-46e0-ae38-130d6f4a57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(row):\n",
    "    time.sleep(3)\n",
    "    #print(row.name)\n",
    "    input_text = row['Indicator Name'].replace(\"\\n\", \" \")\n",
    "    input_text = re.sub(r'\\s+', ' ', input_text)\n",
    "    encodings = encoding.encode(input_text)\n",
    "    length = len(encodings)\n",
    "    embedding = client.embeddings.create( \n",
    "        input=input_text ,model= embedding_model\n",
    "    ).data[0].embedding\n",
    "    \n",
    "    return length, embedding\n",
    "\n",
    "wdi_series['token_length'], wdi_series['Embedding'] = zip(*wdi_series.apply(lambda row: create_embedding(row), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f53dfdb7-12dd-43cc-a860-d880ce8fdf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_series.to_pickle('../data/indicator_meta_embed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43470894-46b1-43a5-8680-3e3788a7c026",
   "metadata": {},
   "source": [
    "## Searching target indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e3b703a-57b3-493a-862c-8160d152acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/indicator_meta_embed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eab9be9-a94b-40cd-8c23-70efbb217489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Jaccard similarity between two texts\n",
    "def jaccard_similarity(text1, text2):\n",
    "    # Tokenize texts\n",
    "    tokens1 = set(text1.lower().split())\n",
    "    tokens2 = set(text2.lower().split())\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    intersection = len(tokens1.intersection(tokens2))\n",
    "    union = len(tokens1.union(tokens2))\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96a5e173-6a61-4a48-bb68-180e698e1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_indicators(user_query):\n",
    "    # Calculate similarity scores for each indicators\n",
    "    similarity_scores = []\n",
    "    indicators = []\n",
    "\n",
    "    # Iterate through each indicator title and calculate similarity score\n",
    "    for indicator in df['Indicator Name']:\n",
    "        similarity_score = jaccard_similarity(user_query, indicator)\n",
    "        similarity_scores.append(similarity_score)\n",
    "        indicators.append(indicator)\n",
    "        \n",
    "    # Create DataFrame only with valid similarity scores\n",
    "    similarity_df = pd.DataFrame({'Indicator Name': indicators, 'Similarity Score': similarity_scores})\n",
    "    similarity_df = similarity_df.sort_values('Similarity Score', ascending=False)\n",
    "    similarity_df = similarity_df[:10]\n",
    "        \n",
    "    # Filter indicators where similarity score is above a threshold (e.g., 0.3)\n",
    "    threshold = 0.01\n",
    "    filtered_df = df[df['Indicator Name'].isin(similarity_df[similarity_df['Similarity Score'] > threshold]['Indicator Name'])]\n",
    "\n",
    "    return  filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f51e73a-597b-41c1-a2e0-76d3fece207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search target indicator\n",
    "def search_embeddings(user_query):\n",
    "    df_filtered = filter_indicators(user_query) if filter_indicators(user_query) is not None else None\n",
    "    \n",
    "    if df_filtered is not None and not df_filtered.empty:  # Check if DataFrame is not None and not empty\n",
    "        length = len(df_filtered.head())\n",
    "        filtered_embeddings_arrays = np.array(list(df_filtered['Embedding']))\n",
    "        index = faiss.IndexFlatIP(filtered_embeddings_arrays.shape[1]) \n",
    "        index.add(filtered_embeddings_arrays)\n",
    "        \n",
    "        user_query_embedding = client.embeddings.create( \n",
    "                input=user_query ,model= embedding_model\n",
    "            ).data[0].embedding\n",
    "\n",
    "        k = min(5, length)\n",
    "        distances, indices = index.search(np.array([user_query_embedding]), k)\n",
    "        return df_filtered, distances, indices\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a55574-296e-41c0-845f-86d67f13be07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1524b-f814-4aaa-befb-97b878ef2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(user_query, content):\n",
    "    system_prompt = \"You are a system that answers user questions based on excerpts from word indicator documents provided for context. Only answer if the answer can be found in the provided context. Do not make up the answer; if you cannot find the answer, say so.\"\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_question},\n",
    "        {'role': 'user', 'content': content},\n",
    "    ]\n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0.2,\n",
    "                    messages=messages\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54971fae-ddcf-4caf-b0fe-1c3c6240f746",
   "metadata": {},
   "source": [
    "## Function for searching target period (1960 - 2023) ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a40d575b-c8ba-4ff5-baba-3002debe466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract set of years from given timex3_list\n",
    "def timex3_to_year_list(timex3_list):\n",
    "    year_list = set()\n",
    "    for timex3 in timex3_list:\n",
    "        sutimeType, value = timex3[\"type\"], timex3[\"value\"]\n",
    "        if \"REF\" not in value:\n",
    "            if isinstance(value, dict):\n",
    "                for year in range(int(value['begin']), int(value['end']) + 1):\n",
    "                    year_list.add(year)\n",
    "            elif value.isdigit():\n",
    "                year_list.add(int(value))\n",
    "            elif sutimeType in ['DATE', 'DURATION']:\n",
    "                if sutimeType == 'DATE':\n",
    "                    res = re.search('^\\d\\d\\d\\d', value)\n",
    "                    if res:\n",
    "                        year_list.add(int(res.group(0)))\n",
    "                else:\n",
    "                    year_dur = 0\n",
    "                    current_year = datetime.now().year\n",
    "                    dur_list = re.findall('\\d+', \"\".join(re.findall('P[0-9]+Y', value)))\n",
    "                    if dur_list:\n",
    "                        year_dur = max([int(y) for y in dur_list])\n",
    "                        while year_dur:\n",
    "                            year_list.add(current_year - year_dur)\n",
    "                            year_dur -= 1\n",
    "            else:\n",
    "                continue\n",
    "    print(year_list)\n",
    "    return year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "56c2e1fc-0840-46eb-b515-02ac8c12ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_period_timex3(user_query):\n",
    "    sutime = SUTime(mark_time_ranges = True, include_range = True)\n",
    "    res = sutime.parse(user_query)\n",
    "    return timex3_to_year_list(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4406f-5189-4a7f-9752-b377f40a8d07",
   "metadata": {},
   "source": [
    "## Final one function for searching indicator data (Function for finding info from indicator database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45b480-44fa-4fd7-b02a-83eda2cedab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_structure(countries, indicators, years):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e64e007e-c4cf-4876-a39a-361d31556c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## module to extract text from documents and return the text and document codes\n",
    "def indicatorsModule(user_query, client, embedding_model):\n",
    "    countries = find_mentioned_country_code(user_query)\n",
    "    indicators = filter_indicators(user_query) #df, distances, indices\n",
    "    years = find_target_period(user_query)\n",
    "    if countries and indicators and years:\n",
    "        result_structure = map_to_structure(countries, indicators, years)\n",
    "        return result_structure\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a638a0d-3eba-4225-8093-eb2dd44c4c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
