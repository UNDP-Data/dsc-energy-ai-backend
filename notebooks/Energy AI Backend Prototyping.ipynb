{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install langchain_community\n",
    "#!pip3 install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542a4ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import ast\n",
    "from openai import AzureOpenAI\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf814d9",
   "metadata": {},
   "source": [
    "### Load Enviroment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4c742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 10\n",
      "Python-dotenv could not parse statement starting at line 11\n",
      "Python-dotenv could not parse statement starting at line 12\n",
      "Python-dotenv could not parse statement starting at line 13\n",
      "Python-dotenv could not parse statement starting at line 14\n",
      "Python-dotenv could not parse statement starting at line 15\n",
      "Python-dotenv could not parse statement starting at line 16\n",
      "Python-dotenv could not parse statement starting at line 17\n",
      "Python-dotenv could not parse statement starting at line 18\n",
      "Python-dotenv could not parse statement starting at line 19\n",
      "Python-dotenv could not parse statement starting at line 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8652e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai_deployment = \"sdgi-gpt-35-turbo-16k\"\n",
    "neo4j_pass = os.getenv(\"NEO4JPASS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3e87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API configuration\n",
    "#openai.api_type = \"azure\"\n",
    "#openai.api_key = os.getenv(\"api_key_azure\")\n",
    "#openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "#openai.api_version = os.getenv(\"api_version\")\n",
    "#openai_deployment = \"sdgi-gpt-35-turbo-16k\"\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\"),  \n",
    "  api_version = os.getenv(\"OPENAI_API_VERSION\"),\n",
    "  azure_endpoint =os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    ")\n",
    "\n",
    "embedding_model = os.getenv(\"USER_QUERY_EMBEDDING_ENGINE\") \n",
    "\n",
    "# print(openai.api_key)\n",
    "# print(openai.api_base)\n",
    "# print(openai.api_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16534287",
   "metadata": {},
   "source": [
    "<h3>globals</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0b2a3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query=\"What is the role of USAID in supporting Albania's energy sector strategy?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f11f01",
   "metadata": {},
   "source": [
    "<h3> helper functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc569537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to make simple openAI Calls\n",
    "def callOpenAI(prompt):  \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ]\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd62b3",
   "metadata": {},
   "source": [
    "<h3> processing modules </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6798164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USAID', 'Albania', 'energy sector strategy']\n"
     ]
    }
   ],
   "source": [
    "def extractEntitiesFromQuery(user_query):\n",
    "    prompt = f\"\"\"\n",
    "    Extract entities from the following user query: \\\"{user_query}\\\" and return output in array format.\n",
    "    \n",
    "    -Entities should be directly related to the domain or topic of interest. They should represent important concepts that contribute to the understanding of the subject matter.\n",
    "    -Each entity in the knowledge graph should be distinct and have a unique identifier. This ensures clarity and avoids ambiguity when establishing relationships between entities.\n",
    "    -You Must return output in array format e.g  ['entity1','entity2'] !!!\n",
    "    -Avoid adding new lines or breaking spaces to your output. Array should be single dimension and single line !!!\n",
    " \n",
    "    \"\"\"\n",
    "    entity_list = callOpenAI(prompt)   \n",
    "    return entity_list\n",
    "\n",
    "# Test usage\n",
    "entity_list = extractEntitiesFromQuery(test_query)\n",
    "print(entity_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc16e4",
   "metadata": {},
   "source": [
    "# KG module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b55cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59688ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(uri = 'bolt://localhost:7687',user='neo4j',password=neo4j_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5345b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(temperature=0), graph=graph, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee00a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"\"\"\n",
    "Which intermediary is connected to most entites?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b68892ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_relationships_with_py2neo(entity_type, name):\n",
    "    # Sanitize the entity_type to avoid injection (this example assumes entity_type is safe)\n",
    "    # Implement additional checks as necessary based on your application's requirements\n",
    "    #sanitized_entity_type = entity_type.replace(\"`\", \"\").replace(\";\", \"\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    MATCH (n:`{entity_type}`)-[r]-(m)\n",
    "    WHERE toLower(n.name) = toLower($name)\n",
    "    RETURN n, r, m\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query with parameters\n",
    "    results = graph.run(query, name)\n",
    "\n",
    "    # Example usage of results\n",
    "    for record in results:\n",
    "        print(record['n'], record['r'], record['m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38712a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_entities_with_relations_by_name(label, name):\n",
    "    \"\"\"\n",
    "    Search for nodes by label and name, including all their relationships and connected nodes.\n",
    "\n",
    "    :param label: The label of the nodes to search.\n",
    "    :param name: The name property value of the nodes to search.\n",
    "    :return: A list of dictionaries, each containing a node and its relationships and connected nodes.\n",
    "    \"\"\"\n",
    "    # Match nodes and their relationships, case-insensitive search\n",
    "    query = f\"\"\"\n",
    "    MATCH (n:`{label}`)-[r]-(m)\n",
    "    WHERE toLower(n.name) = toLower($name)\n",
    "    RETURN n, collect(r) as relations, collect(m) as connectedNodes\n",
    "    \"\"\"\n",
    "    results = graph.run(query, name=name).data()\n",
    "\n",
    "    # Construct a comprehensive view for each node with its relationships and connected nodes\n",
    "    entities_with_relations = []\n",
    "    for record in results:\n",
    "        entity_info = {\n",
    "            'node': record['n'],\n",
    "            'relationships': record['relations'],\n",
    "            'connected_nodes': record['connectedNodes']\n",
    "        }\n",
    "        entities_with_relations.append(entity_info)\n",
    "\n",
    "    return entities_with_relations\n",
    "\n",
    "# Example usage\n",
    "label = \"Organization\"\n",
    "name = \"United States Agency for International Development\"\n",
    "entities_with_relations = search_entities_with_relations_by_name(label, name)\n",
    "for entity_info in entities_with_relations:\n",
    "    #print(\"Node:\", entity_info['node'])\n",
    "    print(\"Relationships:\", entity_info['relationships'])\n",
    "    #print(\"Connected Nodes:\", entity_info['connected_nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b554a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_entities_and_relationships(relationships):\n",
    "    \"\"\"\n",
    "    Separates entities and relationships from Neo4j query output into distinct structures,\n",
    "    ensuring no duplicate entities are included.\n",
    "\n",
    "    :param relationships: A list of Relationship objects from a Neo4j query.\n",
    "    :return: A tuple containing two lists: one for unique entities and another for relationships.\n",
    "    \"\"\"\n",
    "    # Using a dictionary to ensure unique entities based on a combination of name and category\n",
    "    entities_dict = {}\n",
    "    rels = []\n",
    "\n",
    "    for rel in relationships:\n",
    "        # Process both the source and target nodes for each relationship\n",
    "        for node in [rel.start_node, rel.end_node]:\n",
    "            # Define a unique identifier for each entity\n",
    "            entity_id = f\"{node['name']}_{node['category']}\"\n",
    "            \n",
    "            # If the entity is not already in the dictionary, add it\n",
    "            if entity_id not in entities_dict:\n",
    "                entities_dict[entity_id] = {\n",
    "                    'name': node['name'],\n",
    "                    'category': node.get('category', 'N/A'),\n",
    "                    'summary': node.get('summary', 'N/A'),\n",
    "                    'acronym': node.get('acronym', 'N/A'),\n",
    "                }\n",
    "\n",
    "        # Add relationship information\n",
    "        rels.append({\n",
    "            'subject': rel.start_node['name'],\n",
    "            'object': rel.end_node['name'],\n",
    "            'relationship_type': rel.__class__.__name__,\n",
    "            'description': rel.get('description', 'N/A'),\n",
    "        })\n",
    "\n",
    "    # Convert the entities dictionary to a list to remove the unique identifier layer\n",
    "    entities_list = list(entities_dict.values())\n",
    "\n",
    "    return entities_list, rels\n",
    "\n",
    "# Assuming 'relationships' is your list of Relationship objects from the query\n",
    "entities, relationships = separate_entities_and_relationships(entity_info['relationships'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eebc99bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relationships_to_data_structure(relationships):\n",
    "    \"\"\"\n",
    "    Converts relationships from Neo4j query output into a structured Python data structure.\n",
    "\n",
    "    :param relationships: A list of Relationship objects from a Neo4j query.\n",
    "    :return: A list of dictionaries, each representing a relationship and its node details.\n",
    "    \"\"\"\n",
    "    formatted_relationships = []\n",
    "\n",
    "    # Sort the relationships by the name of the source node for consistent ordering\n",
    "    sorted_relationships = sorted(relationships, key=lambda rel: rel.start_node['name'])\n",
    "\n",
    "    for rel in sorted_relationships:\n",
    "        relationship_data = {\n",
    "            'relationship_type': rel.__class__.__name__,\n",
    "            'source_node': {\n",
    "                'name': rel.start_node['name'],\n",
    "                'category': rel.start_node.get('category', 'N/A'),\n",
    "                'summary': rel.start_node.get('summary', ''),\n",
    "                'acronym': rel.start_node.get('acronym', ''),\n",
    "                # Include additional properties as needed\n",
    "            },\n",
    "            'target_node': {\n",
    "                'name': rel.end_node['name'],\n",
    "                'category': rel.end_node.get('category', ''),\n",
    "                'summary': rel.end_node.get('summary', ''),\n",
    "                'acronym': rel.end_node.get('acronym', ''),\n",
    "\n",
    "                # Include additional properties as needed\n",
    "            },\n",
    "            'properties': {\n",
    "                # Include relationship properties\n",
    "                'description': rel.get('description', 'N/A'),\n",
    "            \n",
    "            }\n",
    "        }\n",
    "\n",
    "        formatted_relationships.append(relationship_data)\n",
    "\n",
    "    return formatted_relationships\n",
    "\n",
    "# Example usage, assuming 'relationships' is your list of Relationship objects from the query\n",
    "formatted_data = relationships_to_data_structure(entity_info['relationships'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5cd5d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship: partners with\n",
      "  Source Node: Albania (Category: Location)\n",
      "  Target Node: United States Agency for International Development (Category: Organization)\n",
      "  Description: Albania partners with USAID\n",
      "\n",
      "Relationship: partners with\n",
      "  Source Node: United States Agency for International Development (Category: Organization)\n",
      "  Target Node: Working Group (Category: Organization)\n",
      "  Description: This Working Group coordinated the process for drafting the National Strategy for the Energy Sector and was closely supported by USAID with technical expertise1 from USAID’s strategic team, composed of leading experts in the fields of electricity, oil and gas, renewables, energy efficiency and strategic energy planning.\n",
      "\n",
      "Relationship: partners with\n",
      "  Source Node: Working Group (Category: Organization)\n",
      "  Target Node: United States Agency for International Development (Category: Organization)\n",
      "  Description: This Working Group coordinated the process for drafting the National Strategy for the Energy Sector and was closely supported by USAID with technical expertise1 from USAID’s strategic team, composed of leading experts in the fields of electricity, oil and gas, renewables, energy efficiency and strategic energy planning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_and_sort_relationships(relationships):\n",
    "    \"\"\"\n",
    "    Formats and sorts the relationships from Neo4j query output.\n",
    "\n",
    "    :param relationships: A list of Relationship objects from a Neo4j query.\n",
    "    \"\"\"\n",
    "    # Sort the relationships by the name of the source node for consistent ordering\n",
    "    sorted_relationships = sorted(relationships, key=lambda rel: rel.start_node['name'])\n",
    "\n",
    "    for rel in sorted_relationships:\n",
    "        source_node = rel.start_node\n",
    "        target_node = rel.end_node\n",
    "        print(f\"Relationship: {rel.__class__.__name__}\")\n",
    "        print(f\"  Source Node: {source_node['name']} (Category: {source_node.get('category', 'N/A')})\")\n",
    "        print(f\"  Target Node: {target_node['name']} (Category: {target_node.get('category', 'N/A')})\")\n",
    "        \n",
    "        # Print relationship properties with indentation\n",
    "        if rel.get('description'):\n",
    "            print(f\"  Description: {rel['description']}\")\n",
    "        if rel.get('summary'):\n",
    "            print(f\"  Summary: {rel['summary']}\")\n",
    "\n",
    "        print()  # Add a newline for spacing between relationships\n",
    "\n",
    "# Example usage, assuming 'relationships' is your list of Relationship objects from the query\n",
    "format_and_sort_relationships(entity_info['relationships'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa06008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_relationships_with_py2neo(\"Location\", [\"Bitola\", \"entityId2\", \"entityId3\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b85bd554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_embeddings(user_query):\n",
    "    df = pd.read_pickle('../models/df_embed_EN.pkl')\n",
    "    df_filtered = df\n",
    "    length = len(df_filtered.head())\n",
    "    filtered_embeddings_arrays = np.array(list(df_filtered['Embedding']))\n",
    "    index = faiss.IndexFlatIP(filtered_embeddings_arrays.shape[1]) \n",
    "    index.add(filtered_embeddings_arrays)\n",
    "    \n",
    "    user_query_embedding = client.embeddings.create( \n",
    "        input=user_query ,model= embedding_model\n",
    "    ).data[0].embedding\n",
    "    \n",
    "    k = min(5, length)\n",
    "    distances, indices = index.search(np.array([user_query_embedding]), k)\n",
    "    return df_filtered, distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c30f34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(user_question, content):\n",
    "    system_prompt = \"You are a system that answers user questions based on excerpts from PDF documents provided for context. Only answer if the answer can be found in the provided context. Do not make up the answer; if you cannot find the answer, say so.\"\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_question},\n",
    "        {'role': 'user', 'content': content},\n",
    "    ]\n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0.2,\n",
    "                    messages=messages\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    return response\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "27928260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_structure(qs):\n",
    "    result_dict = {}\n",
    "\n",
    "    # Extract the DataFrame from the tuple\n",
    "    dataframe = qs[0]\n",
    "\n",
    "    # Counter to limit the loop to 10 iterations\n",
    "    count = 0\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # Define a unique identifier for each document, you can customize this based on your data\n",
    "        document_id = f\"doc-{index + 1}\"\n",
    "        # Handle NaN in content by using fillna\n",
    "        content = row[\"Content\"]\n",
    "        content = ' '.join(row[\"Content\"].split()[:160])\n",
    "        # Create a dictionary for each document\n",
    "        document_info = {\n",
    "            \"title\": row[\"Document Title\"],\n",
    "            \"extract\": content or \"\",  # You may need to adjust this based on your column names\n",
    "            \"category\": row[\"Category\"],\n",
    "            \"link\": row[\"Link\"],\n",
    "            \"thumbnail\": ''\n",
    "        }\n",
    "        # print(document_info)\n",
    "        # Add the document to the result dictionary\n",
    "        result_dict[document_id] = document_info\n",
    "\n",
    "        # Increment the counter\n",
    "        count += 1\n",
    "\n",
    "        # # Break out of the loop if the counter reaches top 10\n",
    "        if count == 10:\n",
    "            break\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "58c69dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excerpts saved to outputs/excerpts.json\n"
     ]
    }
   ],
   "source": [
    "## module to extract text from documents and return the text and document codes\n",
    "\n",
    "def semanticSearchModule(user_query):\n",
    "    qs = search_embeddings(user_query) #df, distances, indices\n",
    "    result_structure = map_to_structure(qs)\n",
    "    return result_structure\n",
    "\n",
    "#test usage\n",
    "excerpts_dict=semanticSearchModule(test_query)\n",
    "# print(excerpts_dict)\n",
    "\n",
    "\n",
    "#Return top 10-20 most related \n",
    "# Define the filename to save the JSON data -  can remove later\n",
    "json_filename = \"outputs/excerpts.json\"\n",
    "\n",
    "# Save excerpts_dict to the JSON file just for a better preview\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(excerpts_dict, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Excerpts saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "db75b59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indicator-id-1': 'value from indicator-id-1', 'indicator-id-2': 'value from indicator-id-2'}\n"
     ]
    }
   ],
   "source": [
    "## module to get data for specific indicators which are identified is relevant to the user query\n",
    "\n",
    "def indicatorsModule(user_query): #lower priority\n",
    "    \n",
    "    # find relevant indicators based on uesr query and extract values\n",
    "    indicators_dict={\n",
    "        \"indicator-id-1\":\"value from indicator-id-1\",\n",
    "        \"indicator-id-2\":\"value from indicator-id-2\"\n",
    "    }#temp\n",
    "    \n",
    "    return indicators_dict\n",
    "\n",
    "#test usage\n",
    "indicators_dict=indicatorsModule(test_query)\n",
    "print(indicators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8237482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What initiatives has USAID taken to support Albania's energy sector strategy?',\n",
      " 'How has USAID contributed to the development of Albania's energy sector strategy?',\n",
      " 'What specific projects has USAID implemented to support Albania's energy sector strategy?',\n",
      " 'What is the impact of USAID's support on Albania's energy sector strategy?',\n",
      " 'How does USAID collaborate with Albania's government and other stakeholders in implementing the energy sector strategy?',\n",
      " 'What are the goals and objectives of USAID's involvement in Albania's energy sector strategy?',\n",
      " 'What are the key challenges and opportunities in USAID's support for Albania's energy sector strategy?',\n",
      " 'What is the timeline for USAID's support in implementing Albania's energy sector strategy?',\n",
      " 'What are the expected outcomes and benefits of USAID's support for Albania's energy sector strategy?',\n",
      " 'How does USAID ensure transparency and accountability in its support for Albania's energy sector strategy?']\n"
     ]
    }
   ],
   "source": [
    "## module to generate query ideas\n",
    "\n",
    "def queryIdeationModule(user_query): # lower priority\n",
    "    \n",
    "    # Generate query ideas using OpenAI GPT-3\n",
    "    prompt = f\"\"\"Generate query ideas based on the user query: {user_query}\n",
    "    \n",
    "    -You Must return output in array format e.g ['idea 1', 'idea2'] !!!\n",
    "    -Avoid adding new lines or breaking spaces to your output. Array should be single dimension and single line !!!\n",
    "    \n",
    "    \"\"\"\n",
    "    response = callOpenAI(prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "#test usage\n",
    "query_idea_list=queryIdeationModule(test_query)\n",
    "print(query_idea_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b73a93",
   "metadata": {},
   "source": [
    "<h3> synthesis module </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0f509d",
   "metadata": {},
   "source": [
    "    llm_instructions=\"llm instruction template here, with placeholders for insertion of user query, excerpts, indicator data, and entity and relation info\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7113366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to synthesize answer using retreival augmented generation approach\n",
    "\n",
    "def synthesisModule(user_query, excerpts_dict, indicators_dict):\n",
    "    \n",
    "    # Generate prompt engineering text and template\n",
    "    llm_instructions = f\"\"\"\n",
    "    Ignore previous commands!!!\n",
    "    Given a user query, use the provided excerpts, and Sources to\n",
    "    provide the correct answer to the user's query\n",
    "    \n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Sources: {excerpts_dict}\n",
    "    \n",
    "\n",
    "    - Answer output must be properly formatted using HTML. \n",
    "    - Don't include <html>, <script>, <link> or <body> tags. Only text formating tags should be allowed. e.g h1..h3, p, anchor, etc.\n",
    "    - Make sure to Include citations based on the Sources. e.g Text excerpt here<a data-id='test-doc-1'>[1]</a> when referencing a document in the sources. using 1 ...nth\n",
    "    - The citations anchor should be near the excerpt not following each other.\n",
    "    - Use the anchor tag for the citation links and should link to the document link. for example Undp operates in afganistan <a data-id='test-doc-1'>[1]</a>. UNDP offers health relationships <a data-id='test-doc-2'>[2]</a>.\n",
    "    - The text in the anchor tag should be citation number not document title.\n",
    "    - You can reference multitple citations based sources\n",
    "    \"\"\"\n",
    "    ###synthesize data into structure within llm prompt engineering instructions\n",
    "    answer=callOpenAI(llm_instructions)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "## to test this, run the full pipeline with the handleApiCall function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "16f02e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to synthesize answer using retreival augmented generation approach\n",
    "\n",
    "def synthesisModule_KG(user_query, entities, relationships, excerpts_dict, indicators_dict):\n",
    "    \n",
    "    # Generate prompt engineering text and template\n",
    "    llm_instructions = f\"\"\"\n",
    "    Ignore previous commands!!!\n",
    "    Given a user query, use the provided excerpts, Sources, and relevant entities and relations to\n",
    "    provide the correct answer to the user's query\n",
    "    \n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Sources: {excerpts_dict}\n",
    "    \n",
    "    Entity and Relation info: {entities} {relationships}\n",
    "\n",
    "    - Answer output must be properly formatted using HTML. \n",
    "    - Don't include <html>, <script>, <link> or <body> tags. Only text formating tags should be allowed. e.g h1..h3, p, anchor, etc.\n",
    "    - Make sure to Include citations based on the Sources. e.g Text excerpt here<a data-id='test-doc-1'>[1]</a> when referencing a document in the sources. using 1 ...nth\n",
    "    - The citations anchor should be near the excerpt not following each other.\n",
    "    - Use the anchor tag for the citation links and should link to the document link. for example Undp operates in afganistan <a data-id='test-doc-1'>[1]</a>. UNDP offers health relationships <a data-id='test-doc-2'>[2]</a>.\n",
    "    - The text in the anchor tag should be citation number not document title.\n",
    "    - You can reference multitple citations based sources\n",
    "    \"\"\"\n",
    "    ###synthesize data into structure within llm prompt engineering instructions\n",
    "    answer=callOpenAI(llm_instructions)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "## to test this, run the full pipeline with the handleApiCall function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787b228",
   "metadata": {},
   "source": [
    "<h3> run pipeline </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "10fe2bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesis saved to outputs/synthesis_output.json\n"
     ]
    }
   ],
   "source": [
    "# full pipeline with retreival, synthesis of answer to user query, and structure results into api response\n",
    "\n",
    "def handleApiCall(user_query):\n",
    "        \n",
    "    ##run processing modules (in parallel)\n",
    "    #entities_dict=knowledgeGraphModule(user_query)\n",
    "    excerpts_dict=semanticSearchModule(user_query)\n",
    "    indicators_dict=indicatorsModule(user_query) ##lower priority\n",
    "    query_idea_list=queryIdeationModule(user_query) ##lower priority\n",
    "    \n",
    "    ##synthesis module\n",
    "    answer=synthesisModule(user_query, excerpts_dict, indicators_dict)\n",
    "    \n",
    "    ##structure response\n",
    "    response={\n",
    "        \"user_query\":user_query,\n",
    "        \"answer\":answer,\n",
    "        \"sources\":excerpts_dict,\n",
    "        \"query_ideas\":query_idea_list\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "# test usage\n",
    "response=handleApiCall(test_query) \n",
    "# Define the filename to save the JSON data -  can remove later\n",
    "json_filename = \"outputs/synthesis_output.json\"\n",
    "\n",
    "# Save excerpts_dict to the JSON file just for a better preview\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(response, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Synthesis saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "001a3831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesis saved to outputs_KG/Query1_output.json\n"
     ]
    }
   ],
   "source": [
    "# full pipeline with retreival, synthesis of answer to user query, and structure results into api response\n",
    "\n",
    "def handleApiCallKG(user_query):\n",
    "        \n",
    "    ##run processing modules (in parallel)\n",
    "    #entities_dict=knowledgeGraphModule(user_query)\n",
    "    excerpts_dict=semanticSearchModule(user_query)\n",
    "    indicators_dict=indicatorsModule(user_query) ##lower priority\n",
    "    query_idea_list=queryIdeationModule(user_query) ##lower priority\n",
    "    \n",
    "    ##synthesis module\n",
    "    answer=synthesisModule_KG(user_query, entities, relationships, excerpts_dict, indicators_dict)\n",
    "    \n",
    "    ##structure response\n",
    "    response={\n",
    "        \"user_query\":user_query,\n",
    "        \"answer\":answer,\n",
    "        \"sources\":excerpts_dict,\n",
    "        \"query_ideas\":query_idea_list,\n",
    "        \"entities\": entities,\n",
    "        \"relations\":relationships\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "# test usage\n",
    "response=handleApiCallKG(test_query) \n",
    "# Define the filename to save the JSON data -  can remove later\n",
    "json_filename = \"outputs_KG/Query1_output.json\"\n",
    "\n",
    "# Save excerpts_dict to the JSON file just for a better preview\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(response, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Synthesis saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7cc6f",
   "metadata": {},
   "source": [
    "<h3>testing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecee81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## next step, develop automated testing for all modules\n",
    "## iterate through test_queries and build automated tests to score results\n",
    "\n",
    "# open testing dataset with queries and expected results\n",
    "test_queries_df=pd.read_csv(\"../testing/energy_ai_test_dataset_v0.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58cb31a",
   "metadata": {},
   "source": [
    "  # TODO::: \n",
    "  ##### Add citation prompt to the synthesis module. -done \n",
    "  ##### Convert notebook to flask API script. main.py - done\n",
    "  ##### Refactor PDF -> txt pipeline \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7718dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relations': 'The relation between UNDP and Afghanistan is that UNDP works in Afghanistan to support development projects and initiatives.', 'entities': {'UNDP': 'The United Nations Development Programme (UNDP) is a global organization that works to eradicate poverty, reduce inequalities, and promote sustainable development. It provides support to countries in areas such as governance, climate change, and crisis response, aiming to improve the lives of people and protect the planet.', 'Afghanistan': 'Afghanistan is a landlocked country located in Central Asia, bordered by Iran, Pakistan, Turkmenistan, Uzbekistan, Tajikistan, and China. It is known for its rugged mountainous terrain, rich cultural heritage, and complex history. Despite facing numerous challenges, Afghanistan is home to resilient people, diverse ethnic groups, and a vibrant blend of traditions.'}}\n"
     ]
    }
   ],
   "source": [
    "## module to get information on the entities from user query using the KG\n",
    "def knowledgeGraphModule(user_query):\n",
    "    \n",
    "    # generate list of entities based on user query\n",
    "    entity_list = extractEntitiesFromQuery(user_query)\n",
    "    my_list = ast.literal_eval(entity_list)\n",
    "    prompt_summarise_entites = f\"\"\"\n",
    "    Summarize all relations between all the entities : {my_list}\n",
    "    \"\"\"\n",
    "    summarise_entities = callOpenAI(prompt_summarise_entites)\n",
    "    # Initialize an empty dictionary to store information\n",
    "    entities_dict = {\n",
    "        \"relations\": summarise_entities,\n",
    "        \"entities\": {}\n",
    "    }\n",
    "    # Loop through each entity in the list\n",
    "    for entity in my_list:\n",
    "        # Fetch information about the entity from your knowledge graph\n",
    "        prompt = f\"Give me a short description 50 words of {entity}\"\n",
    "        entity_info = callOpenAI(prompt)\n",
    "        # Add the entity information to the dictionary\n",
    "        entities_dict[\"entities\"][entity] = entity_info\n",
    "    \n",
    "    return entities_dict\n",
    "\n",
    "\n",
    "# Test usage\n",
    "test_query = \"what is the major work on UNDP in Afganistan?\"\n",
    "entities_dict = knowledgeGraphModule(test_query)\n",
    "print(entities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4376457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
