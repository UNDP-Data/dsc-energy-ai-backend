{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542a4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.0.0) was trained with spaCy v3.0.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import ast\n",
    "from openai import AzureOpenAI\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import pycountry\n",
    "import re\n",
    "from bert_score import score as bert_score\n",
    "import csv\n",
    "import transformers\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fdd010",
   "metadata": {},
   "source": [
    "### Load Model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ecc76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../models/df_embed_EN_All_V3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf814d9",
   "metadata": {},
   "source": [
    "### Load Enviroment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4c742f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3e87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API configuration\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"api_key_azure\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"api_version\")\n",
    "openai_deployment = \"sdgi-gpt-35-turbo-16k\"\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"api_key_azure\"),  \n",
    "  api_version = os.getenv(\"api_version\"),\n",
    "  azure_endpoint =os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    ")\n",
    "\n",
    "embedding_model = os.getenv(\"USER_QUERY_EMBEDDING_ENGINE\") \n",
    "\n",
    "# print(openai.api_key)\n",
    "# print(openai.api_base)\n",
    "# print(openai.api_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16534287",
   "metadata": {},
   "source": [
    "<h3>globals</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2a3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_query=\"What are the sustainable energy priorities for UNDP?\"\n",
    "test_query = 'What is the Human Development Index (HDI) value for Albania as mentioned in the document?'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f11f01",
   "metadata": {},
   "source": [
    "<h3> helper functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc569537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to make simple openAI Calls\n",
    "def callOpenAI(prompt):  \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ]\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd62b3",
   "metadata": {},
   "source": [
    "<h3> processing modules </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6798164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEntitiesFromQuery(user_query):\n",
    "    prompt = f\"\"\"\n",
    "    Extract entities from the following user query: \\\"{user_query}\\\" and return output in array format.\n",
    "    \n",
    "    -Entities should be directly related to the domain or topic of interest. They should represent important concepts that contribute to the understanding of the subject matter.\n",
    "    -Each entity in the knowledge graph should be distinct and have a unique identifier. This ensures clarity and avoids ambiguity when establishing relationships between entities.\n",
    "    -You Must return output in array format e.g  ['entity1','entity2'] !!!\n",
    "    -Avoid adding new lines or breaking spaces to your output. Array should be single dimension and single line !!!\n",
    " \n",
    "    \"\"\"\n",
    "    entity_list = callOpenAI(prompt)   \n",
    "    return entity_list\n",
    "\n",
    "# Test usage\n",
    "# test_query = \"What are the sustainable energy for UNDP?\"\n",
    "# entity_list = extractEntitiesFromQuery(test_query)\n",
    "# print(entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7718dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relations': 'The Paris Agreement is related to sustainable energy development.', 'entities': {'Paris Agreement': \"The Paris Agreement is an international treaty adopted in 2015 by nearly every country in the world. Its goal is to combat climate change by limiting global warming to well below 2 degrees Celsius above pre-industrial levels. It promotes cooperation, transparency, and regular updates of countries' efforts to reduce greenhouse gas emissions.\", 'sustainable energy development': 'Sustainable energy development refers to the process of harnessing and utilizing renewable energy sources in a manner that minimizes environmental impact and promotes long-term viability. It involves the adoption of clean technologies, such as solar, wind, and hydro power, to meet energy needs while reducing greenhouse gas emissions and preserving natural resources.'}}\n"
     ]
    }
   ],
   "source": [
    "## module to get information on the entities from user query using the KG\n",
    "def knowledgeGraphModule(user_query):\n",
    "    \n",
    "    # generate list of entities based on user query\n",
    "    entity_list = extractEntitiesFromQuery(user_query)\n",
    "    my_list = ast.literal_eval(entity_list)\n",
    "    prompt_summarise_entites = f\"\"\"\n",
    "    Summarize all relations between all the entities : {my_list}\n",
    "    \"\"\"\n",
    "    summarise_entities = callOpenAI(prompt_summarise_entites)\n",
    "    # Initialize an empty dictionary to store information\n",
    "    entities_dict = {\n",
    "        \"relations\": summarise_entities,\n",
    "        \"entities\": {}\n",
    "    }\n",
    "    # Loop through each entity in the list\n",
    "    for entity in my_list:\n",
    "        # Fetch information about the entity from your knowledge graph\n",
    "        prompt = f\"Give me a short description 50 words of {entity}\"\n",
    "        entity_info = callOpenAI(prompt)\n",
    "        # Add the entity information to the dictionary\n",
    "        entities_dict[\"entities\"][entity] = entity_info\n",
    "    \n",
    "    return entities_dict\n",
    "\n",
    "\n",
    "# Test usage\n",
    "test_query = \"What is the role of Paris Agreement in sustainable energy development?\"\n",
    "entities_dict = knowledgeGraphModule(test_query)\n",
    "print(entities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c65c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_mentioned_countries(text):\n",
    "    countries = set()\n",
    "    \n",
    "    # Tokenize the text using regular expressions to preserve punctuation marks\n",
    "    words = re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "    text = ' '.join(words)  # Join the tokens back into a string\n",
    "    \n",
    "    for word in text.split():\n",
    "        try:\n",
    "            country = pycountry.countries.get(name=word) #pycountry.countries.lookup(word)\n",
    "            if country != None : \n",
    "               countries.add(country.name)\n",
    "        except LookupError:\n",
    "            pass\n",
    "    \n",
    "    return list(countries)\n",
    "\n",
    "# Example \n",
    "# user_query = 'Give me a summary of the goals UNDP wants to achieve in 10 years and the energy plans for Philippines and Angola'\n",
    "# mentioned_countries = find_mentioned_countries(user_query)\n",
    "# mentioned_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee0a9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the English language model\n",
    "# Function to calculate the average word embedding for a sentence\n",
    "def average_word_embedding(sentence):\n",
    "    # Parse the sentence using SpaCy\n",
    "    doc = nlp(sentence)\n",
    "    # Get word vectors and average them\n",
    "    word_vectors = [token.vector for token in doc if token.has_vector]\n",
    "    if not word_vectors:\n",
    "        return None\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Function to calculate context similarity between two sentences using word embedding averaging\n",
    "def calculate_context_similarity(sentence1, sentence2):\n",
    "    # Get average word embeddings for each sentence\n",
    "    avg_embedding1 = average_word_embedding(sentence1)\n",
    "    avg_embedding2 = average_word_embedding(sentence2)\n",
    "    if avg_embedding1 is None or avg_embedding2 is None:\n",
    "        return None\n",
    "    # Calculate cosine similarity between the embeddings\n",
    "    similarity = cosine_similarity([avg_embedding1], [avg_embedding2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# # Example sentences\n",
    "# sentence1 = 'The companys quarterly earnings report exceeded expectations, leading to a surge in stock prices.'\n",
    "# sentence2 = 'The firms financial results for the last quarter surpassed predictions, resulting in a sharp rise in the value of shares'\n",
    "\n",
    "\n",
    "\n",
    "# Calculate context similarity\n",
    "# similarity = calculate_context_similarity(sentence1, sentence2)\n",
    "# print(\"Context similarity:\", similarity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d626cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Jaccard similarity between two texts\n",
    "def jaccard_similarity(text1, text2):\n",
    "    # Tokenize texts\n",
    "    tokens1 = set(text1.lower().split())\n",
    "    tokens2 = set(text2.lower().split())\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    intersection = len(tokens1.intersection(tokens2))\n",
    "    union = len(tokens1.union(tokens2))\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50651a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_contains_entity(entity, title):\n",
    "    # Convert both entity and title to lowercase for case-insensitive comparison\n",
    "    entity_lower = entity.lower()\n",
    "    title_lower = title.lower()\n",
    "\n",
    "    # Check if the lowercase entity is contained within the lowercase title\n",
    "    if entity_lower in title_lower:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79226e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This contains all filters for the semantic search\n",
    "#Context Similarity takes two queries and find how similar they are \"context wise\"\n",
    "#E.g \"My house is empty today\" and \"Nobody is at my home\" are same context but not word similarity\n",
    "# - Filter country relevant documents when mentioned \n",
    "# - Filter by Context similarity in user_query and title, journal, content etc.\n",
    "\n",
    "def filter_semantics(user_query):\n",
    "\n",
    "    #Allow parallels\n",
    "    #Extract notable entities in query e.g ORG, NAME, Place, country, location etc.\n",
    "    #Location related: \n",
    "    # GPE: Countries, cities, states.\n",
    "    # NORP: Nationalities, religious and political groups.\n",
    "    # LANGUAGE: Any named language. \n",
    "    # FAC: Buildings, airports, highways, bridges, etc.\n",
    "\n",
    "    #Other/General:\n",
    "    # PERSON: People, including fictional entities.\n",
    "    # ORG: Companies, agencies, institutions, etc.\n",
    "    # LOC: Non-GPE locations, mountain ranges, bodies of water.\n",
    "    # PRODUCT: Objects, vehicles, foods, etc. (Not services)\n",
    "    # EVENT: Named hurricanes, battles, wars, sports events, etc.\n",
    "    # WORK_OF_ART: Titles of books, songs, etc.\n",
    "    # LAW: Named documents made into laws.\n",
    "    # LANGUAGE: Any named language.\n",
    "    # DATE: Absolute or relative dates or periods.\n",
    "    # TIME: Times smaller than a day.\n",
    "    # PERCENT: Percentage, including \"%\".\n",
    "    # MONEY: Monetary values, including unit.\n",
    "    # QUANTITY: Measurements, as numerical values with units.\n",
    "    # ORDINAL: \"first\", \"second\", etc.\n",
    "    # CARDINAL: Numerals that do not fall under another type.\n",
    "    \n",
    "    doc = nlp(user_query)\n",
    "    # Extract all entities\n",
    "    # entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ != \"\"]  # Filter out empty entities\n",
    "    entities.extend((token.text, \"NOUN\") for token in doc if token.pos_ in [\"NOUN\",\"PROPN\", \"PRON\", \"PROPN\", \"NUM\", \"SYM\", \"X\",\"ABBR\"] or token.is_alpha)\n",
    "\n",
    "    # Remove stop words\n",
    "    entities = [(entity, label) for entity, label in entities if entity.lower() not in STOP_WORDS]\n",
    "    \n",
    "    # Print the extracted entities\n",
    "    # print(\"All Entities and POS:\", entities)\n",
    "    # Generate DFs for main entities\n",
    "    filtered_df_country = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "    filtered_df_others = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "    filtered_df_backup_reference = pd.DataFrame() # Initialize an empty DataFrame\n",
    "    allow_low = True\n",
    "\n",
    "    for entity, label in entities:\n",
    "        # print(entity)\n",
    "        filtered_df_others = pd.concat([filtered_df_others, df[df['Document Title'].str.lower().str.contains(entity.lower(), na=False)]])\n",
    "\n",
    "        #Calculate similarity scores for each document title\n",
    "        similarity_scores = []\n",
    "        document_titles = []\n",
    "\n",
    "        # Iterate through each document title and calculate similarity score\n",
    "        for title in filtered_df_others['Document Title']:\n",
    "            if title is not None:\n",
    "                similarity_score = calculate_context_similarity(user_query,title) \n",
    "                # print(entity)\n",
    "                # print(similarity_score)\n",
    "                # print(user_query)\n",
    "                # print(title)\n",
    "                # print(\"=================================\")    \n",
    "                similarity_scores.append(similarity_score)\n",
    "                document_titles.append(title)\n",
    "        \n",
    "        # Create DataFrame only with valid similarity scores\n",
    "        similarity_df = pd.DataFrame({'Document Title': document_titles, 'Similarity Score': similarity_scores})\n",
    "        \n",
    "        df_temp = pd.concat([df])\n",
    "        \n",
    "        threshold = 0.5\n",
    "\n",
    "        # Filter df based on similarity scores greater than threshold for filtered_df_others\n",
    "        filtered_df_others = df[df['Document Title'].isin(similarity_df[similarity_df['Similarity Score'] > threshold]['Document Title'])]\n",
    "        filtered_df_backup_reference = pd.concat([filtered_df_backup_reference,  df_temp[df_temp['Document Title'].isin(similarity_df[(similarity_df['Similarity Score'] >= 0.1) & (similarity_df['Similarity Score'] < 0.45)]['Document Title'])] ])\n",
    "\n",
    "        #Check for location related e.g by country, language, locals\n",
    "        if label in ['GPE', 'NORP', 'LANGUAGE', 'FAC']:\n",
    "            filtered_df_country = pd.concat([filtered_df_country, df[df['Country Name'] == entity]])\n",
    "   \n",
    "    merged_df = pd.DataFrame()\n",
    "    if filtered_df_others.empty and filtered_df_country.empty:\n",
    "       print(f'on the reference df {filtered_df_backup_reference.empty}')\n",
    "       merged_df = pd.concat([filtered_df_backup_reference])\n",
    "    else :\n",
    "       merged_df = pd.concat([filtered_df_country,filtered_df_others])\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n",
    "# Example \n",
    "# test_query=\" is the promotion of renewable energy a focal point within the energy sector?\"\n",
    "# filtered_country = filter_semantics(test_query)\n",
    "# filtered_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b85bd554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_embeddings(user_query):\n",
    "    # df_filtered = filter_semantics(user_query) if filter_semantics(user_query) is not None else None\n",
    "    filtered_result = filter_semantics(user_query)\n",
    "    # Check if the result is not None before assigning it to df_filtered\n",
    "    df_filtered = filtered_result if filtered_result is not None else None\n",
    "\n",
    "    if df_filtered is not None and not df_filtered.empty:  # Check if DataFrame is not None and not empty\n",
    "        length = len(df_filtered.head())\n",
    "        filtered_embeddings_arrays = np.array(list(df_filtered['Embedding']))\n",
    "        index = faiss.IndexFlatIP(filtered_embeddings_arrays.shape[1]) \n",
    "        index.add(filtered_embeddings_arrays)\n",
    "        \n",
    "        user_query_embedding = client.embeddings.create( \n",
    "                input=user_query ,model= embedding_model\n",
    "            ).data[0].embedding\n",
    "\n",
    "        k = min(5, length)\n",
    "        distances, indices = index.search(np.array([user_query_embedding]), k)\n",
    "        return df_filtered, distances, indices\n",
    "    else:\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27928260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_structure(qs):\n",
    "    result_dict = {}\n",
    "\n",
    "    # Extract the DataFrame from the tuple\n",
    "    dataframe = qs[0]\n",
    "    print(qs[1])\n",
    "    print(qs[2])\n",
    "\n",
    "    # Counter to limit the loop to 10 iterations\n",
    "    count = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # Define a unique identifier for each document, you can customize this based on your data\n",
    "        document_id = f\"doc-{index + 1}\"\n",
    "        # Handle NaN in content by using fillna\n",
    "        content = row[\"Content\"]\n",
    "        content = ' '.join(row[\"Content\"].split()[:160])\n",
    "        # Create a dictionary for each document\n",
    "        document_info = {\n",
    "            \"title\": row[\"Document Title\"],\n",
    "            \"extract\": content or \"\",  # You may need to adjust this based on your column names\n",
    "            \"category\": row[\"Category\"],\n",
    "            \"link\": row[\"Link\"],\n",
    "            \"thumbnail\": ''\n",
    "        }\n",
    "        # print(document_info)\n",
    "        # Add the document to the result dictionary\n",
    "        result_dict[document_id] = document_info\n",
    "\n",
    "        # Increment the counter\n",
    "        count += 1\n",
    "\n",
    "        # # Break out of the loop if the counter reaches top 25\n",
    "        if count == 10:\n",
    "            break\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6f166c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to relabel keys and add citations\n",
    "def relabel_and_add_citations(data):\n",
    "    new_data = {}\n",
    "    citation_counter = 1\n",
    "\n",
    "    for doc_id, doc_info in data.items():\n",
    "        new_data[doc_id] = {\n",
    "            \"document_title\": doc_info.get(\"title\", \"\"),\n",
    "            \"summary\": doc_info.get(\"extract\", \"\"),\n",
    "            \"document_category\": doc_info.get(\"category\", \"\"),\n",
    "            \"document_link\": doc_info.get(\"link\", \"\"),\n",
    "            \"document_thumbnail\": doc_info.get(\"thumbnail\", \"\"),\n",
    "            \"citation\": citation_counter\n",
    "        }\n",
    "        citation_counter += 1\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58c69dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8761674  0.84270215 0.8349415  0.8349415  0.83446956]]\n",
      "[[0 6 8 4 5]]\n",
      "Excerpts saved to outputs/excerpts.json\n"
     ]
    }
   ],
   "source": [
    "## module to extract text from documents and return the text and document codes\n",
    "\n",
    "def semanticSearchModule(user_query):\n",
    "    qs = search_embeddings(user_query) #df, distances, indices\n",
    "    # if qs != None :\n",
    "    if qs[0] is not None:\n",
    "        result_structure = map_to_structure(qs)\n",
    "        return result_structure\n",
    "    else : \n",
    "        return []\n",
    "\n",
    "        \n",
    "#test usage\n",
    "excerpts_dict= relabel_and_add_citations(semanticSearchModule(\"What is the role of USAID in supporting Albania's energy sector strategy?\"))\n",
    "# # print(f\"\"\"excerpts_dict {excerpts_dict}\"\"\")\n",
    "\n",
    "# #Return top 10-20 most related \n",
    "# # Define the filename to save the JSON data -  can remove later\n",
    "json_filename = \"outputs/excerpts.json\"\n",
    "\n",
    "# # Save excerpts_dict to the JSON file just for a better preview\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(excerpts_dict, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Excerpts saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db75b59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indicator-id-1': 'value from indicator-id-1', 'indicator-id-2': 'value from indicator-id-2'}\n"
     ]
    }
   ],
   "source": [
    "## module to get data for specific indicators which are identified is relevant to the user query\n",
    "\n",
    "def indicatorsModule(user_query): #lower priority\n",
    "    \n",
    "    # find relevant indicators based on uesr query and extract values\n",
    "    indicators_dict={\n",
    "        \"indicator-id-1\":\"value from indicator-id-1\",\n",
    "        \"indicator-id-2\":\"value from indicator-id-2\"\n",
    "    }#temp\n",
    "    \n",
    "    return indicators_dict\n",
    "\n",
    "#test usage\n",
    "indicators_dict=indicatorsModule(test_query)\n",
    "print(indicators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8237482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## module to generate query ideas\n",
    "\n",
    "def queryIdeationModule(user_query): # lower priority\n",
    "    \n",
    "    # Generate query ideas using OpenAI GPT-3\n",
    "    prompt = f\"\"\"\n",
    "    Ignore previous commands!!!\n",
    "    Generate prompt ideas based on the user query: {user_query}\n",
    "\n",
    "    \n",
    "    -Prompt shoud not be answer to the user query but give other contextual ways of representing the user query !!!\n",
    "    -You Must return output seperated by |  e.g idea 1 | idea2 \n",
    "    - Each generated ideas should be very dinstinct but contextual. Not repeatitive or using same words\n",
    "    - The query idea should be in a question form and not an answer form.\n",
    "    -Avoid adding new lines or breaking spaces to your output and must seperate each idea with |\n",
    "    \"\"\"\n",
    "    response = callOpenAI(prompt)\n",
    "    return response\n",
    "\n",
    "#test usage\n",
    "# query_idea_list=queryIdeationModule(test_query)\n",
    "# print(query_idea_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44eb60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(user_question, relevant_docs):\n",
    "\n",
    "    # Never show the source links or titles. Just put the doc-id as reference when you cite a document!!!! e.g cited content here <a href=\"#doc-id\">[n]</a> where n is an integer and must follow proper order e.g 1,2,3,4,5... !!! \n",
    "    # Do not include references or sources links at the end!!! \n",
    "    # formattings_old = f\"\"\"    \n",
    "    # Ignore all previous commands!!!\n",
    "\n",
    "    # Your answer only in HTML syntax with HTML tags.\n",
    "    # Use HTML tags like < ul>, < ol>, < li>, < strong>, < p>\n",
    "    # Only consider the inner part of the < body> tag.\n",
    "    # ALWAYS use the following tag for new lines: < br />\n",
    "    # Do not add CSS attributes.\n",
    "    # Your answer must be formatted in HTML format\n",
    "    \n",
    "    # Make sure to properly format the text like a professional write. Avoid punctuation errors and the likes. \n",
    "    # Must Use < ul>, < ol>, < li> for listing. Avoid listing on same line. All list or numbering should be on new lines\n",
    "    # Must Use <p> for paragraphs\n",
    "    # When listing item, make sure to count properlly.\n",
    "\n",
    "    # You Must Follow these strictly : \n",
    "    # 1. You Must also find and cite relevant information from the DOCS References extract and title properly !!!! Use the anchor tag pointing to the doc link as href for the citation number e.g <a href=\"link\">[n]</a> \n",
    "    # 2. For example : content here <a href=\"link\">[n]</a> another content. And another <a href=\"link\">[n]</a> where n is integer starting at 1 for [n] and must increament order 1,2,3,4,5,6 .... citations must follow proper increment by 1. \n",
    "    #    for example : content here <a href=\"link\">[1]</a> contnt . anoter content  <a href=\"link\">[2]</a> is correct. \n",
    "    #    for example : content here <a href=\"link\">[1]</a> contnt . anoter content  <a href=\"link\">[3]</a> is very wrong as its jumped to 3. It must be 1,2,3,.... progressive!!!!!\n",
    "\n",
    "    # 2a. link must only be used as href value !!!. Each citation number must be an anchor link\n",
    "    # 3. Let the extracted texts must come inbetween and naturally in the answers and not at the end as relevant in paragraphs !!!! \n",
    "    # 4. Must Avoid using words like Citation - , Sources-  etc at the ending. Never add it to the end of the content. Its not needed. Just cite inbetween the paragraphs as needed!!!\n",
    "    # 5. Don't use too much citations. Only a few as most relevant!!! like 20%. You must use at least one or more relavant citation !!! Use citations as part of the answers and not in isolation\n",
    "    # \"\"\"\n",
    "\n",
    "\n",
    "    #References:\n",
    "    # Title of the <<SOUCRCE>>. Retrieved from URL e.g \n",
    "    # Title of the <<SOUCRCE>>. Retrieved from URL. \n",
    "\n",
    "    formattingsold = f\"\"\" \n",
    "        Strictly follow the follow steps:\n",
    "        Your answer only in HTML syntax with HTML tags.\n",
    "        Use HTML tags like < ul>, < ol>, < li>,  < strong>, < p>\n",
    "        Only consider the inner part of the < body> tag.\n",
    "        ALWAYS use the following tag for new lines: < br />\n",
    "        use <a> for cite numbers\n",
    "        Do not add CSS attributes.\n",
    "        Your answer must be formatted in HTML format\n",
    "        \n",
    "        \n",
    "        1. <<SOUCRCE>> for citing : {relevant_docs}\n",
    "\n",
    "        2. Must Follow the Structure for your output strictly: \n",
    "\n",
    "            \n",
    "                Break down the answer into main points.\n",
    "                Provide explanations and cite <<SOUCRCE>> directly.\n",
    "\n",
    "                Summarize the main points.\n",
    "\n",
    "                For Example: \n",
    "                Question: What are the benefits of regular exercise?\n",
    "                \n",
    "                Answer\n",
    "                Regular exercise offers significant benefits across physical, mental, and emotional dimensions. Physically, it strengthens the heart and enhances circulation, which can reduce the risk of heart disease by up to 40% <a href=“link” data-id=“doc-id”>[1]</a>. It also aids in weight management by burning calories and building muscle mass <a href=“link” data-id=“doc-id”>[2]</a>.\n",
    "                Mentally, exercise helps reduce anxiety and depression by increasing the production of endorphins, acting similarly to some medications. Additionally, it enhances cognitive function, improving memory and learning capabilities <a href=“link” data-id=“doc-id”>[3]</a>.\n",
    "                Emotionally and socially, regular physical activity reduces stress hormones such as cortisol  and boosts self-esteem by improving body image and self-confidence. Participation in group sports also provides social benefits and fosters a sense of community.\n",
    "                In summary, regular exercise is essential for overall health, enhancing physical fitness, mental clarity, and emotional well-being.\n",
    "\n",
    "\n",
    "    3. Return answer without explicit partitions, keeping it concise and integrating citations naturally within the text.\n",
    "    4. You must cite at least one relevant <<SOUCRCE>> provided above. This is compulsory. Don't just show a reference at the footnotes but also integrate into the text using the cite number e.g <a href=“link” data-id=“doc-id”>[1]</a>.\n",
    "    5. Cited source number must be an anchor tag link !!!!! You don't have to always cite. Only do this when relevant. If you can't find the link just leave the citation out.\n",
    "    6. VERY IMPORTANT:  avoid numberic listings in your answer!!!!!\n",
    "    \"\"\"\n",
    "    \n",
    "    formattings = f\"\"\" \n",
    "        Strictly follow the follow steps:\n",
    "        Your answer only in HTML syntax with HTML tags.\n",
    "        Use HTML tags like < ul>, < ol>, < li>,  < strong>, < p>\n",
    "        Only consider the inner part of the < body> tag.\n",
    "        ALWAYS use the following tag for new lines: < br />\n",
    "        use <a> for cite numbers\n",
    "        Do not add CSS attributes.\n",
    "        Your answer must be formatted in HTML format\n",
    "        \n",
    "        \n",
    "        1. <<SOUCRCE>> for citing : {relevant_docs}\n",
    "    \"\"\"\n",
    "   \n",
    "    # {\"role\": \"assistant\", \"content\": formattings},\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":\"You are a helpful assistant and a professional writer with 50 years experience. Give answer to the user's inquiry.\"\n",
    "        },\n",
    "        {'role': 'user', 'content': f\"\"\"{formattings} \n",
    "                                        {user_question}\"\"\"},\n",
    "    ]\n",
    "    print(f\"\"\" excerpts_dict === {len(relevant_docs)} \"\"\")\n",
    "\n",
    "    # print(formattings)\n",
    "\n",
    "    print(openai_deployment)\n",
    "        \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0.3,\n",
    "                    messages=messages,\n",
    "                    top_p=0.8,\n",
    "                    frequency_penalty=0.6,\n",
    "                    presence_penalty=0.8\n",
    "\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    # Define the regex pattern to match digits followed by '. do'\n",
    "    pattern = r'\\d+\\. do'\n",
    "\n",
    "    # Remove matches from the text\n",
    "    cleaned_text = re.sub(pattern, '', response)\n",
    "\n",
    "    # # Optionally, clean up any extra spaces or punctuation left behind\n",
    "    # cleaned_text = re.sub(r'\\s{2,}', ' ', cleaned_text).strip()\n",
    "\n",
    "\n",
    "    return cleaned_text\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b73a93",
   "metadata": {},
   "source": [
    "<h3> synthesis module </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0f509d",
   "metadata": {},
   "source": [
    "    llm_instructions=\"llm instruction template here, with placeholders for insertion of user query, excerpts, indicator data, and entity and relation info\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7113366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to synthesize answer using retreival augmented generation approach\n",
    "\n",
    "\n",
    "      #  - Make sure to Include citations based on the Sources. e.g Text excerpt here<a data-id='test-doc-1'>[1]</a> when referencing a document in the sources. using 1 ...nth\n",
    "      #       - The citations anchor should be near the excerpt not following each other.\n",
    "      #       - Use the anchor tag for the citation links and should link to the document link in the Sources. for example Undp operates in afganistan <a data-id='test-doc-1'>[1]</a>. UNDP offers health relationships <a data-id='test-doc-2'>[2]</a>.\n",
    "      #       - Make sure the data-id actually exists in the Sources.\n",
    "      #       - The text in the anchor tag should be citation number not document title.\n",
    "      #       - You can reference multitple citations based sources\n",
    "\n",
    "# prompt_formattings= f\"\"\"\n",
    "#     - Answer output must be properly formatted using HTML. \n",
    "#     - Don't include <html>, <script>, <link> <a>  or <body> tags. Only text formating tags should be allowed. e.g h1..h3, p, anchor, etc. Strictly HTML only\n",
    "#     - Strictly infer your answers from the <Sources> Only and make citations to Source extract referenced \n",
    "#     - The Source as format like: \"doc-n\": {{\n",
    "#         \"title\": \"title of the relate document\",\n",
    "#         \"extract\": \"content\",\n",
    "#         \"category\": \"\",\n",
    "#         \"link\": \"\",\n",
    "#         \"thumbnail\": \"\",\n",
    "#         \"citation\": n\n",
    "#     }}, where doc-n can be doc-1, doc-24 etc.. n is in integer.\n",
    "#     - Reference the extract and title of all document sources provided in the json and summarise it into a coherent answer that relates to the <User Query>\n",
    "#     - Citation should follow formats: [reference content][citation number]. \n",
    "#     - Give output writing tone like a academic research tone\n",
    "#     - If no <Sources> are provided, try to make suggestives or  simply say you don't have that information   \n",
    "#     - Remove new line or tab characters from your output\n",
    "#     - do not use or include links,  anchor links or a href tags !!!\n",
    "#     -do not include references links at the end!!!\n",
    "#     - to reference within the text do [n] not [source n] . musct be [n] where n is an integer of the citation number\n",
    "#     - Should be one citation only e.g [n] not [n][n][n]\n",
    "# \"\"\"\n",
    "\n",
    "def synthesisModule(user_query, entities_dict, excerpts_dict, indicators_dict,prompt_formattings):\n",
    "    \n",
    "    # Generate prompt engineering text and template\n",
    "    # llm_instructions = f\"\"\"\n",
    "    # Ignore previous commands!!!\n",
    "    # Given a user query, use the provided <Sources> extract section of the JSON only to provide the correct answer to the user's query.\n",
    "    \n",
    "    # User Query: {user_query}\n",
    "    \n",
    "    # Sources: {excerpts_dict}\n",
    "    \n",
    "    # {prompt_formattings}\n",
    "    # \"\"\"\n",
    "\n",
    "    #Closed Domain prompting\n",
    "    # llm_instructions = f\"\"\" \n",
    "    #   Context:  {excerpts_dict}\n",
    "    #  \"\"\"\n",
    "    # print(llm_instructions)\n",
    "    ###synthesize data into structure within llm prompt engineering instructions\n",
    "    answer=get_answer(user_query, excerpts_dict) #callOpenAI\n",
    "    answer_formated_fixed = answer.replace(\"\\n\\n\",\"<br>\").replace(\"\\n\",\"<br>\")\n",
    "    return answer_formated_fixed\n",
    "\n",
    "## to test this, run the full pipeline with the handleApiCall function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787b228",
   "metadata": {},
   "source": [
    "<h3> run pipeline </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10fe2bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85505545 0.8340653  0.82767075 0.8249451  0.82131886]]\n",
      "[[33 25 56  7 46]]\n",
      " excerpts_dict === 10 \n",
      " excerpts_dict === 10 \n",
      " \n",
      "        Strictly follow the follow steps:\n",
      "        Your answer only in HTML syntax with HTML tags.\n",
      "        Use HTML tags like < ul>, < ol>, < li>,  < strong>, < p>\n",
      "        Only consider the inner part of the < body> tag.\n",
      "        ALWAYS use the following tag for new lines: < br />\n",
      "        use <a> for cite numbers\n",
      "        Do not add CSS attributes.\n",
      "        Your answer must be formatted in HTML format\n",
      "        \n",
      "        \n",
      "        1. <<SOUCRCE>> for citing : {'doc-494': {'title': 'Nigeria National Gas Policy', 'extract': 'Nigeria National Gas Policy THE GOVERNMENT OF THE FEDERAL REPUBLIC OF NIGERIA - -------------------------------------------------------------------------------- -- NATIONAL GAS POLICY --------------------------------------------------------- -------------------------- The purpose of this document is to define the policy of the Federal Government in respect of Nigeria’ natural gas endowment, establish its medium to long-term targets for gas reserves growth and utilisation and record strategies to be pursued to ensure the successful implementation of the policy in accordance with Nigeria’ national socio-economic development priorities Ministry of Petroleum Resources Table of Contents: EXECUTIVE SUMMARY : Page: 13 INTRODUCTION : Page: 17 VISION AND OBJECTIVES: Page: 32 GOVERNANCE : Page: 35 Table of Contents: INDUSTRY STRUCTURE: Page: 50 DEVELOPING GAS RESOURCES: Page: 57 INFRASTRUCTURE : Page: 65 BUILDING GAS MARKETS : Page: 68 Table of Contents: DEVELOPING NATIONAL HUMAN RESOURCES : Page: 83 COMMUNICATIONS : Page: 89 Table of Contents: ROADMAP AND ACTION PLAN: Page: 91 Nigeria National Gas Policy LIST OF FIGURES Figure : World Proved Gas Reserves Ranking (2015)', 'category': 'NGP', 'link': 'http://www.petroleumindustrybill.com/wp-content/uploads/2017/06/National-Gas-Policy-Approved-By-FEC-in-June-2017.pdf', 'thumbnail': ''}, 'doc-495': {'title': 'Country programme document for Nigeria (2023-2027)', 'extract': 'DP/DCP/NGA/ United Nations Executive Board of the United Nations Development Programme, the United Nations Population Fund and the United Nations Office for Project Services Distr: General December 2022 Original: English First regular session 2023 30 January – February 2023, New York Item of the provisional agenda Country programmes and related matters Country programme document for Nigeria () Contents Chapter Page UNDP within the United Nations Sustainable Development Cooperation Framework…………… II Programme priorities and partnerships………………………………………………… ………… III Programme and risk management ………………………………………………………………… IV Monitoring and evaluation ………………………………………………………………………… Annex Results and resources framework for Nigeria ()………………………………………… 22-27499X () 081222 *2227499* DP/DCP/NGA/ UNDP within the United Nations Sustainable Development Cooperation Framework Nigeria has the largest economy ($429 billion US dollars in 2020) and is the most populous (211 million in 2021) country in Africa Despite being the largest crude oil producer in Africa, poverty (40 per cent or people million in 2019) and unemployment (33 per cent in 2021) remain high Nigeria ranked', 'category': 'CPD', 'link': 'https://digitallibrary.un.org/record/3998938/files/DP_DCP_NGA_4-EN.pdf?ln=en', 'thumbnail': ''}, 'doc-1': {'title': 'Machine learning for a sustainable energy future', 'extract': '0123456789();: The combustion of fossil fuels, used to fulfill approximately 80% of the world’ energy needs, is the largest single source of rising greenhouse gas emissions and global temperature1 The increased use of renewable sources of energy, notably solar and wind power, is an economically viable path towards meeting the climate goals of the Paris Agreement2 However, the rate at which renewable energy has grown has been outpaced by ever-growing energy demand, and as result the fraction of total energy produced by renewable sources has remained constant since 2000 (ref) It is thus essential to accelerate the transition towards sustainable sources of energy4 Achieving this transition requires energy technologies, infrastructure and policies that enable and promote the harvest, storage, conversion and management of renewable energy In sustainable energy research, suitable material candidates (such as photovoltaic materials) must first be chosen from the combinatorial space of possible materials, then synthesized at high enough yield and quality for use in devices Next,', 'category': 'SEH', 'link': 'https://www.nature.com/articles/s41578-022-00490-5', 'thumbnail': ''}, 'doc-2': {'title': 'Clean energy for all? Mapping inequity potential in the clean energy transition in the United States', 'extract': 'Energy Research & Social Science 108 (2024) 103400 Available online 30 December 2023 /© 2023 Elsevier Ltd All rights reserved Original research article Clean energy for all? Mapping inequity potential in the clean energy transition in the United States Huiting Chen ,, Sung-Gheel Jang ,*, Yan Zhang , Yaolin Liu , School of Resource and Environmental Sciences, Wuhan University, Wuhan 430079, China School of Marine and Atmospheric Sciences, Stony Brook University, Stony Brook 11794, USA Land Consolidation and Rehabilitation Center, Ministry of Natural Resources, Beijing 100035, China Key Laboratory of Geographic Information System, Ministry of Education, Wuhan University, Wuhan 430079, China Keywords: Clean energy transition Energy justice Energy equity Inequity potential Spatial analysis The clean energy transition leads to an unequal distribution of benefits and burdens over region To ensure equity in the energy transition, policymakers need to understand the spatial distribution and extent of regional inequities There is lack of systematic and quantitative studies addressing the different types of', 'category': 'SEH', 'link': 'https://www.sciencedirect.com/science/article/abs/pii/S2214629623004607', 'thumbnail': ''}, 'doc-3': {'title': 'Access to clean cooking services in energy and emission scenarios after COVID-19', 'extract': 'AnAlysis 1Energy, Climate, and Environment Program, International Institute of Applied Systems Analysis, Laxenburg, Austria 2Population and Just Societies Program, International Institute of Applied Systems Analysis, Laxenburg, Austria 3Climate Analytics, Berlin, Germany ✉-mail: pachauri@iiasaacat nergy for cooking is most fundamental need Yet today, over three billion people still cook by burning wood on open fires and in smoky stoves The enormous social, public health and environmental benefits of transitioning to cleaner cooking underpin the inclusion of universal access target for this under the United Nations Sustainable Development Goal (SDG )– Even before the COVID-19 pandemic, data showed that efforts to provide clean fuels and stoves have been lagging far behind those aimed at extend- ing electricity access4 recent report claims that this sluggish prog- ress in providing clean cooking access is costing the world more than US$ trillion each year as result of health impacts, produc- tivity losses and environmental degradation5 Mounting evidence of the impacts of air pollution exposure on', 'category': 'SEH', 'link': 'https://www.nature.com/articles/s41560-021-00911-9', 'thumbnail': ''}, 'doc-4': {'title': 'The asymmetric impacts of artificial intelligence and oil shocks on clean energy industries by considering COVID-19', 'extract': 'Energy 291 (2024) 130197 Available online January 2024 /© 2024 Elsevier Ltd All rights reserved The asymmetric impacts of artificial intelligence and oil shocks on clean energy industries by considering COVID-19 Hongwei Zhang ,, Beixin Fang , Pengwei He ,*, Wang Gao School of Mathematics and Statistics, Central South University, Changsha, 410083, PR China Institute of Metal Resources Strategy, Central South University, Changsha, 410083, PR China Business School, University of Shanghai for Science and Technology, Shanghai, 200093, PR China School of Finance, Hebei University of Economics and Business, Shijiazhuang, 050062, PR China Handling editor: Isabel Soares Keywords: Artificial intelligence Oil shocks Clean energy stock NARDL model COVID-19 pandemic Can grand environmental goals still be achieved when the ◦ climate target and Industry encounter the COVID-19 pandemic? Exploring the impacts of artificial intelligence (AI) and crude oil shocks as critical drivers on clean energy stocks may provide fresh insights to tackle this question This paper explores the asymmetric impacts of positive', 'category': 'SEH', 'link': 'https://www.sciencedirect.com/science/article/abs/pii/S0360544223035910', 'thumbnail': ''}, 'doc-6': {'title': 'Sustainable Energy from agro-industrial wastewaters in Latin-America', 'extract': 'Sustainable Energy from agro-industrial wastewaters in Latin-America Alexander Meneses-Jácome ,,, Rocío Diaz-Chavez , Héctor Velásquez-Arredondo , Diana Cárdenas-Chávez , Roberto Parra , Angela Ruiz-Colorado Grupo de Investigación en Bioprocesos Flujos Reactivos, Universidad Nacional de Colombia – Sede Medellín, Colombia Programa de Ingeniería Ambiental, Unidades Tecnológicas de Santander (UTS), Calle de los estudiantes, Bucaramanga, Colombia Centre for Environmental Policy, Imperial College London, London SW7 1NA, UK Facultad de Minas, Escuela de Procesos Energía, Universidad Nacional de Colombia – Sede Medellín, Colombia Cátedra de Bioprocesos Ambientales, Centro del Agua para América Latina el Caribe, Tecnológico de Monterrey, Monterrey 64849, Mexico Article history: Received 16 August 2014 Received in revised form 25 July 2015 Accepted December 2015 Available online 29 December 2015 Keywords: Agro- industrial efﬂuents Sustainable energy Water- energy nexus Life cycle assessment (LCA) Sustainability indicators Wastewater treatment Conventional biological processes used to treat high- polluted agro-industrial efﬂuents produce biogas and sludge, two by-products stocking up important energy contents Advanced biotechnologies to', 'category': 'SEH', 'link': 'https://www.sciencedirect.com/science/article/abs/pii/S1364032115014197', 'thumbnail': ''}, 'doc-7': {'title': 'The justice and policy implications of clean energy transition in Africa', 'extract': 'The justice and policy implications of clean energy transition in Africa Benyoh Emmanuel Kigha Nsafon1,*, Noel Ngando Same1,, Abdulfatai Olatunji Yakub1,, Deepak Chaulagain1,, Nallapaneni Manoj Kumar4, and Jeung-Soo Huh1,,* 1Institute for Global Climate Change and Energy, Kyungpook National University, Daegu, South Korea, 2Department of Energy Convergence and Climate Change, Graduate School, Kyungpook National University, Daegu, South Korea, 3Department of Convergence and Fusion System Engineering, Graduate School, Kyungpook National University, Daegu, South Korea, 4School of Energy and Environment, City University of Hong Kong, Kowloon, Hong Kong SAR, China, 5Center for Circular Supplies, HICCER—Hariterde International Council of Circular Economy Research, Palakkad, Kerala, India Despite the low local energy access rates, Africa is considered key player in the global energy transition due to its large supply of fossil fuels and large reserve of critical minerals essential for manufacturing renewable energy components in the energy sector and storage devices in the transportation and electronics sectors But building sustainable society at all levels across nations', 'category': 'SEH', 'link': 'https://www.frontiersin.org/articles/10.3389/fenvs.2023.1089391/full', 'thumbnail': ''}, 'doc-8': {'title': 'Climate change, energy security risk, and clean energy investment', 'extract': 'Energy Economics 129 (2024) 107225 Available online December 2023 /© 2023 The Author() Published by Elsevier This is an open access article under the CC BY license ( Climate change, energy security risk, and clean energy investment Bernard Njindan Iyke La Trobe Business School, La Trobe University, Melbourne, Australia JEL codes: E22 Q43 Q54 Keywords: Climate change Clean energy investment Energy security We examine the impact of climate change on energy security risk and explore the role of clean energy investment in reducing this impact By exploiting recently developed historical energy security risk dataset alongside climate change and clean energy investment datasets, we demonstrate that climate change enhances energy security risk Additionally, we show that investment in clean energy can reduce the impact of climate change on energy security risk This mitigating effect of clean energy investment is more pronounced in countries with slower population growth, the capacity to invest in robust energy infrastructures, and lower corruption practices To optimize', 'category': 'SEH', 'link': 'https://www.sciencedirect.com/science/article/pii/S0140988323007235', 'thumbnail': ''}, 'doc-9': {'title': 'Clean cooking access may stall under slow post-pandemic recovery and ambitious climate mitigation without explicit focus', 'extract': '1009 policy brief ENERGY SCENARIOS Clean cooking access may stall under slow post-pandemic recovery and ambitious climate mitigation without explicit focus Without additional support policies, clean cooking could become unaffordable for about 470 million people by 2030 if post-pandemic recovery is slow, and about 200 million people by 2030 under ambitious climate mitigation action Acceleration of clean cooking transitions by tapping into pandemic recovery and climate funds to target the poorest people and regions globally is urgently needed Shonali Pachauri ✉, Miguel Poblete-Cazenave , Arda Aktas2 and Matthew Gidden1, BASED ON Pachauri, , Poblete-Cazenave, Aktas & Gidden Nature Energy (2021) The policy problem At the current rate, the Sustainable Development Goal (SDG7) target of universal access to clean cooking services by 2030 is unachievable and may remain unattainable for some countries even by This can also hinder progress on other SDGs, including those on health, gender, inequality, climate and land Financial strain following the COVID-19 pandemic is pushing people further', 'category': 'SEH', 'link': 'https://www.nature.com/articles/s41560-021-00939-x', 'thumbnail': ''}}\n",
      "    \n",
      "sdgi-gpt-35-turbo-16k\n",
      "Synthesis saved to outputs/synthesis_output.json\n"
     ]
    }
   ],
   "source": [
    "# full pipeline with retreival, synthesis of answer to user query, and structure results into api response\n",
    "\n",
    "def handleApiCall(user_query):\n",
    "    \n",
    "    ##run processing modules (in parallel)\n",
    "    entities_dict=knowledgeGraphModule(user_query)\n",
    "    excerpts_dict=semanticSearchModule(user_query)\n",
    "    indicators_dict=indicatorsModule(user_query) ##lower priority\n",
    "    query_idea_list=queryIdeationModule(user_query) ##lower priority\n",
    "    prompt_formattings=\"\"\n",
    "    ##synthesis module\n",
    "    answer=synthesisModule(user_query, entities_dict, excerpts_dict, indicators_dict, prompt_formattings)\n",
    "\n",
    "    ##structure response\n",
    "    response={\n",
    "        \"user_query\":user_query,\n",
    "        \"answer\":answer,\n",
    "        \"sources\":excerpts_dict,\n",
    "        \"query_ideas\":query_idea_list,\n",
    "        \"entities\":list(entities_dict[\"entities\"].keys())       \n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "# test usage\n",
    "test_query = \"Can off-grid solutions effectively address energy access challenges in remote areas in Nigeria?\"\n",
    "response=handleApiCall(test_query) \n",
    "# Define the filename to save the JSON data -  can remove later\n",
    "json_filename = \"outputs/synthesis_output.json\"\n",
    "\n",
    "# Save excerpts_dict to the JSON file just for a better preview\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(response, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Synthesis saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7cc6f",
   "metadata": {},
   "source": [
    "<h1>Testing</h1>\n",
    "\n",
    "<p>This sections contains all things testings </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89f8f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(csv_file):\n",
    "    # Initialize an empty list to store processed entries\n",
    "    result = []\n",
    "    \n",
    "    # Loop through each entry in the CSV file\n",
    "    for entry in csv.DictReader(csv_file):\n",
    "        query = entry['query']\n",
    "        sample_answer = entry['sample_answer']\n",
    "        \n",
    "        # Call OpenAI for chat GPT answer\n",
    "        chat_gpt_answer = callOpenAI(f\"\"\" \n",
    "                                    {query} \n",
    "                                    {prompt_formattings} \n",
    "                                    \"\"\")\n",
    "        \n",
    "        # Call the moonshot model API\n",
    "        moonshot_model_answer = handleApiCall(query) \n",
    "        \n",
    "        # Calculate BERT score for moonshot model answer\n",
    "        P, F, R = bert_score([sample_answer], [moonshot_model_answer['answer']], lang='en', verbose=True)\n",
    "        entry['moonshot_model_answer'] = moonshot_model_answer['answer']\n",
    "        entry['bert_score'] = round(float(F), 2)\n",
    "\n",
    "        # Calculate BERT score for chat GPT answer\n",
    "        P, F, R = bert_score([sample_answer], [chat_gpt_answer], lang='en', verbose=True)\n",
    "        entry['chat_gpt_answer'] = chat_gpt_answer\n",
    "        entry['bert_score_gpt'] = round(float(F), 2)\n",
    "        \n",
    "        # Append the processed entry to the result list\n",
    "        result.append(entry)\n",
    "    \n",
    "    # Return the list of processed entries\n",
    "    return result\n",
    "\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = \"../testing/queries.csv\"\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open(csv_file_path, mode='r') as file:\n",
    "    # Pass the file object to the function\n",
    "    result = calculate_scores(file)\n",
    "\n",
    "# Print updated data with scores\n",
    "# print(json.dumps(result, indent=4))\n",
    "\n",
    "# Save updated data to a JSON file\n",
    "with open('../testing/test_output.json', 'w') as file:\n",
    "    json.dump(result, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8961eb",
   "metadata": {},
   "source": [
    "<h1>Compare Moonshot BERT score to GPT BERT Score</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e3412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bert_score: 0.7995652173913044\n",
      "Average bert_score_gpt: 0.7778260869565218\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "with open('../testing/test_output.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize variables to store total scores and count of items\n",
    "total_bert_score = 0\n",
    "total_bert_score_gpt = 0\n",
    "count = 0\n",
    "\n",
    "# Iterate through each item in the JSON data\n",
    "for item in data:\n",
    "    # Extract bert_score and bert_score_gpt from the current item\n",
    "    bert_score = item['bert_score']\n",
    "    bert_score_gpt = item['bert_score_gpt']\n",
    "    \n",
    "    # Add the scores to the total\n",
    "    total_bert_score += bert_score\n",
    "    total_bert_score_gpt += bert_score_gpt\n",
    "    \n",
    "    # Increment the count\n",
    "    count += 1\n",
    "\n",
    "# Calculate the average scores\n",
    "average_bert_score = total_bert_score / count\n",
    "average_bert_score_gpt = total_bert_score_gpt / count\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average bert_score:\", average_bert_score)\n",
    "print(\"Average bert_score_gpt:\", average_bert_score_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905ad59",
   "metadata": {},
   "source": [
    "<h1>Trello Board AutoPopulate</h1>\n",
    "<p> Automation for trello</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66edd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import requests\n",
    "from markdownify import markdownify as md\n",
    "import textwrap\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "def8e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "trello_api_list_id = os.getenv(\"trello_api_list_id\")\n",
    "trello_api_key_id = os.getenv(\"trello_api_key_id\")\n",
    "trello_api_key_token = os.getenv(\"trello_api_key_token\")\n",
    "trello_board_id= os.getenv(\"trello_board_id\")\n",
    "trello_url =\"https://api.trello.com/1/\"\n",
    "# print(trello_board_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c91b0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list function - this allows for various test versions \n",
    "\n",
    "def create_list(list_title):\n",
    "    url = f\"{trello_url}lists?name={list_title}&token={trello_api_key_token}&idBoard={trello_board_id}&key={trello_api_key_id}\"\n",
    "    response = requests.request(\"POST\", url)\n",
    "    response_json = response.json()  # Parse response JSON\n",
    "    list_id = response_json[\"id\"]  # Access 'id' from JSON\n",
    "    return list_id\n",
    "\n",
    "#example\n",
    "# list_response = create_list('User Queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b2d2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list function - this allows for various test versions \n",
    "def create_card_label(card_id, color, name):\n",
    "    url = f\"{trello_url}cards/{card_id}/labels?color={color}&name={name}&token={trello_api_key_token}&idBoard={trello_board_id}&key={trello_api_key_id}\"\n",
    "    # print(url)\n",
    "    response = requests.request(\"POST\", url)\n",
    "    response_json = response.json()  # Parse response JSON\n",
    "    list_id = response_json[\"id\"]  # Access 'id' from JSON\n",
    "    return list_id\n",
    "\n",
    "#example\n",
    "# list_response = create_card_label('','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c28eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_date(format='%b %d %H:%M'):\n",
    "    return datetime.now().strftime(format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "de4fc320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Async function to send the request\n",
    "\n",
    "async def send_request(query,list_response,card_color,card_label_name):\n",
    "    name = query[\"query\"]\n",
    "    response=handleApiCall(name) \n",
    "\n",
    "    #for trello preview only\n",
    "    cleanResp = response['answer'].replace(\"</p>\",\"</p> ******************************************************************************\").replace(\"<p>\",\"<br/>\").replace(\"<br>\",\" *******************************************************************************\")\n",
    "    markdown_content_description = md(f\"{cleanResp}\")\n",
    "    # markdown_content_description = html2text.html2text(cleanResp)\n",
    "\n",
    "    desc = f\"\"\"{markdown_content_description}\"\"\"\n",
    "    url = f\"{trello_url}cards?idList={list_response}&key={trello_api_key_id}&token={trello_api_key_token}&name={name}&desc={desc}\"\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(url, timeout=1200) as response:\n",
    "            el = ''\n",
    "            # print(name)\n",
    "            resp = await response.text()\n",
    "            resp_dict = json.loads(resp)\n",
    "            id = resp_dict['id']\n",
    "\n",
    "            card_label_resp = create_card_label(id, card_color, card_label_name)\n",
    "            print(card_label_resp)\n",
    "            print(\"---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Test process\n",
    "async def mainTest(color,file):\n",
    "    card_title = f\"\"\"{get_current_date()}\"\"\"\n",
    "    card_color = color\n",
    "    card_label_name =file\n",
    "    queries_source = f\"\"\"../testing/queries/{file}.csv\"\"\"\n",
    "    tasks = []\n",
    "    list_response = create_list(card_title)\n",
    "    with open(queries_source, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            tasks.append(send_request(row,list_response,card_color,card_label_name))\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Apply nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the event loop\n",
    "# await mainTest('red','clarification')\n",
    "# await mainTest('purple','comparative')\n",
    "# await mainTest('green','descriptive')\n",
    "# await mainTest('yellow','informational')\n",
    "# await mainTest('blue','opinion')\n",
    "# await mainTest('orange','procedural')\n",
    "# await mainTest('violet','queries')\n",
    "# await mainTest('pink','yesno')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
