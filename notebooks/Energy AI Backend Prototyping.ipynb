{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542a4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.0.0) was trained with spaCy v3.0.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import ast\n",
    "from openai import AzureOpenAI\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import pycountry\n",
    "import re\n",
    "from bert_score import score as bert_score\n",
    "import csv\n",
    "import transformers\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from datetime import datetime\n",
    "import tiktoken\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "from country_named_entity_recognition import find_countries\n",
    "import awoc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fdd010",
   "metadata": {},
   "source": [
    "### Load Model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecc76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../models/df_embed_EN_All_V4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf814d9",
   "metadata": {},
   "source": [
    "### Load Enviroment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4c742f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3e87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API configuration\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"api_key_azure\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"api_version\")\n",
    "openai_deployment = \"sdgi-gpt-35-turbo-16k\"\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"api_key_azure\"),  \n",
    "  api_version = os.getenv(\"api_version\"),\n",
    "  azure_endpoint =os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    ")\n",
    "\n",
    "embedding_model = os.getenv(\"USER_QUERY_EMBEDDING_ENGINE\") \n",
    "\n",
    "# print(openai.api_key)\n",
    "# print(openai.api_base)\n",
    "# print(openai.api_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16534287",
   "metadata": {},
   "source": [
    "<h3>globals</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2a3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_query=\"What are the sustainable energy priorities for UNDP?\"\n",
    "test_query = 'What is the Human Development Index (HDI) value for Albania as mentioned in the document?'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f11f01",
   "metadata": {},
   "source": [
    "<h3> helper functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc569537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to make simple openAI Calls\n",
    "def callOpenAI(prompt):  \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ]\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd62b3",
   "metadata": {},
   "source": [
    "<h3> processing modules </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6798164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEntitiesFromQuery(user_query):\n",
    "    prompt = f\"\"\"\n",
    "    Extract entities from the following user query: \\\"{user_query}\\\" and return output in array format.\n",
    "    \n",
    "    -Entities should be directly related to the domain or topic of interest. They should represent important concepts that contribute to the understanding of the subject matter.\n",
    "    -Each entity in the knowledge graph should be distinct and have a unique identifier. This ensures clarity and avoids ambiguity when establishing relationships between entities.\n",
    "    -You Must return output in array format e.g  ['entity1','entity2'] !!!\n",
    "    -Avoid adding new lines or breaking spaces to your output. Array should be single dimension and single line !!!\n",
    " \n",
    "    \"\"\"\n",
    "    entity_list = callOpenAI(prompt)   \n",
    "    return entity_list\n",
    "\n",
    "# Test usage\n",
    "# test_query = \"What are the sustainable energy for UNDP?\"\n",
    "# entity_list = extractEntitiesFromQuery(test_query)\n",
    "# print(entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7718dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relations': 'The Paris Agreement is related to sustainable energy development.', 'entities': {'Paris Agreement': \"The Paris Agreement is an international treaty adopted in 2015 by nearly every country in the world. Its goal is to combat climate change by limiting global warming to well below 2 degrees Celsius above pre-industrial levels. It promotes cooperation, transparency, and regular updates of countries' efforts to reduce greenhouse gas emissions.\", 'sustainable energy development': 'Sustainable energy development refers to the process of harnessing and utilizing renewable energy sources in a manner that minimizes environmental impact and promotes long-term viability. It involves the adoption of clean technologies, such as solar, wind, and hydro power, to meet energy needs while reducing greenhouse gas emissions and preserving natural resources.'}}\n"
     ]
    }
   ],
   "source": [
    "## module to get information on the entities from user query using the KG\n",
    "def knowledgeGraphModule(user_query):\n",
    "    \n",
    "    # generate list of entities based on user query\n",
    "    entity_list = extractEntitiesFromQuery(user_query)\n",
    "    my_list = ast.literal_eval(entity_list)\n",
    "    prompt_summarise_entites = f\"\"\"\n",
    "    Summarize all relations between all the entities : {my_list}\n",
    "    \"\"\"\n",
    "    summarise_entities = callOpenAI(prompt_summarise_entites)\n",
    "    # Initialize an empty dictionary to store information\n",
    "    entities_dict = {\n",
    "        \"relations\": summarise_entities,\n",
    "        \"entities\": {}\n",
    "    }\n",
    "    # Loop through each entity in the list\n",
    "    for entity in my_list:\n",
    "        # Fetch information about the entity from your knowledge graph\n",
    "        prompt = f\"Give me a short description 50 words of {entity}\"\n",
    "        entity_info = callOpenAI(prompt)\n",
    "        # Add the entity information to the dictionary\n",
    "        entities_dict[\"entities\"][entity] = entity_info\n",
    "    \n",
    "    return entities_dict\n",
    "\n",
    "\n",
    "# Test usage\n",
    "test_query = \"What is the role of Paris Agreement in sustainable energy development?\"\n",
    "entities_dict = knowledgeGraphModule(test_query)\n",
    "print(entities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c65c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awoc import AWOC\n",
    "\n",
    "\n",
    "# def find_mentioned_countries(text):\n",
    "#     countries = set()\n",
    "    \n",
    "#     # Tokenize the text using regular expressions to preserve punctuation marks\n",
    "#     words = re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "#     text = ' '.join(words)  # Join the tokens back into a string\n",
    "    \n",
    "#     for word in text.split():\n",
    "#         try:\n",
    "#             country = pycountry.countries.get(name=word) #pycountry.countries.lookup(word)\n",
    "#             if country != None : \n",
    "#                countries.add(country.name)\n",
    "#         except LookupError:\n",
    "#             pass\n",
    "    \n",
    "#     return list(countries)\n",
    "\n",
    "# '''\n",
    "# Previous 'find_mentioned_countries' can detect countries when they are formed correctly.\n",
    "\n",
    "# '''\n",
    "# # Extract mentioned countries' ISO3 code\n",
    "# def find_mentioned_country_code(user_query):\n",
    "#     countries = set()\n",
    "#     extracted_countries = find_countries(user_query, is_ignore_case=True)\n",
    "#     # check if we have country first\n",
    "#     if extracted_countries:\n",
    "#         for c in extracted_countries:\n",
    "#             countries.add(c[0].alpha_3)\n",
    "#     # check if we have continent\n",
    "#     else:\n",
    "#         words = re.findall(r'\\w+|[^\\w\\s]', user_query)\n",
    "#         text = ' '.join(words)  # Join the tokens back into a string\n",
    "    \n",
    "#         world_info = awoc.AWOC()\n",
    "#         all_continents = set([continent.lower() for continent in world_info.get_continents_list()])\n",
    "#         for word in text.split():\n",
    "#             word = word.lower()\n",
    "#             # check if this continent\n",
    "#             if word in all_continents:\n",
    "#                 target_countries = world_info.get_countries_list_of(word)\n",
    "#                 for country in target_countries:\n",
    "#                     countries.add(world_info.get_country_data(country)['ISO3'])\n",
    "#     return countries\n",
    "\n",
    "def find_mentioned_countries(text):\n",
    "    countries = set()\n",
    "    \n",
    "    # Tokenize the text using regular expressions to preserve punctuation marks\n",
    "    words = re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "    text = ' '.join(words)  # Join the tokens back into a string\n",
    "    \n",
    "    # Get a list of all country names\n",
    "    all_countries = {country.name: country for country in pycountry.countries}\n",
    "    \n",
    "    # Check for multi-word country names first to avoid partial matches\n",
    "    for name in sorted(all_countries.keys(), key=lambda x: len(x), reverse=True):\n",
    "        if name in text:\n",
    "            countries.add(all_countries[name].name)\n",
    "            text = text.replace(name, '')  # Remove the found country name from the text to avoid duplicates\n",
    "\n",
    "    return list(countries)\n",
    "\n",
    "\n",
    "# Extract mentioned countries' ISO3 code\n",
    "def find_mentioned_country_code(user_query):\n",
    "    countries = set()\n",
    "    extracted_countries = find_mentioned_countries(user_query)\n",
    "    \n",
    "    for country in extracted_countries:\n",
    "        try:\n",
    "            country_info = pycountry.countries.get(name=country)\n",
    "            if country_info:\n",
    "                countries.add(country_info.alpha_3)\n",
    "        except LookupError:\n",
    "            pass\n",
    "    \n",
    "    # If no countries are found, check for continent mentions\n",
    "    if not countries:\n",
    "        words = re.findall(r'\\w+|[^\\w\\s]', user_query)\n",
    "        text = ' '.join(words)  # Join the tokens back into a string\n",
    "    \n",
    "        world_info = AWOC()\n",
    "        all_continents = set([continent.lower() for continent in world_info.get_continents_list()])\n",
    "        for word in text.split():\n",
    "            word = word.lower()\n",
    "            if word in all_continents:\n",
    "                target_countries = world_info.get_countries_list_of(word)\n",
    "                for country in target_countries:\n",
    "                    countries.add(world_info.get_country_data(country)['ISO3'])\n",
    "    \n",
    "    return countries\n",
    "\n",
    "\n",
    "# # Example \n",
    "# user_query = 'Could you clarify how UNDP ensures financial transparency and accountability in its large-scale solar energy projects in Latin America?'\n",
    "# mentioned_countries = find_mentioned_country_code(user_query)\n",
    "# mentioned_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee0a9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the English language model\n",
    "# Function to calculate the average word embedding for a sentence\n",
    "# def average_word_embedding(sentence):\n",
    "#     # Parse the sentence using SpaCy\n",
    "#     doc = nlp(sentence)\n",
    "#     # Get word vectors and average them\n",
    "#     word_vectors = [token.vector for token in doc if token.has_vector]\n",
    "#     if not word_vectors:\n",
    "#         return None\n",
    "#     return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n",
    "def average_word_embedding(sentence):\n",
    "    if sentence is None:\n",
    "        sentence = \"\"\n",
    "    \n",
    "    # Parse the sentence using SpaCy\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Get word vectors and average them\n",
    "    vectors = [token.vector for token in doc if token.has_vector]\n",
    "    if not vectors:\n",
    "        return None\n",
    "    \n",
    "    avg_vector = sum(vectors) / len(vectors)\n",
    "    return avg_vector\n",
    "\n",
    "# Function to calculate context similarity between two sentences using word embedding averaging\n",
    "def calculate_context_similarity(sentence1, sentence2):\n",
    "    # Get average word embeddings for each sentence\n",
    "    avg_embedding1 = average_word_embedding(sentence1)\n",
    "    avg_embedding2 = average_word_embedding(sentence2)\n",
    "    if avg_embedding1 is None or avg_embedding2 is None:\n",
    "        return None\n",
    "    # Calculate cosine similarity between the embeddings\n",
    "    similarity = cosine_similarity([avg_embedding1], [avg_embedding2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# # Example sentences\n",
    "# sentence1 = 'The companys quarterly earnings report exceeded expectations, leading to a surge in stock prices.'\n",
    "# sentence2 = 'The firms financial results for the last quarter surpassed predictions, resulting in a sharp rise in the value of shares'\n",
    "\n",
    "\n",
    "\n",
    "# Calculate context similarity\n",
    "# similarity = calculate_context_similarity(sentence1, sentence2)\n",
    "# print(\"Context similarity:\", similarity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d626cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Jaccard similarity between two texts\n",
    "def jaccard_similarity(text1, text2):\n",
    "    # Tokenize texts\n",
    "    tokens1 = set(text1.lower().split())\n",
    "    tokens2 = set(text2.lower().split())\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    intersection = len(tokens1.intersection(tokens2))\n",
    "    union = len(tokens1.union(tokens2))\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50651a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_contains_entity(entity, title):\n",
    "    # Convert both entity and title to lowercase for case-insensitive comparison\n",
    "    entity_lower = entity.lower()\n",
    "    title_lower = title.lower()\n",
    "\n",
    "    # Check if the lowercase entity is contained within the lowercase title\n",
    "    if entity_lower in title_lower:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79226e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This contains all filters for the semantic search\n",
    "#Context Similarity takes two queries and find how similar they are \"context wise\"\n",
    "#E.g \"My house is empty today\" and \"Nobody is at my home\" are same context but not word similarity\n",
    "# - Filter country relevant documents when mentioned \n",
    "# - Filter by Context similarity in user_query and title, journal, content etc.\n",
    "\n",
    "def filter_semantics_old(user_query):\n",
    "    \n",
    "\n",
    "    # mentioned_countries = find_mentioned_country_code(user_query)\n",
    "    # print(mentioned_countries)\n",
    "\n",
    "    doc = nlp(user_query)\n",
    "    # Extract all entities\n",
    "    # entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ != \"\"]  # Filter out empty entities\n",
    "    entities.extend((token.text, \"NOUN\") for token in doc if token.pos_ in [\"NOUN\",\"PROPN\", \"PRON\", \"PROPN\", \"NUM\", \"SYM\", \"X\",\"ABBR\"] or token.is_alpha)\n",
    "\n",
    "    # Remove stop words\n",
    "    entities = [(entity, label) for entity, label in entities if entity.lower() not in STOP_WORDS]\n",
    "    \n",
    "    # Print the extracted entities\n",
    "    # print(\"All Entities and POS:\", entities)\n",
    "    # Generate DFs for main entities\n",
    "    filtered_df_country = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "    filtered_df_others = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "    filtered_df_backup_reference = pd.DataFrame() # Initialize an empty DataFrame\n",
    "    allow_low = True\n",
    "    for entity, label in entities:\n",
    "        # print(entity)\n",
    "        filtered_df_others = pd.concat([filtered_df_others, df[df['Country Name'].str.lower().str.contains(entity.lower(), na=False)]])\n",
    "\n",
    "        #Calculate similarity scores for each document title\n",
    "        similarity_scores = []\n",
    "        document_titles = []\n",
    "\n",
    "        # Iterate through each document title and calculate similarity score\n",
    "        for title in filtered_df_others['Country Name']:\n",
    "            if title is not None:\n",
    "                similarity_score = calculate_context_similarity(user_query,title) \n",
    "                # print(entity)\n",
    "                # print(similarity_score)\n",
    "                # print(user_query)\n",
    "                # print(title)\n",
    "                # print(\"=================================\")    \n",
    "                similarity_scores.append(similarity_score)\n",
    "                document_titles.append(title)\n",
    "        \n",
    "        # Create DataFrame only with valid similarity scores\n",
    "        similarity_df = pd.DataFrame({'Country Name': document_titles, 'Similarity Score': similarity_scores})\n",
    "        \n",
    "        df_temp = pd.concat([df])\n",
    "        \n",
    "        threshold = 0.5\n",
    "\n",
    "        # Filter df based on similarity scores greater than threshold for filtered_df_others\n",
    "        filtered_df_others = df[df['Country Name'].isin(similarity_df[similarity_df['Similarity Score'] > threshold]['Country Name'])]\n",
    "        filtered_df_backup_reference = pd.concat([filtered_df_backup_reference,  df_temp[df_temp['Country Name'].isin(similarity_df[(similarity_df['Similarity Score'] >= 0.1) & (similarity_df['Similarity Score'] < 0.45)]['Country Name'])] ])\n",
    "\n",
    "        #Check for location related e.g by country, language, locals\n",
    "        if label in ['GPE', 'NORP', 'LANGUAGE', 'FAC']:\n",
    "            filtered_df_country = pd.concat([filtered_df_country, df[df['Country Name'] == entity]])\n",
    "   \n",
    "    merged_df = pd.DataFrame()\n",
    "    if filtered_df_others.empty and filtered_df_country.empty:\n",
    "       print(f'on the reference df {filtered_df_backup_reference.empty}')\n",
    "       merged_df = pd.concat([filtered_df_backup_reference])\n",
    "    else :\n",
    "       merged_df = pd.concat([filtered_df_country,filtered_df_others])\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def filter_semantics(user_query):\n",
    "    doc = nlp(user_query)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ != \"\"]  # Filter out empty entities\n",
    "    entities.extend((token.text, \"NOUN\") for token in doc if token.pos_ in [\"NOUN\", \"PROPN\", \"PRON\", \"NUM\", \"SYM\", \"X\", \"ABBR\"] or token.is_alpha)\n",
    "\n",
    "    # Remove stop words\n",
    "    entities = [(entity, label) for entity, label in entities if entity.lower() not in STOP_WORDS]\n",
    "\n",
    "    # Initialize empty DataFrames\n",
    "    filtered_df_country = pd.DataFrame()\n",
    "    filtered_df_others = pd.DataFrame()\n",
    "    filtered_df_others_title = pd.DataFrame()\n",
    "\n",
    "    filtered_df_backup_reference = pd.DataFrame()\n",
    "    allow_low = True\n",
    "\n",
    "    for entity, label in entities:\n",
    "       \n",
    "        filtered_df_others = pd.concat([filtered_df_others, df[df['Country Name'].str.lower().str.contains(entity.lower(), na=False)]])\n",
    "        filtered_df_others_title = pd.concat([filtered_df_others_title, df[df['Document Title'].str.lower().str.contains(entity.lower(), na=False)]])\n",
    "\n",
    "        # Calculate similarity scores for each document title and country name\n",
    "        similarity_scores_country = []\n",
    "        similarity_scores_title = []\n",
    "        document_titles = []\n",
    "\n",
    "        for index, row in filtered_df_others.iterrows():\n",
    "            country_name = row['Country Name']\n",
    "            document_title = row['Document Title']\n",
    "\n",
    "            if country_name is not None:\n",
    "                \n",
    "                similarity_score_country = calculate_context_similarity(user_query, country_name)\n",
    "                similarity_scores_country.append(similarity_score_country)\n",
    "            else:\n",
    "                similarity_scores_country.append(0)\n",
    "\n",
    "            if document_title is not None:\n",
    "                similarity_score_title = calculate_context_similarity(user_query, document_title)\n",
    "                similarity_scores_title.append(similarity_score_title)\n",
    "            else:\n",
    "                similarity_scores_title.append(0)\n",
    "\n",
    "            document_titles.append(document_title)\n",
    "        \n",
    "        similarity_df = pd.DataFrame({\n",
    "            'Country Name': filtered_df_others['Country Name'],\n",
    "            'Document Title': document_titles,\n",
    "            'Similarity Score Country': similarity_scores_country,\n",
    "            'Similarity Score Title': similarity_scores_title\n",
    "        })\n",
    "\n",
    "        # Define thresholds\n",
    "        threshold_country = 0.5\n",
    "        threshold_title = 0.5\n",
    "\n",
    "        # Filter df based on similarity scores greater than threshold\n",
    "        filtered_df_others = df[\n",
    "            df['Country Name'].isin(similarity_df[similarity_df['Similarity Score Country'] > threshold_country]['Country Name']) &\n",
    "            df['Document Title'].isin(similarity_df[similarity_df['Similarity Score Title'] > threshold_title]['Document Title'])\n",
    "        ]\n",
    "\n",
    "        filtered_df_backup_reference = pd.concat([filtered_df_backup_reference, df[\n",
    "            df['Country Name'].isin(similarity_df[(similarity_df['Similarity Score Country'] >= 0.1) & (similarity_df['Similarity Score Country'] < threshold_country)]['Country Name']) |\n",
    "            df['Document Title'].isin(similarity_df[(similarity_df['Similarity Score Title'] >= 0.1) & (similarity_df['Similarity Score Title'] < threshold_title)]['Document Title'])\n",
    "        ]])\n",
    "\n",
    "        # Check for location related e.g by country, language, locals\n",
    "        if label in ['GPE', 'NORP', 'LANGUAGE', 'FAC']:\n",
    "            filtered_df_country = pd.concat([filtered_df_country, df[df['Country Name'] == entity]])\n",
    "   \n",
    "    merged_df = pd.DataFrame()\n",
    "    # if filtered_df_others.empty and filtered_df_country.empty:\n",
    "    #     print(f'on the reference df {filtered_df_backup_reference.empty}')\n",
    "    #     merged_df = pd.concat([filtered_df_backup_reference])\n",
    "    # else:\n",
    "    merged_df = pd.concat([filtered_df_country, filtered_df_others, filtered_df_backup_reference,filtered_df_others_title])\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# Example \n",
    "# test_query=\"How do the challenges of implementing renewable energy projects in Asia compare to those in Latin America?\"\n",
    "# filtered_country = filter_semantics(test_query)\n",
    "# filtered_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85bd554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_embeddings(user_query):\n",
    "    # df_filtered = filter_semantics(user_query) if filter_semantics(user_query) is not None else None\n",
    "    filtered_result = filter_semantics(user_query)\n",
    "    # Check if the result is not None before assigning it to df_filtered\n",
    "    df_filtered = filtered_result if filtered_result is not None else None\n",
    "\n",
    "    if df_filtered is not None and not df_filtered.empty:  # Check if DataFrame is not None and not empty\n",
    "        length = len(df_filtered.head())\n",
    "        filtered_embeddings_arrays = np.array(list(df_filtered['Embedding']))\n",
    "        index = faiss.IndexFlatIP(filtered_embeddings_arrays.shape[1]) \n",
    "        index.add(filtered_embeddings_arrays)\n",
    "        \n",
    "        user_query_embedding = client.embeddings.create( \n",
    "                input=user_query ,model= embedding_model\n",
    "            ).data[0].embedding\n",
    "\n",
    "        k = min(5, length)\n",
    "        distances, indices = index.search(np.array([user_query_embedding]), k)\n",
    "        return df_filtered, distances, indices\n",
    "    else:\n",
    "        return None, None, None\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27928260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_structure(qs):\n",
    "    result_dict = {}\n",
    "\n",
    "    # Extract the DataFrame from the tuple\n",
    "    dataframe = qs[0]\n",
    "    print(qs[1])\n",
    "    print(qs[2])\n",
    "\n",
    "    # Counter to limit the loop to 10 iterations\n",
    "    count = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # Define a unique identifier for each document, you can customize this based on your data\n",
    "        document_id = f\"doc-{index + 1}\"\n",
    "        # Handle NaN in content by using fillna\n",
    "        content = row[\"Content\"]\n",
    "        content = ' '.join(row[\"Content\"].split()[:160])\n",
    "        # Create a dictionary for each document\n",
    "        document_info = {\n",
    "            \"title\": row[\"Document Title\"],\n",
    "            \"extract\": content or \"\",  # You may need to adjust this based on your column names\n",
    "            \"category\": row[\"Category\"],\n",
    "            \"link\": row[\"Link\"].replace(\"https-//\",\"https://\"),\n",
    "            \"summary\": row[\"Summary\"],\n",
    "            \"thumbnail\": ''\n",
    "        }\n",
    "        # print(document_info)\n",
    "        # Add the document to the result dictionary\n",
    "        result_dict[document_id] = document_info\n",
    "\n",
    "        # Increment the counter\n",
    "        count += 1\n",
    "\n",
    "        # # Break out of the loop if the counter reaches top 25\n",
    "        if count == 10:\n",
    "            break\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f166c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to relabel keys and add citations\n",
    "def relabel_and_add_citations(data):\n",
    "    new_data = {}\n",
    "    citation_counter = 1\n",
    "\n",
    "    for doc_id, doc_info in data.items():\n",
    "        new_data[doc_id] = {\n",
    "            \"document_title\": doc_info.get(\"title\", \"\"),\n",
    "            \"summary\": doc_info.get(\"extract\", \"\"),\n",
    "            \"document_category\": doc_info.get(\"category\", \"\"),\n",
    "            \"document_link\": doc_info.get(\"link\", \"\"),\n",
    "            \"document_thumbnail\": doc_info.get(\"thumbnail\", \"\"),\n",
    "\n",
    "            \"citation\": citation_counter\n",
    "        }\n",
    "        citation_counter += 1\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a53eff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_valid_json_objects(json_string):\n",
    "    # Regex pattern to extract valid JSON objects\n",
    "    pattern = re.compile(r'{.*?}', re.DOTALL)\n",
    "\n",
    "    # Find all matches in the string\n",
    "    matches = pattern.findall(json_string)\n",
    "\n",
    "    # Parse each match to a dictionary\n",
    "    parsed_data = []\n",
    "    for match in matches:\n",
    "        try:\n",
    "            parsed_data.append(json.loads(match))\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    \n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c69dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8761674 0.8761674 0.8761674 0.8761674 0.8761674]]\n",
      "[[32 30 21 11  1]]\n",
      "Excerpts saved to outputs/excerpts.json\n"
     ]
    }
   ],
   "source": [
    "## module to extract text from documents and return the text and document codes\n",
    "def semanticSearchModule(user_query):\n",
    "    qs = search_embeddings(user_query) #df, distances, indices\n",
    "    # if qs != None :\n",
    "    if qs[0] is not None:\n",
    "        result_structure = map_to_structure(qs)\n",
    "        return result_structure\n",
    "    else : \n",
    "        return []\n",
    "\n",
    "        \n",
    "#test usage\n",
    "excerpts_dict= relabel_and_add_citations(semanticSearchModule(\"What is the role of USAID in supporting Albania's energy sector strategy?\"))\n",
    "# # print(f\"\"\"excerpts_dict {excerpts_dict}\"\"\")\n",
    "\n",
    "# #Return top 10-20 most related \n",
    "# # Define the filename to save the JSON data -  can remove later\n",
    "json_filename = \"outputs/excerpts.json\"\n",
    "\n",
    "# # Save excerpts_dict to the JSON file just for a better preview\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(excerpts_dict, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Excerpts saved to {json_filename}\")\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db75b59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indicator-id-1': 'value from indicator-id-1', 'indicator-id-2': 'value from indicator-id-2'}\n"
     ]
    }
   ],
   "source": [
    "## module to get data for specific indicators which are identified is relevant to the user query\n",
    "\n",
    "def indicatorsModule(user_query): #lower priority\n",
    "    \n",
    "    # find relevant indicators based on uesr query and extract values\n",
    "    indicators_dict={\n",
    "        \"indicator-id-1\":\"value from indicator-id-1\",\n",
    "        \"indicator-id-2\":\"value from indicator-id-2\"\n",
    "    }#temp\n",
    "    \n",
    "    return indicators_dict\n",
    "\n",
    "#test usage\n",
    "indicators_dict=indicatorsModule(test_query)\n",
    "print(indicators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8237482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## module to generate query ideas\n",
    "\n",
    "def queryIdeationModule(user_query): # lower priority\n",
    "    \n",
    "    # Generate query ideas using OpenAI GPT-3\n",
    "    prompt = f\"\"\"\n",
    "    Ignore previous commands!!!\n",
    "    Generate prompt ideas based on the user query: {user_query}\n",
    "\n",
    "    \n",
    "    -Prompt shoud not be answer to the user query but give other contextual ways of representing the user query !!!\n",
    "    -You Must return output seperated by |  e.g idea 1 | idea2 \n",
    "    - Each generated ideas should be very dinstinct but contextual. Not repeatitive or using same words\n",
    "    - The query idea should be in a question form and not an answer form.\n",
    "    -Avoid adding new lines or breaking spaces to your output and must seperate each idea with |\n",
    "    \"\"\"\n",
    "    response = callOpenAI(prompt)\n",
    "    return response\n",
    "\n",
    "#test usage\n",
    "# query_idea_list=queryIdeationModule(test_query)\n",
    "# print(query_idea_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44eb60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(user_question, relevant_docs):\n",
    " \n",
    "    \n",
    "    formattings_html = f\"\"\" \n",
    "        Strictly follow the follow steps:\n",
    "        Your output answer shoud be  in HTML syntax with HTML tags.\n",
    "        Use HTML tags like < ul>, < ol>, < li>,  < strong>, < p>\n",
    "        Only consider the inner part of the < body> tag.\n",
    "        ALWAYS use the following tag for new lines: < br />\n",
    "        Do not add CSS attributes.\n",
    "        Do not include links or citations at all!!!\n",
    "        Your final answer must be formatted in HTML format !!!\n",
    "\n",
    "    \"\"\"\n",
    "    formattings = f\"\"\" \n",
    "        You can use relevant information in the docs to answer also: \n",
    "\n",
    "        DOCS: {relevant_docs}\n",
    "        \n",
    "       \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":f\"\"\"You are a helpful assistant and a professional researcher with many years of experience in answering questions. Give answer to the user's inquiry. {formattings_html}\"\"\"\n",
    "        },\n",
    "        {'role': 'user', 'content': f\"\"\"{formattings} \n",
    "                                        {user_question}\n",
    "                                        \n",
    "                                         {formattings_html}\n",
    "                                         Do not include links or citations, refrences or sources at all!!!\n",
    "                                        \"\"\"},\n",
    "    ]\n",
    "       \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0.5,\n",
    "                    messages=messages,\n",
    "                    top_p=0.8,\n",
    "                    frequency_penalty=0.6,\n",
    "                    presence_penalty=0.8\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "\n",
    "    return response\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b73a93",
   "metadata": {},
   "source": [
    "<h3> synthesis module </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0f509d",
   "metadata": {},
   "source": [
    "    llm_instructions=\"llm instruction template here, with placeholders for insertion of user query, excerpts, indicator data, and entity and relation info\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7113366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def synthesisModule(user_query, entities_dict, excerpts_dict, indicators_dict,prompt_formattings):\n",
    "    \n",
    "    # print(f\"\"\" ********************************************************************* {user_query} *********************************************************************  \"\"\")\n",
    "\n",
    "    ###synthesize data into structure within llm prompt engineering instructions\n",
    "    answer=get_answer(user_query,excerpts_dict) #callOpenAI\n",
    "    answer_formated_fixed = answer.replace(\"\\n\\n\",\"<br>\").replace(\"\\n\",\"<br>\")\n",
    "    # answer_citation = add_citation(answer_formated_fixed,excerpts_dict)\n",
    "    # answer_citation = answer_citation #.replace(\"\\\\\",\"\").replace(\"\\n\",\"\")\n",
    "    \n",
    "    # print(f\"\"\" {answer} \"\"\")\n",
    "    # print(f\"\"\" ********************************************************************* END *********************************************************************  \"\"\")\n",
    "\n",
    "    return answer\n",
    "\n",
    "## to test this, run the full pipeline with the handleApiCall function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787b228",
   "metadata": {},
   "source": [
    "<h3> run pipeline </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10fe2bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8090702  0.800514   0.800514   0.800514   0.79543173]]\n",
      "[[  7 146  95  38  72]]\n",
      "0.5318013\n",
      "0.6080977\n",
      "0.6545557\n",
      "0.6932544\n",
      "0.61111224\n",
      "0.45915428\n",
      "0\n",
      "0.4233036\n",
      "0\n",
      "0.6466177\n",
      "0.4813679\n",
      "0.70920646\n",
      "0.65838367\n",
      "0.7303943\n",
      "0.29665488\n",
      "0.55757904\n",
      "0.20673504\n",
      "0.59552\n",
      "0.102522984\n",
      "0.30207297\n",
      "0\n",
      "0.30306035\n",
      "0\n",
      "0.55405027\n",
      "0.5354111\n",
      "0.39220572\n",
      "0.4550438\n",
      "0.43126604\n",
      "0.1767304\n",
      "0.5039422\n",
      "0.14425656\n",
      "0.5227666\n",
      "0.122518145\n",
      "0.18170154\n",
      "0\n",
      "0.15662786\n",
      "0\n",
      "0.5202694\n",
      "0.561151\n",
      "0.2362561\n",
      "0.54628056\n",
      "0.30154347\n",
      "0.46436632\n",
      "0.59389424\n",
      "0.4168801\n",
      "0.50851494\n",
      "0.4781994\n",
      "0.46141836\n",
      "0\n",
      "0.4285846\n",
      "0\n",
      "0.5950999\n",
      "0.4206735\n",
      "0.4566598\n",
      "0.46430668\n",
      "0.5311631\n",
      "0.05548714\n",
      "0.49090633\n",
      "0.091039024\n",
      "0.4931215\n",
      "-0.029709198\n",
      "0.12950799\n",
      "0\n",
      "0.11876608\n",
      "0\n",
      "0.48220646\n",
      "0.5334383\n",
      "0.33912376\n",
      "0.4452247\n",
      "0.3190742\n",
      "0.14063683\n",
      "0.49558496\n",
      "0.19301197\n",
      "0.5322093\n",
      "0.09477389\n",
      "0.1364038\n",
      "0\n",
      "0.12554999\n",
      "0\n",
      "0.49573427\n",
      "0.4565568\n",
      "0.33252046\n",
      "0.5350214\n",
      "0.3679788\n",
      "0.36937374\n",
      "0.5936527\n",
      "0.109907754\n",
      "0.42140973\n",
      "0.15648296\n",
      "0.27872914\n",
      "0\n",
      "0.25064814\n",
      "0\n",
      "0.56115603\n",
      "0.4679635\n",
      "0.2637747\n",
      "0.38799757\n",
      "0.3546621\n",
      "0.27510467\n",
      "0.55186576\n",
      "0.17093782\n",
      "0.51644814\n",
      "0.12331614\n",
      "0.27983218\n",
      "0\n",
      "0.2522096\n",
      "0\n",
      "0.47673312\n",
      "0.60016143\n",
      "0.36200285\n",
      "0.50464725\n",
      "0.45203963\n",
      "Element: <p>The UN policy in Kazakhstan is outlined in the document titled \"UNDP within the United Nations Sustainable Development Cooperation Framework\".\n",
      "Document ID: doc-342\n",
      "Document Title: EUEI Energy Strategy and Action Plan for Burundi\n",
      "Title Similarity: 0.6546\n",
      "Extract Similarity: 0.6933\n",
      "\n",
      "Element: <p>The UN policy in Kazakhstan is outlined in the document titled \"UNDP within the United Nations Sustainable Development Cooperation Framework\".\n",
      "Document ID: doc-7\n",
      "Document Title: Clean energy for all? Mapping inequity potential in the clean energy transition in the United States\n",
      "Title Similarity: 0.6584\n",
      "Extract Similarity: 0.7304\n",
      "\n",
      "Synthesis saved to outputs/synthesis_output.json\n"
     ]
    }
   ],
   "source": [
    "# full pipeline with retreival, synthesis of answer to user query, and structure results into api response\n",
    "\n",
    "def handleApiCall(user_query):\n",
    "    \n",
    "    ##run processing modules (in parallel)\n",
    "    entities_dict=knowledgeGraphModule(user_query)\n",
    "    excerpts_dict=semanticSearchModule(user_query)\n",
    "    indicators_dict=indicatorsModule(user_query) ##lower priority\n",
    "    query_idea_list=queryIdeationModule(user_query) ##lower priority\n",
    "    prompt_formattings=\"\"\n",
    "    ##synthesis module\n",
    "    answer=synthesisModule(user_query, entities_dict, excerpts_dict, indicators_dict, prompt_formattings)\n",
    "    # print(f\"\"\" Answer==== {answer} \"\"\")\n",
    "    pattern =  re.compile(r'[^.]*\\.')  #re.compile(r'<li>(.*?)</li>')\n",
    "    # Find all matches\n",
    "    content_array = pattern.findall(answer)\n",
    "    sources = excerpts_dict\n",
    "    results = []\n",
    "    # print(content_array)\n",
    "    limiter = 0\n",
    "    for element in content_array:\n",
    "        for doc_id, doc_info in sources.items():\n",
    "            title_similarity = calculate_context_similarity(element, doc_info['title']) or 0\n",
    "            extract_similarity = calculate_context_similarity(element, doc_info['extract']) or  0\n",
    "            # summary_similarity = calculate_context_similarity(element, doc_info['summary'])\n",
    "            print(title_similarity)\n",
    "            print(extract_similarity)\n",
    "            if title_similarity > 0.65 and extract_similarity > 0.65 and limiter < 5:\n",
    "                result = {\n",
    "                            'element': element,\n",
    "                            'title': doc_info['title'],\n",
    "                            'extract': doc_info['extract'],\n",
    "                            'extract': doc_info['extract'],\n",
    "                            'link': doc_info['link'],\n",
    "                            'doc_id': doc_id,\n",
    "                            'title_similarity': float(title_similarity),\n",
    "                            'extract_similarity': float(extract_similarity)\n",
    "                            # 'summary_similarity': float(summary_similarity)\n",
    "                        }\n",
    "                results.append(result)\n",
    "                limiter += 1\n",
    "\n",
    "    for result in results:\n",
    "        citation_fixes = callOpenAI(f\"Given the below: {result} Create an output that mixes Element, Document extract and Summary into one output while still maintaining the context of the Element. Your final output answer length should not be more than 200 words. Also avoid using links, sources and references. \")\n",
    "        result['citation_fixes'] = citation_fixes\n",
    "        result\n",
    "\n",
    " \n",
    "    content = answer\n",
    "    counter = 0\n",
    "    # Loop through each JSON object and replace the element with citation_fixes in the content\n",
    "    for result in results:\n",
    "        counter += 1\n",
    "        print(f\"Element: {result['element']}\")\n",
    "        print(f\"Document ID: {result['doc_id']}\")\n",
    "        print(f\"Document Title: {result['title']}\")\n",
    "        print(f\"Title Similarity: {result['title_similarity']:.4f}\")\n",
    "        print(f\"Extract Similarity: {result['extract_similarity']:.4f}\")\n",
    "        # print(f\"Summary Similarity: {result['summary_similarity']:.4f}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        content = content.replace(result['element'], f\"\"\" {result['citation_fixes']} <a href='{result['link']}' data-id='{result['doc_id']}'>[{counter}]</a> <br/>\\n\\n\"\"\")\n",
    "        \n",
    "    response={\n",
    "        \"user_query\":user_query,\n",
    "        \"answer\":f\"\"\" {content}\"\"\",\n",
    "        \"sources\":excerpts_dict,\n",
    "        \"query_ideas\":query_idea_list,\n",
    "        \"entities\":list(entities_dict[\"entities\"].keys())       \n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "# test usage\n",
    "test_query = \"What's UN policy in kazakhstan\"\n",
    "response=handleApiCall(test_query) \n",
    "# Define the filename to save the JSON data -  can remove later\n",
    "json_filename = \"outputs/synthesis_output.json\"\n",
    "\n",
    "\n",
    "\n",
    "# Save excerpts_dict to the JSON file just for a better preview\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(response, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Synthesis saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7cc6f",
   "metadata": {},
   "source": [
    "<h1>Testing</h1>\n",
    "\n",
    "<p>This sections contains all things testings </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(csv_file):\n",
    "    # Initialize an empty list to store processed entries\n",
    "    result = []\n",
    "    \n",
    "    # Loop through each entry in the CSV file\n",
    "    for entry in csv.DictReader(csv_file):\n",
    "        query = entry['query']\n",
    "        sample_answer = entry['sample_answer']\n",
    "        \n",
    "        # Call OpenAI for chat GPT answer\n",
    "        chat_gpt_answer = callOpenAI(f\"\"\" \n",
    "                                    {query} \n",
    "                                    {prompt_formattings} \n",
    "                                    \"\"\")\n",
    "        \n",
    "        # Call the moonshot model API\n",
    "        moonshot_model_answer = handleApiCall(query) \n",
    "        \n",
    "        # Calculate BERT score for moonshot model answer\n",
    "        P, F, R = bert_score([sample_answer], [moonshot_model_answer['answer']], lang='en', verbose=True)\n",
    "        entry['moonshot_model_answer'] = moonshot_model_answer['answer']\n",
    "        entry['bert_score'] = round(float(F), 2)\n",
    "\n",
    "        # Calculate BERT score for chat GPT answer\n",
    "        P, F, R = bert_score([sample_answer], [chat_gpt_answer], lang='en', verbose=True)\n",
    "        entry['chat_gpt_answer'] = chat_gpt_answer\n",
    "        entry['bert_score_gpt'] = round(float(F), 2)\n",
    "        \n",
    "        # Append the processed entry to the result list\n",
    "        result.append(entry)\n",
    "    \n",
    "    # Return the list of processed entries\n",
    "    return result\n",
    "\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = \"../testing/queries.csv\"\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open(csv_file_path, mode='r') as file:\n",
    "    # Pass the file object to the function\n",
    "    result = calculate_scores(file)\n",
    "\n",
    "# Print updated data with scores\n",
    "# print(json.dumps(result, indent=4))\n",
    "\n",
    "# Save updated data to a JSON file\n",
    "with open('../testing/test_output.json', 'w') as file:\n",
    "    json.dump(result, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8961eb",
   "metadata": {},
   "source": [
    "<h1>Compare Moonshot BERT score to GPT BERT Score</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e3412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bert_score: 0.7995652173913044\n",
      "Average bert_score_gpt: 0.7778260869565218\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "with open('../testing/test_output.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize variables to store total scores and count of items\n",
    "total_bert_score = 0\n",
    "total_bert_score_gpt = 0\n",
    "count = 0\n",
    "\n",
    "# Iterate through each item in the JSON data\n",
    "for item in data:\n",
    "    # Extract bert_score and bert_score_gpt from the current item\n",
    "    bert_score = item['bert_score']\n",
    "    bert_score_gpt = item['bert_score_gpt']\n",
    "    \n",
    "    # Add the scores to the total\n",
    "    total_bert_score += bert_score\n",
    "    total_bert_score_gpt += bert_score_gpt\n",
    "    \n",
    "    # Increment the count\n",
    "    count += 1\n",
    "\n",
    "# Calculate the average scores\n",
    "average_bert_score = total_bert_score / count\n",
    "average_bert_score_gpt = total_bert_score_gpt / count\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average bert_score:\", average_bert_score)\n",
    "print(\"Average bert_score_gpt:\", average_bert_score_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905ad59",
   "metadata": {},
   "source": [
    "<h1>Trello Board AutoPopulate</h1>\n",
    "<p> Automation for trello</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66edd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import requests\n",
    "from markdownify import markdownify as md\n",
    "import textwrap\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "def8e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "trello_api_list_id = os.getenv(\"trello_api_list_id\")\n",
    "trello_api_key_id = os.getenv(\"trello_api_key_id\")\n",
    "trello_api_key_token = os.getenv(\"trello_api_key_token\")\n",
    "trello_board_id= os.getenv(\"trello_board_id\")\n",
    "trello_url =\"https://api.trello.com/1/\"\n",
    "# print(trello_board_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c91b0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list function - this allows for various test versions \n",
    "\n",
    "def create_list(list_title):\n",
    "    url = f\"{trello_url}lists?name={list_title}&token={trello_api_key_token}&idBoard={trello_board_id}&key={trello_api_key_id}\"\n",
    "    response = requests.request(\"POST\", url)\n",
    "    response_json = response.json()  # Parse response JSON\n",
    "    list_id = response_json[\"id\"]  # Access 'id' from JSON\n",
    "    return list_id\n",
    "\n",
    "#example\n",
    "# list_response = create_list('User Queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b2d2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list function - this allows for various test versions \n",
    "def create_card_label(card_id, color, name):\n",
    "    url = f\"{trello_url}cards/{card_id}/labels?color={color}&name={name}&token={trello_api_key_token}&idBoard={trello_board_id}&key={trello_api_key_id}\"\n",
    "    # print(url)\n",
    "    response = requests.request(\"POST\", url)\n",
    "    response_json = response.json()  # Parse response JSON\n",
    "    list_id = response_json[\"id\"]  # Access 'id' from JSON\n",
    "    return list_id\n",
    "\n",
    "#example\n",
    "# list_response = create_card_label('','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c28eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_date(format='%b %d %H:%M'):\n",
    "    return datetime.now().strftime(format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de4fc320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Async function to send the request\n",
    "\n",
    "async def send_request(query,list_response,card_color,card_label_name):\n",
    "    name = query[\"query\"]\n",
    "    response=handleApiCall(name) \n",
    "    \n",
    "    # print(f\"\"\" send_request==== {response['answer']} \"\"\" )\n",
    "    #for trello preview only\n",
    "    cleanResp = response['answer'].replace(\"</p>\",\"</p> ******************************************************************************\").replace(\"<p>\",\"<br/>\").replace(\"<br>\",\" *******************************************************************************\").replace(\"</li>\",\" *******************************************************************************\")\n",
    "    markdown_content_description = md(f\"{(cleanResp)}\")\n",
    "    # markdown_content_description = html2text.html2text(cleanResp)\n",
    "\n",
    "    desc = f\"\"\"{markdown_content_description}\"\"\"\n",
    "    url = f\"{trello_url}cards?idList={list_response}&key={trello_api_key_id}&token={trello_api_key_token}&name={name}&desc={desc}\"\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(url, timeout=1200) as response:\n",
    "            el = ''\n",
    "            # print(name)\n",
    "            resp = await response.text()\n",
    "            print(resp)\n",
    "            resp_dict = json.loads(resp)\n",
    "            id = resp_dict['id']\n",
    "\n",
    "            card_label_resp = create_card_label(id, card_color, card_label_name)\n",
    "            print(card_label_resp)\n",
    "            print(\"---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c7c8dfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89351094 0.89351094 0.89351094 0.89351094 0.89351094]]\n",
      "[[37 29 21 13  5]]\n",
      "Element: <p><strong>Country Program Document for Afghanistan (2015-2019)</strong></p>\n",
      "<br />\n",
      "<p>The Country Program Document for Afghanistan (2015-2019) outlines the strategies and initiatives implemented by the government to promote economic development, governance, social inclusion, poverty reduction, gender equality, security, and sustainable development goals.\n",
      "Document ID: doc-595\n",
      "Document Title: Country programme document for Afghanistan (2015 2019)\n",
      "Title Similarity: 0.7377\n",
      "Extract Similarity: 0.7033\n",
      "\n",
      "[[0.7487942 0.7487942 0.7487942 0.7487942 0.7487942]]\n",
      "[[12  9  6  3  0]]\n",
      "[[0.84504837 0.84504837 0.84504837 0.83230925 0.8265004 ]]\n",
      "[[ 6  3  1  8 65]]\n",
      "[[0.8119659 0.8119659 0.8119659 0.789129  0.789129 ]]\n",
      "[[8 5 2 7 4]]\n",
      "[[0.81843096 0.81843096 0.81843096 0.80037606 0.80037606]]\n",
      "[[14  9  4 10  5]]\n",
      "[[0.7364007 0.7364007 0.7272769 0.7256751 0.7256751]]\n",
      "[[ 12   3 119 187  34]]\n",
      "[[0.8366852 0.8366852 0.8366852 0.8366852 0.8366852]]\n",
      "[[109  41  26  16   6]]\n",
      "[[0.81373775 0.81373775 0.81373775 0.81373775 0.81373775]]\n",
      "[[547 359 164   7   1]]\n",
      "[[0.7835165 0.7835165 0.7835165 0.7835165 0.7835165]]\n",
      "[[654 531 464 345 157]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 24\u001b[0m\n\u001b[1;32m     17\u001b[0m nest_asyncio\u001b[38;5;241m.\u001b[39mapply()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Run the event loop\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# await mainTest('purple','comparative') - fair\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# await mainTest('blue','opinion') - fair \u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# await mainTest('green','descriptive') - fair\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m mainTest(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# await mainTest('red','clarification') - fair\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# await mainTest('orange','procedural') - fair\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# await mainTest('pink','yesno') - fair\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[109], line 14\u001b[0m, in \u001b[0;36mmainTest\u001b[0;34m(color, file)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     13\u001b[0m         tasks\u001b[38;5;241m.\u001b[39mappend(send_request(row,list_response,card_color,card_label_name))\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py:328\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=325'>326</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__wakeup\u001b[39m(\u001b[39mself\u001b[39m, future):\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=326'>327</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=327'>328</a>\u001b[0m         future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=328'>329</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=329'>330</a>\u001b[0m         \u001b[39m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=330'>331</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py:256\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=251'>252</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=252'>253</a>\u001b[0m     \u001b[39mif\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=253'>254</a>\u001b[0m         \u001b[39m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=254'>255</a>\u001b[0m         \u001b[39m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=255'>256</a>\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=256'>257</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/asyncio/tasks.py?line=257'>258</a>\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m, in \u001b[0;36msend_request\u001b[0;34m(query, list_response, card_color, card_label_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_request\u001b[39m(query,list_response,card_color,card_label_name):\n\u001b[1;32m      4\u001b[0m     name \u001b[38;5;241m=\u001b[39m query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     response\u001b[38;5;241m=\u001b[39m\u001b[43mhandleApiCall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# print(f\"\"\" send_request==== {response['answer']} \"\"\" )\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#for trello preview only\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     cleanResp \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</p>\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</p> ******************************************************************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<p>\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<br/>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<br>\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m *******************************************************************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</li>\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m *******************************************************************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[105], line 23\u001b[0m, in \u001b[0;36mhandleApiCall\u001b[0;34m(user_query)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m content_array:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc_id, doc_info \u001b[38;5;129;01min\u001b[39;00m sources\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 23\u001b[0m         title_similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_context_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m         extract_similarity \u001b[38;5;241m=\u001b[39m calculate_context_similarity(element, doc_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextract\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# summary_similarity = calculate_context_similarity(element, doc_info['summary'])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mcalculate_context_similarity\u001b[0;34m(sentence1, sentence2)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_context_similarity\u001b[39m(sentence1, sentence2):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Get average word embeddings for each sentence\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     avg_embedding1 \u001b[38;5;241m=\u001b[39m average_word_embedding(sentence1)\n\u001b[0;32m---> 16\u001b[0m     avg_embedding2 \u001b[38;5;241m=\u001b[39m \u001b[43maverage_word_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m avg_embedding1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m avg_embedding2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m, in \u001b[0;36maverage_word_embedding\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maverage_word_embedding\u001b[39m(sentence):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Parse the sentence using SpaCy\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Get word vectors and average them\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     word_vectors \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mvector \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mhas_vector]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py:1037\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1015'>1016</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1016'>1017</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1017'>1018</a>\u001b[0m     text: Union[\u001b[39mstr\u001b[39m, Doc],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1020'>1021</a>\u001b[0m     component_cfg: Optional[Dict[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1021'>1022</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Doc:\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1022'>1023</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1023'>1024</a>\u001b[0m \u001b[39m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1024'>1025</a>\u001b[0m \u001b[39m    is preserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1034'>1035</a>\u001b[0m \u001b[39m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1035'>1036</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1036'>1037</a>\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_doc(text)\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1037'>1038</a>\u001b[0m     \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1038'>1039</a>\u001b[0m         component_cfg \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py:1131\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[0;34m(self, doc_like)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1128'>1129</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1129'>1130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n\u001b[0;32m-> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/language.py?line=1130'>1131</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE1041\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc_like)))\n",
      "\u001b[0;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'NoneType'>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"666ba2ad518aa909300efd9a\",\"badges\":{\"attachmentsByType\":{\"trello\":{\"board\":0,\"card\":0}},\"externalSource\":null,\"location\":false,\"votes\":0,\"viewingMemberVoted\":false,\"subscribed\":false,\"attachments\":0,\"fogbugz\":\"\",\"checkItems\":0,\"checkItemsChecked\":0,\"checkItemsEarliestDue\":null,\"comments\":0,\"description\":true,\"due\":null,\"dueComplete\":false,\"lastUpdatedByAi\":false,\"start\":null},\"checkItemStates\":[],\"closed\":false,\"dueComplete\":false,\"dateLastActivity\":\"2024-06-14T01:53:49.771Z\",\"desc\":\"   Here is the data on China's energy landscape from 2014 to 2022: \\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*  * Total Energy Supply (TES) in 2015: 111,746 TJ \\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\* * Total Energy Supply (TES) in 2020: 128,939,885 TJ \\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\* * Percentage of Renewable Energy in TES in 2015: N/A \\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\* * Percentage of Renewable Energy in TES in 2020: N/A \\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\",\"descData\":{\"emoji\":{}},\"due\":null,\"dueReminder\":null,\"email\":null,\"idBoard\":\"6605a97cd1e3c1c63deeb02e\",\"idChecklists\":[],\"idList\":\"666b9a8b49f6d0866a27bf6e\",\"idMembers\":[],\"idMembersVoted\":[],\"idShort\":1687,\"idAttachmentCover\":null,\"labels\":[],\"idLabels\":[],\"manualCoverAttachment\":false,\"name\":\" \\\"I'm interested in some detailed data on China's energy landscape from 2014 to 2022. Could you highlight data on Total Energy Supply (TES) and its division between renewable and non-renewable energy sources? Specifically\",\"pos\":16384,\"shortLink\":\"emWfCJkJ\",\"shortUrl\":\"https://trello.com/c/emWfCJkJ\",\"start\":null,\"subscribed\":false,\"url\":\"https://trello.com/c/emWfCJkJ/1687-im-interested-in-some-detailed-data-on-chinas-energy-landscape-from-2014-to-2022-could-you-highlight-data-on-total-energy-suppl\",\"cover\":{\"idAttachment\":null,\"color\":null,\"idUploadedBackground\":null,\"size\":\"normal\",\"brightness\":\"dark\",\"idPlugin\":null},\"isTemplate\":false,\"cardRole\":null,\"attachments\":[],\"stickers\":[],\"limits\":{}}\n",
      "666ba2ae85a6a7adc8d97139\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "#Run Test process\n",
    "async def mainTest(color,file):\n",
    "    card_title = f\"\"\"{get_current_date()}\"\"\"\n",
    "    card_color = color\n",
    "    card_label_name =file\n",
    "    queries_source = f\"\"\"../testing/queries/{file}.csv\"\"\"\n",
    "\n",
    "    tasks = []\n",
    "    list_response = create_list(card_title)\n",
    "    with open(queries_source, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            tasks.append(send_request(row,list_response,card_color,card_label_name))\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Apply nest_asyncio\n",
    "nest_asyncio.apply()\n",
    " \n",
    "# Run the event loop\n",
    "\n",
    "# await mainTest('purple','comparative') - fair\n",
    "# await mainTest('blue','opinion') - fair \n",
    "# await mainTest('green','descriptive') - fair\n",
    "# await mainTest('red','clarification') - fair\n",
    "# await mainTest('orange','procedural') - fair\n",
    "# await mainTest('pink','yesno') - fair"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
