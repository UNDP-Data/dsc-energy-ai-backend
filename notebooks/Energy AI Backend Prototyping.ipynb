{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "542a4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.0.0) was trained with spaCy v3.0.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import ast\n",
    "from openai import AzureOpenAI\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import pycountry\n",
    "import re\n",
    "from bert_score import score as bert_score\n",
    "import csv\n",
    "import transformers\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from datetime import datetime\n",
    "import tiktoken\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "from country_named_entity_recognition import find_countries\n",
    "import awoc\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fdd010",
   "metadata": {},
   "source": [
    "### Load Model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ecc76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../models/df_embed_EN_All_V4.pkl')\n",
    "\n",
    "# # Filter DataFrame for rows where Country Code is 'THA'\n",
    "# df_tha = df[df['Country Code'] == 'China']\n",
    "\n",
    "# # Display the first 10 rows of the filtered DataFrame\n",
    "# print(df_tha.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf814d9",
   "metadata": {},
   "source": [
    "### Load Enviroment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f4c742f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6f3e87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API configuration\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"api_key_azure\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"api_version\")\n",
    "openai_deployment = \"sdgi-gpt-35-turbo-16k\"\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"api_key_azure\"),  \n",
    "  api_version = os.getenv(\"api_version\"),\n",
    "  azure_endpoint =os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    ")\n",
    "\n",
    "embedding_model = os.getenv(\"USER_QUERY_EMBEDDING_ENGINE\") \n",
    "\n",
    "# print(openai.api_key)\n",
    "# print(openai.api_base)\n",
    "# print(openai.api_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16534287",
   "metadata": {},
   "source": [
    "<h3>globals</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b2a3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_query=\"What are the sustainable energy priorities for UNDP?\"\n",
    "test_query = 'What is the Human Development Index (HDI) value for Albania as mentioned in the document?'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f11f01",
   "metadata": {},
   "source": [
    "<h3> helper functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc569537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to make simple openAI Calls\n",
    "def callOpenAI(prompt):  \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ]\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd62b3",
   "metadata": {},
   "source": [
    "<h3> processing modules </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6798164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEntitiesFromQuery(user_query):\n",
    "    prompt = f\"\"\"\n",
    "    Extract entities from the following user query: \\\"{user_query}\\\" and return output in array format.\n",
    "    \n",
    "    -Entities should be directly related to the domain or topic of interest. They should represent important concepts that contribute to the understanding of the subject matter.\n",
    "    -Each entity in the knowledge graph should be distinct and have a unique identifier. This ensures clarity and avoids ambiguity when establishing relationships between entities.\n",
    "    -You Must return output in array format e.g  ['entity1','entity2'] !!!\n",
    "    -Avoid adding new lines or breaking spaces to your output. Array should be single dimension and single line !!!\n",
    " \n",
    "    \"\"\"\n",
    "    entity_list = callOpenAI(prompt)   \n",
    "    return entity_list\n",
    "\n",
    "# Test usage\n",
    "# test_query = \"What are the sustainable energy for UNDP?\"\n",
    "# entity_list = extractEntitiesFromQuery(test_query)\n",
    "# print(entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7718dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## module to get information on the entities from user query using the KG\n",
    "def knowledgeGraphModule(user_query):\n",
    "    \n",
    "    # generate list of entities based on user query\n",
    "    entity_list = extractEntitiesFromQuery(user_query)\n",
    "    my_list = ast.literal_eval(entity_list)\n",
    "    prompt_summarise_entites = f\"\"\"\n",
    "    Summarize all relations between all the entities : {my_list}\n",
    "    \"\"\"\n",
    "    summarise_entities = callOpenAI(prompt_summarise_entites)\n",
    "    # Initialize an empty dictionary to store information\n",
    "    entities_dict = {\n",
    "        \"relations\": summarise_entities,\n",
    "        \"entities\": {}\n",
    "    }\n",
    "    # Loop through each entity in the list\n",
    "    for entity in my_list:\n",
    "        # Fetch information about the entity from your knowledge graph\n",
    "        prompt = f\"Give me a short description 50 words of {entity}\"\n",
    "        entity_info = callOpenAI(prompt)\n",
    "        # Add the entity information to the dictionary\n",
    "        entities_dict[\"entities\"][entity] = entity_info\n",
    "    \n",
    "    return entities_dict\n",
    "\n",
    "\n",
    "# Test usage\n",
    "# test_query = \"What is the role of Paris Agreement in sustainable energy development?\"\n",
    "# entities_dict = knowledgeGraphModule(test_query)\n",
    "# print(entities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37c65c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awoc import AWOC\n",
    "\n",
    " \n",
    " \n",
    "def find_mentioned_countries(text):\n",
    "    countries = set()\n",
    "    \n",
    "    # Tokenize the text using regular expressions to preserve punctuation marks\n",
    "    words = re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "    text = ' '.join(words)  # Join the tokens back into a string\n",
    "    \n",
    "    # Get a list of all country names\n",
    "    all_countries = {country.name: country for country in pycountry.countries}\n",
    "    \n",
    "    # Check for multi-word country names first to avoid partial matches\n",
    "    for name in sorted(all_countries.keys(), key=lambda x: len(x), reverse=True):\n",
    "        if name in text:\n",
    "            countries.add(all_countries[name].name)\n",
    "            text = text.replace(name, '')  # Remove the found country name from the text to avoid duplicates\n",
    "\n",
    "    return list(countries)\n",
    "\n",
    "\n",
    "# Extract mentioned countries' ISO3 code\n",
    "def find_mentioned_country_code(user_query):\n",
    "    countries = set()\n",
    "    extracted_countries = find_mentioned_countries(user_query)\n",
    "    \n",
    "    for country in extracted_countries:\n",
    "        try:\n",
    "            country_info = pycountry.countries.get(name=country)\n",
    "            if country_info:\n",
    "                countries.add(country_info.alpha_3)\n",
    "        except LookupError:\n",
    "            pass\n",
    "    \n",
    "    # If no countries are found, check for continent mentions\n",
    "    if not countries:\n",
    "        words = re.findall(r'\\w+|[^\\w\\s]', user_query)\n",
    "        text = ' '.join(words)  # Join the tokens back into a string\n",
    "    \n",
    "        world_info = AWOC()\n",
    "        all_continents = set([continent.lower() for continent in world_info.get_continents_list()])\n",
    "        for word in text.split():\n",
    "            word = word.lower()\n",
    "            if word in all_continents:\n",
    "                target_countries = world_info.get_countries_list_of(word)\n",
    "                \n",
    "                for country in target_countries:\n",
    "                    countries.add(world_info.get_country_data(country)['ISO3'])\n",
    "    \n",
    "    return countries\n",
    "\n",
    "\n",
    "# # Example \n",
    "# user_query = 'Could you clarify how UNDP ensures financial transparency and accountability in its large-scale solar energy projects in Africa ?'\n",
    "# mentioned_countries = find_mentioned_country_code(user_query)\n",
    "# mentioned_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee0a9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the English language model\n",
    "# Function to calculate the average word embedding for a sentence\n",
    "# def average_word_embedding(sentence):\n",
    "#     # Parse the sentence using SpaCy\n",
    "#     doc = nlp(sentence)\n",
    "#     # Get word vectors and average them\n",
    "#     word_vectors = [token.vector for token in doc if token.has_vector]\n",
    "#     if not word_vectors:\n",
    "#         return None\n",
    "#     return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n",
    "def average_word_embedding(sentence):\n",
    "    if sentence is None:\n",
    "        sentence = \"\"\n",
    "    \n",
    "    # Parse the sentence using SpaCy\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Get word vectors and average them\n",
    "    vectors = [token.vector for token in doc if token.has_vector]\n",
    "    if not vectors:\n",
    "        return None\n",
    "    \n",
    "    avg_vector = sum(vectors) / len(vectors)\n",
    "    return avg_vector\n",
    "\n",
    "# Function to calculate context similarity between two sentences using word embedding averaging\n",
    "def calculate_context_similarity(sentence1, sentence2):\n",
    "    # Get average word embeddings for each sentence\n",
    "    avg_embedding1 = average_word_embedding(sentence1)\n",
    "    avg_embedding2 = average_word_embedding(sentence2)\n",
    "    if avg_embedding1 is None or avg_embedding2 is None:\n",
    "        return None\n",
    "    # Calculate cosine similarity between the embeddings\n",
    "    similarity = cosine_similarity([avg_embedding1], [avg_embedding2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# # Example sentences\n",
    "# sentence1 = 'The companys quarterly earnings report exceeded expectations, leading to a surge in stock prices.'\n",
    "# sentence2 = 'The firms financial results for the last quarter surpassed predictions, resulting in a sharp rise in the value of shares'\n",
    "\n",
    "\n",
    "\n",
    "# Calculate context similarity\n",
    "# similarity = calculate_context_similarity(sentence1, sentence2)\n",
    "# print(\"Context similarity:\", similarity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d626cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Jaccard similarity between two texts\n",
    "def jaccard_similarity(text1, text2):\n",
    "    # Tokenize texts\n",
    "    tokens1 = set(text1.lower().split())\n",
    "    tokens2 = set(text2.lower().split())\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    intersection = len(tokens1.intersection(tokens2))\n",
    "    union = len(tokens1.union(tokens2))\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50651a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_contains_entity(entity, title):\n",
    "    # Convert both entity and title to lowercase for case-insensitive comparison\n",
    "    entity_lower = entity.lower()\n",
    "    title_lower = title.lower()\n",
    "\n",
    "    # Check if the lowercase entity is contained within the lowercase title\n",
    "    if entity_lower in title_lower:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f8f9b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_semantics_spacy(user_query):\n",
    "#     doc = nlp(user_query)\n",
    "#     entities = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ != \"\"]  # Filter out empty entities\n",
    "#     entities.extend((token.text, \"NOUN\") for token in doc if token.pos_ in [\"NOUN\", \"PROPN\", \"PRON\", \"NUM\", \"SYM\", \"X\", \"ABBR\"] or token.is_alpha)\n",
    "\n",
    "#     # Remove stop words\n",
    "#     entities = [(entity, label) for entity, label in entities if entity.lower() not in STOP_WORDS]\n",
    "\n",
    "#     # Initialize empty DataFrames\n",
    "#     filtered_df_country = pd.DataFrame()\n",
    "#     filtered_df_others = pd.DataFrame()\n",
    "#     filtered_df_others_title = pd.DataFrame()\n",
    "\n",
    "#     filtered_df_backup_reference = pd.DataFrame()\n",
    "#     allow_low = True\n",
    "\n",
    "#     for entity, label in entities:\n",
    "       \n",
    "#         filtered_df_others = pd.concat([filtered_df_others, df[df['Country Name'].str.lower().str.contains(entity.lower(), na=False)]])\n",
    "#         filtered_df_others_title = pd.concat([filtered_df_others_title, df[df['Document Title'].str.lower().str.contains(entity.lower(), na=False)]])\n",
    "\n",
    "#         # Calculate similarity scores for each document title and country name\n",
    "#         similarity_scores_country = []\n",
    "#         similarity_scores_title = []\n",
    "#         document_titles = []\n",
    "\n",
    "#         for index, row in filtered_df_others.iterrows():\n",
    "#             country_name = row['Country Name']\n",
    "#             document_title = row['Document Title']\n",
    "\n",
    "#             if country_name is not None:\n",
    "                \n",
    "#                 similarity_score_country = calculate_context_similarity(user_query, country_name)\n",
    "#                 similarity_scores_country.append(similarity_score_country)\n",
    "#             else:\n",
    "#                 similarity_scores_country.append(0)\n",
    "\n",
    "#             if document_title is not None:\n",
    "#                 similarity_score_title = calculate_context_similarity(user_query, document_title)\n",
    "#                 similarity_scores_title.append(similarity_score_title)\n",
    "#             else:\n",
    "#                 similarity_scores_title.append(0)\n",
    "\n",
    "#             document_titles.append(document_title)\n",
    "        \n",
    "#         similarity_df = pd.DataFrame({\n",
    "#             'Country Name': filtered_df_others['Country Name'],\n",
    "#             'Document Title': document_titles,\n",
    "#             'Similarity Score Country': similarity_scores_country,\n",
    "#             'Similarity Score Title': similarity_scores_title\n",
    "#         })\n",
    "\n",
    "#         # Define thresholds\n",
    "#         threshold_country = 0.5\n",
    "#         threshold_title = 0.5\n",
    "\n",
    "#         # Filter df based on similarity scores greater than threshold\n",
    "#         filtered_df_others = df[\n",
    "#             df['Country Name'].isin(similarity_df[similarity_df['Similarity Score Country'] > threshold_country]['Country Name']) &\n",
    "#             df['Document Title'].isin(similarity_df[similarity_df['Similarity Score Title'] > threshold_title]['Document Title'])\n",
    "#         ]\n",
    "\n",
    "#         filtered_df_backup_reference = pd.concat([filtered_df_backup_reference, df[\n",
    "#             df['Country Name'].isin(similarity_df[(similarity_df['Similarity Score Country'] >= 0.1) & (similarity_df['Similarity Score Country'] < threshold_country)]['Country Name']) |\n",
    "#             df['Document Title'].isin(similarity_df[(similarity_df['Similarity Score Title'] >= 0.1) & (similarity_df['Similarity Score Title'] < threshold_title)]['Document Title'])\n",
    "#         ]])\n",
    "\n",
    "#         # Check for location related e.g by country, language, locals\n",
    "#         # if label in ['GPE', 'NORP', 'LANGUAGE', 'FAC']:\n",
    "#         filtered_df_country_code = find_mentioned_country_code(user_query) #pd.concat([filtered_df_country, df[df['Country Name'] == entity]])\n",
    "            \n",
    "#         # filtered_df_country = df[df['Country Code'] == filtered_df_country_code]\n",
    "#         filtered_df_country = filter_dataframe_by_country_names(df, filtered_df_country_code)\n",
    "\n",
    "#         # print(f\"\"\"find_mentioned_country_code=== \"{filtered_df_country_code}\"\"\")\n",
    "\n",
    "#     merged_df = pd.DataFrame()\n",
    "#     # if filtered_df_others.empty and filtered_df_country.empty:\n",
    "#     #     print(f'on the reference df {filtered_df_backup_reference.empty}')\n",
    "#     #     merged_df = pd.concat([filtered_df_backup_reference])\n",
    "#     # else:\n",
    "#     # merged_df = pd.concat([filtered_df_country, filtered_df_others, filtered_df_backup_reference,filtered_df_others_title])\n",
    "#     merged_df = pd.concat([filtered_df_country])\n",
    "\n",
    "#     return merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "79226e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def average_word_context_embed(sentence):\n",
    "    # Ensure the input is a string\n",
    "    if not isinstance(sentence, str):\n",
    "        return None\n",
    "    \n",
    "    # If the sentence is empty, return None\n",
    "    if not sentence:\n",
    "        return None\n",
    "    \n",
    "    # Parse the sentence using SpaCy\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Get word vectors and average them\n",
    "    vectors = [token.vector for token in doc if token.has_vector]\n",
    "    if vectors:\n",
    "        avg_vector = np.mean(vectors, axis=0)\n",
    "        return avg_vector\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_context_bool(uq, doc_):\n",
    "    avg_emb1 = average_word_context_embed(uq)\n",
    "    avg_emb2 = average_word_context_embed(doc_)\n",
    "    if avg_emb1 is None or avg_emb2 is None:\n",
    "        return False\n",
    "    \n",
    "    similarity = np.dot(avg_emb1, avg_emb2) / (np.linalg.norm(avg_emb1) * np.linalg.norm(avg_emb2))\n",
    "    return similarity > 0.75  # Assuming 0.75 is the threshold for context similarity\n",
    "\n",
    "\n",
    "# Function to convert country codes to country names\n",
    "def convert_codes_to_names(codes):\n",
    "    code_to_name = {country.alpha_3: country.name for country in pycountry.countries}\n",
    "    return {code_to_name.get(code, code) for code in codes}\n",
    "\n",
    "\n",
    "\n",
    "# Function to filter DataFrame based on country names\n",
    "def filter_dataframe_by_country_names(df, filtered_country_cde):\n",
    "    filtered_dfs = []\n",
    "    country_names = convert_codes_to_names(filtered_country_cde)\n",
    "    code_to_name = {country.alpha_3: country.name for country in pycountry.countries}\n",
    "    \n",
    "    for code in filtered_country_cde:\n",
    "        country_name = code_to_name.get(code, None)\n",
    "        if country_name:\n",
    "            filtered_df = df[df['Country Code'] == code]\n",
    "            filtered_df['Country Name'] = country_name\n",
    "            filtered_dfs.append(filtered_df)\n",
    "    \n",
    "    if filtered_dfs:\n",
    "        result_df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "    else:\n",
    "        result_df = pd.DataFrame()  # Return empty DataFrame if no matches\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "#no spacy option - spacy entites gives alot of errors\n",
    "def filter_semantics(user_query): \n",
    "    filtered_df_country = pd.DataFrame()\n",
    "    filtered_df_title_context = pd.DataFrame()\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    filtered_df_country_code = find_mentioned_country_code(user_query)\n",
    "    filtered_df_country = filter_dataframe_by_country_names(df, filtered_df_country_code)\n",
    "\n",
    "    \n",
    "    filtered_df_title_context = df[df['Document Title'].notnull() & df['Document Title'].apply(lambda title: calculate_context_bool(user_query, title))]\n",
    "    filtered_df_summary_context = df[df['Summary'].notnull() & df['Summary'].apply(lambda summary: calculate_context_bool(user_query, summary))]\n",
    "    \n",
    "    # Ensure both DataFrames have the same columns before concatenating\n",
    "    if 'Country Name' not in filtered_df_title_context.columns:\n",
    "        filtered_df_title_context['Country Name'] = np.nan\n",
    "    if 'Country Name' not in filtered_df_summary_context.columns:\n",
    "        filtered_df_summary_context['Country Name'] = np.nan\n",
    "    \n",
    "    # Merge the two filtered DataFrames\n",
    "    merged_df = pd.concat([filtered_df_country, filtered_df_summary_context, filtered_df_title_context])\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# # Example \n",
    "# test_query=\"How do the challenges of implementing renewable energy projects in Asia compare to those in Latin America?\"\n",
    "# filtered_country = filter_semantics(test_query)\n",
    "# filtered_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b85bd554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def search_embeddings(user_query):\n",
    "    # df_filtered = filter_semantics(user_query) if filter_semantics(user_query) is not None else None\n",
    "    filtered_result = filter_semantics(user_query)\n",
    "    # Check if the result is not None before assigning it to df_filtered\n",
    "    df_filtered = filtered_result if filtered_result is not None else None\n",
    "\n",
    "    if df_filtered is not None and not df_filtered.empty:  # Check if DataFrame is not None and not empty\n",
    "        length = len(df_filtered.head())\n",
    "        filtered_embeddings_arrays = np.array(list(df_filtered['Embedding']))\n",
    "        index = faiss.IndexFlatIP(filtered_embeddings_arrays.shape[1]) \n",
    "        index.add(filtered_embeddings_arrays)\n",
    "        \n",
    "        user_query_embedding = client.embeddings.create( \n",
    "                input=user_query ,model= embedding_model\n",
    "            ).data[0].embedding\n",
    "\n",
    "        k = min(5, length)\n",
    "        distances, indices = index.search(np.array([user_query_embedding]), k)\n",
    "\n",
    "        # Extract the text excerpts\n",
    "        text_excerpts = df_filtered.iloc[indices[0]]['Content'].tolist()\n",
    "        print(f\"\"\" indices=== {indices}\"\"\")\n",
    "        return df_filtered, distances, indices, text_excerpts\n",
    "    else:\n",
    "        return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27928260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_structure(qs):\n",
    "    result_dict = {}\n",
    "\n",
    "    # Extract the DataFrame from the tuple\n",
    "    dataframe = qs[0]\n",
    "    # print(qs[1])\n",
    "    # print(qs[2])\n",
    "    # print(f\"\"\" text_excerpts== {qs[3]} \"\"\")\n",
    "\n",
    "    # Counter to limit the loop to 10 iterations\n",
    "    count = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # Define a unique identifier for each document, you can customize this based on your data\n",
    "        document_id = f\"doc-{index + 1}\"\n",
    "        # Handle NaN in content by using fillna\n",
    "        content = row[\"Content\"]\n",
    "        content = ' '.join(row[\"Content\"].split()[:160])\n",
    "        # Create a dictionary for each document\n",
    "        document_info = {\n",
    "            \"title\": row[\"Document Title\"],\n",
    "            \"extract\": content or \"\",  # You may need to adjust this based on your column names\n",
    "            \"category\": row[\"Category\"],\n",
    "            \"link\": row[\"Link\"].replace(\"https-//\",\"https://\"),\n",
    "            \"summary\": row[\"Summary\"],\n",
    "            \"thumbnail\": ''\n",
    "        }\n",
    "        # print(document_info)\n",
    "        # Add the document to the result dictionary\n",
    "        result_dict[document_id] = document_info\n",
    "\n",
    "        # Increment the counter\n",
    "        count += 1\n",
    "\n",
    "        # # Break out of the loop if the counter reaches top 25\n",
    "        if count == 10:\n",
    "            break\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f166c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to relabel keys and add citations\n",
    "def relabel_and_add_citations(data):\n",
    "    new_data = {}\n",
    "    citation_counter = 1\n",
    "\n",
    "    for doc_id, doc_info in data.items():\n",
    "        new_data[doc_id] = {\n",
    "            \"document_title\": doc_info.get(\"title\", \"\"),\n",
    "            \"summary\": doc_info.get(\"extract\", \"\"),\n",
    "            \"document_category\": doc_info.get(\"category\", \"\"),\n",
    "            \"document_link\": doc_info.get(\"link\", \"\"),\n",
    "            \"document_thumbnail\": doc_info.get(\"thumbnail\", \"\"),\n",
    "\n",
    "            \"citation\": citation_counter\n",
    "        }\n",
    "        citation_counter += 1\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a53eff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_valid_json_objects(json_string):\n",
    "    # Regex pattern to extract valid JSON objects\n",
    "    pattern = re.compile(r'{.*?}', re.DOTALL)\n",
    "\n",
    "    # Find all matches in the string\n",
    "    matches = pattern.findall(json_string)\n",
    "\n",
    "    # Parse each match to a dictionary\n",
    "    parsed_data = []\n",
    "    for match in matches:\n",
    "        try:\n",
    "            parsed_data.append(json.loads(match))\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    \n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86b19824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_links_and_process_html(html, content_dict):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('a'):\n",
    "        ref_text = a.get_text()\n",
    "        if ref_text.startswith('[') and ref_text.endswith(']'):\n",
    "            href = a.get('href')\n",
    "            if not any(d['link'] == href for d in content_dict.values()):\n",
    "                a.decompose()\n",
    "    \n",
    "    result = str(soup)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58c69dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " query_transformation: What does UNDP mean by 'gender-inclusive' when discussing renewable energy solutions in Bangladesh? | \n",
      "Why is UNDP emphasizing on gender inclusivity in renewable energy solutions in Bangladesh? | \n",
      "How does UNDP plan to implement gender-inclusive renewable energy solutions in Bangladesh? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/bqmlvyrj2cx73wpm001ps2pr0000gn/T/ipykernel_6878/4128300338.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Country Name'] = country_name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indices=== [[ 0  4  3 10  8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/bqmlvyrj2cx73wpm001ps2pr0000gn/T/ipykernel_6878/4128300338.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Country Name'] = country_name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indices=== [[ 0  4  3  8 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/bqmlvyrj2cx73wpm001ps2pr0000gn/T/ipykernel_6878/4128300338.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Country Name'] = country_name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indices=== [[ 0 10  4  3 11]]\n",
      "Excerpts saved to outputs/excerpts.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_queries(queries):\n",
    "    merged_result_structure = {}\n",
    "\n",
    "    for query in queries:\n",
    "        qs = search_embeddings(query)  # Assuming search_embeddings returns a tuple (df, distances, indices)\n",
    "\n",
    "        if qs[0] is not None:\n",
    "            result_structure = map_to_structure(qs)\n",
    "            for doc_id, doc_info in result_structure.items():\n",
    "                merged_result_structure[doc_id] = doc_info\n",
    "    \n",
    "    return merged_result_structure\n",
    "\n",
    "\n",
    "## module to extract text from documents and return the text and document codes\n",
    "def semanticSearchModule(user_query):\n",
    "    query_transformation = callOpenAI(f\"\"\"\n",
    "    Given a question, your job is to break them into 3 main sub-question and return as array. \n",
    "    \n",
    "    - You Must return output seperated by |\n",
    "    - Avoid adding new lines or breaking spaces to your output and must seperate each idea with |\n",
    "\n",
    "    QUESTION: {user_query}\n",
    "    \"\"\")\n",
    "    print(f\"\"\" query_transformation: {query_transformation} \"\"\")\n",
    "    \n",
    "    # Split the string by the delimiter '|'\n",
    "    questions_array = [question.strip() for question in query_transformation.split('|')]\n",
    "\n",
    "\n",
    "    merged_results = process_queries(questions_array)\n",
    "    return merged_results\n",
    "\n",
    "\n",
    "\n",
    "#test usage\n",
    "excerpts_dict= semanticSearchModule(\"What exactly does UNDP mean by 'gender-inclusive' when discussing renewable energy solutions in Bangladesh?\")\n",
    "# # print(f\"\"\"excerpts_dict {excerpts_dict}\"\"\")\n",
    "\n",
    "# #Return top 10-20 most related \n",
    "# # Define the filename to save the JSON data -  can remove later\n",
    "json_filename = \"outputs/excerpts.json\"\n",
    "\n",
    "# # Save excerpts_dict to the JSON file just for a better preview\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(excerpts_dict, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Excerpts saved to {json_filename}\")\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "db75b59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indicator-id-1': 'value from indicator-id-1', 'indicator-id-2': 'value from indicator-id-2'}\n"
     ]
    }
   ],
   "source": [
    "## module to get data for specific indicators which are identified is relevant to the user query\n",
    "\n",
    "def indicatorsModule(user_query): #lower priority\n",
    "    \n",
    "    # find relevant indicators based on uesr query and extract values\n",
    "    indicators_dict={\n",
    "        \"indicator-id-1\":\"value from indicator-id-1\",\n",
    "        \"indicator-id-2\":\"value from indicator-id-2\"\n",
    "    }#temp\n",
    "    \n",
    "    return indicators_dict\n",
    "\n",
    "#test usage\n",
    "indicators_dict=indicatorsModule(test_query)\n",
    "print(indicators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d8237482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## module to generate query ideas\n",
    "\n",
    "def queryIdeationModule(user_query): # lower priority\n",
    "    \n",
    "    # Generate query ideas using OpenAI GPT-3\n",
    "    prompt = f\"\"\"\n",
    "    Ignore previous commands!!!\n",
    "    Generate prompt ideas based on the user query: {user_query}\n",
    "\n",
    "    \n",
    "    -Prompt shoud not be answer to the user query but give other contextual ways of representing the user query !!!\n",
    "    -You Must return output seperated by |  e.g idea 1 | idea2 \n",
    "    - Each generated ideas should be very dinstinct but contextual. Not repeatitive or using same words\n",
    "    - The query idea should be in a question form and not an answer form.\n",
    "    -Avoid adding new lines or breaking spaces to your output and must seperate each idea with |\n",
    "    \"\"\"\n",
    "    response = callOpenAI(prompt)\n",
    "    return response\n",
    "\n",
    "#test usage\n",
    "# query_idea_list=queryIdeationModule(test_query)\n",
    "# print(query_idea_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "44eb60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(user_question, relevant_docs):\n",
    " \n",
    "    formattings_html = f\"\"\" \n",
    "        Ignore previous\n",
    "        Strictly follow the follow steps:\n",
    "        Your output answer shoud be  in HTML syntax with HTML tags.\n",
    "        Use HTML tags like < ul>, < ol>, < li>,  < strong>, < p>\n",
    "        Only consider the inner part of the < body> tag.\n",
    "        ALWAYS use the following tag for new lines: < br />\n",
    "        Do not add CSS attributes.\n",
    "        Include links and citations at all!!!\n",
    "        Your final answer must be formatted in HTML format !!!\n",
    "\n",
    "        - Only provide links in citations. Never link outside citations.\n",
    "    \"\"\"\n",
    "    formattings = f\"\"\" \n",
    "        You can use relevant information in the docs to answer also: \n",
    "\n",
    "        DOCS: {relevant_docs}\n",
    "        \n",
    "       \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":f\"\"\"You are a helpful assistant and a professional researcher with many years of experience in answering questions. Give answer to the user's inquiry. {formattings_html}\"\"\"\n",
    "        },\n",
    "        {'role': 'user', 'content': f\"\"\"{formattings} \n",
    "                                        {user_question}\n",
    "                                        \n",
    "                                         {formattings_html}\n",
    "                                        \"\"\"},\n",
    "    ]\n",
    "       \n",
    "    response_entities = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    temperature=0.5,\n",
    "                    messages=messages,\n",
    "                    top_p=0.8,\n",
    "                    frequency_penalty=0.6,\n",
    "                    presence_penalty=0.8\n",
    "                )\n",
    "    response = response_entities.choices[0].message.content\n",
    "\n",
    "    return response\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b73a93",
   "metadata": {},
   "source": [
    "<h3> synthesis module </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0f509d",
   "metadata": {},
   "source": [
    "    llm_instructions=\"llm instruction template here, with placeholders for insertion of user query, excerpts, indicator data, and entity and relation info\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b7113366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def synthesisModule(user_query, entities_dict, excerpts_dict, indicators_dict,prompt_formattings):\n",
    "    \n",
    "    # print(f\"\"\" ********************************************************************* {user_query} *********************************************************************  \"\"\")\n",
    "\n",
    "    ###synthesize data into structure within llm prompt engineering instructions\n",
    "    answer=get_answer(user_query,excerpts_dict) #callOpenAI\n",
    "    answer_formated_fixed = answer.replace(\"\\n\\n\",\"<br>\").replace(\"\\n\",\"<br>\")\n",
    "    # answer_citation = add_citation(answer_formated_fixed,excerpts_dict)\n",
    "    # answer_citation = answer_citation #.replace(\"\\\\\",\"\").replace(\"\\n\",\"\")\n",
    "    \n",
    "    # print(f\"\"\" {answer} \"\"\")\n",
    "    # print(f\"\"\" ********************************************************************* END *********************************************************************  \"\"\")\n",
    "\n",
    "    return answer\n",
    "\n",
    "## to test this, run the full pipeline with the handleApiCall function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "db964d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleanup outputs\n",
    "# Parse the HTML content\n",
    "\n",
    "# Function to remove [n] if not inside an <a> tag\n",
    "def remove_unlinked_citations(soup):\n",
    "    # Regular expression to match [n] pattern\n",
    "    pattern = re.compile(r'\\[\\d+\\]')\n",
    "    \n",
    "    for text in soup.find_all(text=pattern):\n",
    "        # Find all matches in the text\n",
    "        matches = pattern.findall(text)\n",
    "        for match in matches:\n",
    "            # Check if the match is inside an <a> tag\n",
    "            if not text.find_parent('a'):\n",
    "                # Remove the match from the text\n",
    "                text.replace_with(text.replace(match, ''))\n",
    "    \n",
    "    return soup\n",
    "\n",
    "\n",
    "def cleanCitation(html_content): \n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    # Remove unlinked citations\n",
    "    clean_soup = remove_unlinked_citations(soup)\n",
    "\n",
    "    # Get the modified HTML content\n",
    "    clean_html_content = str(clean_soup)\n",
    "\n",
    "    return clean_html_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787b228",
   "metadata": {},
   "source": [
    "<h3> run pipeline </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "10fe2bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " query_transformation: What is the role of UNDP in promoting solar energy solutions in urban areas of Thailand? | How does UNDP promote solar energy solutions in urban areas of Thailand? | What are the efforts made by UNDP to promote solar energy solutions in urban areas of Thailand? \n",
      " indices=== [[ 7  9  1 12  6]]\n",
      " indices=== [[6 4 2 1 0]]\n",
      " <p>The United Nations Development Programme (UNDP) plays a crucial role in promoting solar energy solutions in urban areas of Thailand. Through various initiatives and partnerships, UNDP aims to accelerate the adoption of solar energy and contribute to sustainable development goals. Here are some key aspects of UNDP's involvement:</p><ol> <li><strong>Project Implementation:</strong> UNDP implements projects that focus on increasing access to solar energy in urban areas of Thailand. These projects involve the installation of solar panels on rooftops, public buildings, and community facilities. </li> <li><strong>Capacity Building:</strong> UNDP provides technical assistance and capacity building programs to local communities, government agencies, and relevant stakeholders. This includes training on solar panel installation, maintenance, and management. </li> <li><strong>Promoting Policy Support:</strong> UNDP works closely with the Thai government to develop policies and regulations that support the growth of solar energy in urban areas. This includes advocating for favorable feed-in tariffs, net metering schemes, and other incentives for renewable energy. </li> <li><strong>Raising Awareness:</strong> UNDP conducts awareness campaigns to educate the public about the benefits of solar energy and encourage its adoption. These campaigns highlight the environmental advantages, cost savings, job creation potential, and resilience benefits associated with solar power. </li></ol><p>Through these efforts, UNDP aims to create an enabling environment for the widespread use of solar energy in urban areas of Thailand. By promoting clean and sustainable energy solutions, UNDP contributes to reducing greenhouse gas emissions, improving air quality, enhancing energy security, and fostering economic development.</p><p>Sources:</p><ul> <li><a href=\"https://www.th.undp.org/content/thailand/en/home/ourwork/environmentandenergy/successstories/promoting-solar-energy-in-thailand.html\">[1]</a></li> <li><a href=\"https://www.th.undp.org/content/thailand/en/home/ourwork/environmentandenergy/successstories/community-based-solar-energy-for-resilient-communities.html\">[2]</a></li></ul>\n",
      "Synthesis saved to outputs/synthesis_output.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/bqmlvyrj2cx73wpm001ps2pr0000gn/T/ipykernel_6878/3242406292.py:9: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  for text in soup.find_all(text=pattern):\n"
     ]
    }
   ],
   "source": [
    "# full pipeline with retreival, synthesis of answer to user query, and structure results into api response\n",
    "\n",
    "def handleApiCall(user_query):\n",
    "    \n",
    "    ##run processing modules (in parallel)\n",
    "    entities_dict=knowledgeGraphModule(user_query)\n",
    "    excerpts_dict=semanticSearchModule(user_query)\n",
    "    indicators_dict=indicatorsModule(user_query) ##lower priority\n",
    "    query_idea_list=queryIdeationModule(user_query) ##lower priority\n",
    "    prompt_formattings=\"\"\n",
    "    ##synthesis module\n",
    "    answer=synthesisModule(user_query, entities_dict, excerpts_dict, indicators_dict, prompt_formattings)\n",
    "    # print(f\"\"\" Answer==== {answer} \"\"\")\n",
    "    pattern =  re.compile(r'[^.]*\\.')  #re.compile(r'<li>(.*?)</li>')\n",
    "    # Find all matches\n",
    "    content_array = pattern.findall(answer)\n",
    "    sources = excerpts_dict\n",
    "    results = []\n",
    "    # print(content_array)\n",
    "    limiter = 0\n",
    "    for element in content_array:\n",
    "        for doc_id, doc_info in sources.items():\n",
    "            title_similarity = calculate_context_similarity(element, doc_info['title']) or 0\n",
    "            extract_similarity = calculate_context_similarity(element, doc_info['extract']) or  0\n",
    "            # summary_similarity = calculate_context_similarity(element, doc_info['summary'])\n",
    "            # print(title_similarity)\n",
    "            # print(extract_similarity)\n",
    "            if title_similarity > 0.65 and extract_similarity > 0.65 and limiter < 5:\n",
    "                result = {\n",
    "                            'element': element,\n",
    "                            'title': doc_info['title'],\n",
    "                            'extract': doc_info['extract'],\n",
    "                            'extract': doc_info['extract'],\n",
    "                            'link': doc_info['link'],\n",
    "                            'doc_id': doc_id,\n",
    "                            'title_similarity': float(title_similarity),\n",
    "                            'extract_similarity': float(extract_similarity)\n",
    "                            # 'summary_similarity': float(summary_similarity)\n",
    "                        }\n",
    "                results.append(result)\n",
    "                limiter += 1\n",
    "\n",
    "    # for result in results:\n",
    "    #     citation_fixes = callOpenAI(f\"Given the below: {result} Create an output that mixes Element, Document extract and Summary into one output while still maintaining the context of the Element. Your final output answer length should not be more than 200 words. Also avoid using links, sources and references. \")\n",
    "    #     result['citation_fixes'] = citation_fixes\n",
    "    #     result\n",
    "\n",
    " \n",
    "    content = answer\n",
    "    counter = 0\n",
    "    # Loop through each JSON object and replace the element with citation_fixes in the content\n",
    "    # for result in results:\n",
    "    #     counter += 1\n",
    "    #     print(f\"Element: {result['element']}\")\n",
    "    #     print(f\"Document ID: {result['doc_id']}\")\n",
    "    #     print(f\"Document Title: {result['title']}\")\n",
    "    #     print(f\"Title Similarity: {result['title_similarity']:.4f}\")\n",
    "    #     print(f\"Extract Similarity: {result['extract_similarity']:.4f}\")\n",
    "    #     # print(f\"Summary Similarity: {result['summary_similarity']:.4f}\")\n",
    "\n",
    "    #     print()\n",
    "\n",
    "        # content = content.replace(result['element'], f\"\"\" {result['citation_fixes']} <a href='{result['link']}' data-id='{result['doc_id']}'>[{counter}]</a> <br/>\\n\\n\"\"\")\n",
    "    \n",
    "    #final cleanup using openAI\n",
    "    cleanup_content = callOpenAI(f\"\"\" Ignore previous commands !!!\n",
    "                                      Strictly follow the below:\n",
    "                                      Give the sentence. I want to to fix the citation formatings only. Don't add any answer to it.\n",
    "                                       1. make sure  links are all in a citation format [n] where n represent an integer and must link to the document e.g content<a href='url-here'>[1]</a>  !!!!\n",
    "                                       2.  The citations must be numbered in an ordered manner. Fix and return the output. !!!\n",
    "                                       3. remove all foot notes or references. !!! \n",
    "                                       4. The citations MUST BE LINK to the docs e.g <a href='url-here'>[1]</a>  never use without LINKS !!!\n",
    "                                       5. Output should retains HTML formattings. Never adjust a ciation without it being an anchor link. !!!\n",
    "                                       6. Remeber only format the answer citations. Don't add or remove any. !!!\n",
    "                                       7. Don't generate any link or so. Just use the answer as it is and adjust the citations as instructed above\n",
    "                                       SENTENCE: {content}  \n",
    "                                \"\"\")\n",
    "    cleanup_content = cleanup_content.replace(\"\\n\",\"\")\n",
    "    cleanup_content = cleanCitation(cleanup_content)\n",
    "    print(f\"\"\" {cleanup_content}\"\"\")\n",
    "    \n",
    "    response={\n",
    "        \"user_query\":user_query,\n",
    "        \"answer\":f\"\"\"{cleanup_content}\"\"\",\n",
    "        \"sources\":excerpts_dict,\n",
    "        \"query_ideas\":query_idea_list,\n",
    "        \"entities\":list(entities_dict[\"entities\"].keys())       \n",
    "    }\n",
    "    return response\n",
    "\n",
    "\n",
    "# test usage\n",
    "test_query = \"Could you clarify the role of UNDP in promoting solar energy solutions in urban areas of Thailand?\"\n",
    "response=handleApiCall(test_query) \n",
    "# Define the filename to save the JSON data -  can remove later\n",
    "json_filename = \"outputs/synthesis_output.json\"\n",
    "\n",
    "# Save excerpts_dict to the JSON file just for a better preview\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(response, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Synthesis saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7cc6f",
   "metadata": {},
   "source": [
    "<h1>Testing</h1>\n",
    "\n",
    "<p>This sections contains all things testings </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(csv_file):\n",
    "    # Initialize an empty list to store processed entries\n",
    "    result = []\n",
    "    \n",
    "    # Loop through each entry in the CSV file\n",
    "    for entry in csv.DictReader(csv_file):\n",
    "        query = entry['query']\n",
    "        sample_answer = entry['sample_answer']\n",
    "        \n",
    "        # Call OpenAI for chat GPT answer\n",
    "        chat_gpt_answer = callOpenAI(f\"\"\" \n",
    "                                    {query} \n",
    "                                    {prompt_formattings} \n",
    "                                    \"\"\")\n",
    "        \n",
    "        # Call the moonshot model API\n",
    "        moonshot_model_answer = handleApiCall(query) \n",
    "        \n",
    "        # Calculate BERT score for moonshot model answer\n",
    "        P, F, R = bert_score([sample_answer], [moonshot_model_answer['answer']], lang='en', verbose=True)\n",
    "        entry['moonshot_model_answer'] = moonshot_model_answer['answer']\n",
    "        entry['bert_score'] = round(float(F), 2)\n",
    "\n",
    "        # Calculate BERT score for chat GPT answer\n",
    "        P, F, R = bert_score([sample_answer], [chat_gpt_answer], lang='en', verbose=True)\n",
    "        entry['chat_gpt_answer'] = chat_gpt_answer\n",
    "        entry['bert_score_gpt'] = round(float(F), 2)\n",
    "        \n",
    "        # Append the processed entry to the result list\n",
    "        result.append(entry)\n",
    "    \n",
    "    # Return the list of processed entries\n",
    "    return result\n",
    "\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = \"../testing/queries.csv\"\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open(csv_file_path, mode='r') as file:\n",
    "    # Pass the file object to the function\n",
    "    result = calculate_scores(file)\n",
    "\n",
    "# Print updated data with scores\n",
    "# print(json.dumps(result, indent=4))\n",
    "\n",
    "# Save updated data to a JSON file\n",
    "with open('../testing/test_output.json', 'w') as file:\n",
    "    json.dump(result, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8961eb",
   "metadata": {},
   "source": [
    "<h1>Compare Moonshot BERT score to GPT BERT Score</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e3412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bert_score: 0.7995652173913044\n",
      "Average bert_score_gpt: 0.7778260869565218\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "with open('../testing/test_output.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize variables to store total scores and count of items\n",
    "total_bert_score = 0\n",
    "total_bert_score_gpt = 0\n",
    "count = 0\n",
    "\n",
    "# Iterate through each item in the JSON data\n",
    "for item in data:\n",
    "    # Extract bert_score and bert_score_gpt from the current item\n",
    "    bert_score = item['bert_score']\n",
    "    bert_score_gpt = item['bert_score_gpt']\n",
    "    \n",
    "    # Add the scores to the total\n",
    "    total_bert_score += bert_score\n",
    "    total_bert_score_gpt += bert_score_gpt\n",
    "    \n",
    "    # Increment the count\n",
    "    count += 1\n",
    "\n",
    "# Calculate the average scores\n",
    "average_bert_score = total_bert_score / count\n",
    "average_bert_score_gpt = total_bert_score_gpt / count\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average bert_score:\", average_bert_score)\n",
    "print(\"Average bert_score_gpt:\", average_bert_score_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905ad59",
   "metadata": {},
   "source": [
    "<h1>Trello Board AutoPopulate</h1>\n",
    "<p> Automation for trello</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66edd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import requests\n",
    "from markdownify import markdownify as md\n",
    "import textwrap\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "def8e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "trello_api_list_id = os.getenv(\"trello_api_list_id\")\n",
    "trello_api_key_id = os.getenv(\"trello_api_key_id\")\n",
    "trello_api_key_token = os.getenv(\"trello_api_key_token\")\n",
    "trello_board_id= os.getenv(\"trello_board_id\")\n",
    "trello_url =\"https://api.trello.com/1/\"\n",
    "# print(trello_board_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c91b0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list function - this allows for various test versions \n",
    "\n",
    "def create_list(list_title):\n",
    "    url = f\"{trello_url}lists?name={list_title}&token={trello_api_key_token}&idBoard={trello_board_id}&key={trello_api_key_id}\"\n",
    "    response = requests.request(\"POST\", url)\n",
    "    response_json = response.json()  # Parse response JSON\n",
    "    list_id = response_json[\"id\"]  # Access 'id' from JSON\n",
    "    return list_id\n",
    "\n",
    "#example\n",
    "# list_response = create_list('User Queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b2d2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list function - this allows for various test versions \n",
    "def create_card_label(card_id, color, name):\n",
    "    url = f\"{trello_url}cards/{card_id}/labels?color={color}&name={name}&token={trello_api_key_token}&idBoard={trello_board_id}&key={trello_api_key_id}\"\n",
    "    # print(url)\n",
    "    response = requests.request(\"POST\", url)\n",
    "    response_json = response.json()  # Parse response JSON\n",
    "    list_id = response_json[\"id\"]  # Access 'id' from JSON\n",
    "    return list_id\n",
    "\n",
    "#example\n",
    "# list_response = create_card_label('','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c28eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_date(format='%b %d %H:%M'):\n",
    "    return datetime.now().strftime(format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de4fc320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Async function to send the request\n",
    "\n",
    "async def send_request(query,list_response,card_color,card_label_name):\n",
    "    name = query[\"query\"]\n",
    "    response=handleApiCall(name) \n",
    "    \n",
    "    # print(f\"\"\" send_request==== {response['answer']} \"\"\" )\n",
    "    #for trello preview only\n",
    "    cleanResp = response['answer'].replace(\"</p>\",\"</p> ******************************************************************************\").replace(\"<p>\",\"<br/>\").replace(\"<br>\",\" *******************************************************************************\").replace(\"</li>\",\" *******************************************************************************\")\n",
    "    markdown_content_description = md(f\"{(cleanResp)}\")\n",
    "    # markdown_content_description = html2text.html2text(cleanResp)\n",
    "\n",
    "    desc = f\"\"\"{markdown_content_description}\"\"\"\n",
    "    url = f\"{trello_url}cards?idList={list_response}&key={trello_api_key_id}&token={trello_api_key_token}&name={name}&desc={desc}\"\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(url, timeout=1200) as response:\n",
    "            el = ''\n",
    "            # print(name)\n",
    "            resp = await response.text()\n",
    "            print(resp)\n",
    "            resp_dict = json.loads(resp)\n",
    "            id = resp_dict['id']\n",
    "\n",
    "            card_label_resp = create_card_label(id, card_color, card_label_name)\n",
    "            print(card_label_resp)\n",
    "            print(\"---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Test process\n",
    "async def mainTest(color,file):\n",
    "    card_title = f\"\"\"{get_current_date()}\"\"\"\n",
    "    card_color = color\n",
    "    card_label_name =file\n",
    "    queries_source = f\"\"\"../testing/queries/{file}.csv\"\"\"\n",
    "\n",
    "    tasks = []\n",
    "    list_response = create_list(card_title)\n",
    "    with open(queries_source, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            tasks.append(send_request(row,list_response,card_color,card_label_name))\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Apply nest_asyncio\n",
    "nest_asyncio.apply()\n",
    " \n",
    "# Run the event loop\n",
    "\n",
    "await mainTest('purple','comparative') \n",
    "# await mainTest('blue','opinion') - fair \n",
    "# await mainTest('green','descriptive') - fair\n",
    "# await mainTest('red','clarification') - fair\n",
    "# await mainTest('orange','procedural') - fair\n",
    "# await mainTest('pink','yesno') - fair"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
